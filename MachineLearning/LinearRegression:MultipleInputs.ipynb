{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 12 Linear Regression With Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "#plt.style.use('../test/deeplearing.mpstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the task: House price prediction with multiple inputs using linear regression\n",
    "\n",
    "y_pred = w*X + b where X = [x1, x2, x3 .......]\n",
    "\n",
    "Objective:\n",
    "    1. Define the task\n",
    "    2. Data Cleaning and processing\n",
    "    3. Data splitting \n",
    "    4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = \"/home/dipu/Desktop/BongoDev/MachineLearning\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "DATASET_PATH = os.path.join(DATA_DIR, \"Housing.csv\")\n",
    "\n",
    "housing_dataset = pd.read_csv(DATASET_PATH)\n",
    "housing_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "housing_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price               0\n",
       "area                0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "stories             0\n",
       "mainroad            0\n",
       "guestroom           0\n",
       "basement            0\n",
       "hotwaterheating     0\n",
       "airconditioning     0\n",
       "parking             0\n",
       "prefarea            0\n",
       "furnishingstatus    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:  Index(['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking'], dtype='object')\n",
      "Categorical Columns:  Index(['mainroad', 'guestroom', 'basement', 'hotwaterheating',\n",
      "       'airconditioning', 'prefarea', 'furnishingstatus'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = housing_dataset.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = housing_dataset.select_dtypes(include=[object]).columns\n",
    "\n",
    "print(\"Numerical Columns: \", numerical_cols)\n",
    "print(\"Categorical Columns: \", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.562174</td>\n",
       "      <td>1.045766</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>1.376952</td>\n",
       "      <td>1.516299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.000809</td>\n",
       "      <td>1.755397</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>5.400847</td>\n",
       "      <td>2.529700</td>\n",
       "      <td>2.676950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000809</td>\n",
       "      <td>2.216196</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>1.516299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.982096</td>\n",
       "      <td>1.082630</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>2.676950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.551716</td>\n",
       "      <td>1.045766</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>-0.569663</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>1.516299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price      area  bedrooms  bathrooms   stories   parking\n",
       "0  4.562174  1.045766  1.402131   1.420507  1.376952  1.516299\n",
       "1  4.000809  1.755397  1.402131   5.400847  2.529700  2.676950\n",
       "2  4.000809  2.216196  0.047235   1.420507  0.224204  1.516299\n",
       "3  3.982096  1.082630  1.402131   1.420507  0.224204  2.676950\n",
       "4  3.551716  1.045766  1.402131  -0.569663  0.224204  1.516299"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = housing_dataset[numerical_cols].mean()\n",
    "std = housing_dataset[numerical_cols].std()\n",
    "housing_dataset[numerical_cols] = (housing_dataset[numerical_cols] - mean) / std\n",
    "housing_dataset[numerical_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if ranking matter the label encoding else Onehotencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "furnishingstatus\n",
       "semi-furnished    227\n",
       "unfurnished       178\n",
       "furnished         140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset['furnishingstatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "furnishingstatus\n",
       "1    227\n",
       "2    178\n",
       "0    140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset[['furnishingstatus']] = housing_dataset[['furnishingstatus']].replace(['furnished', 'semi-furnished', 'unfurnished'], [0, 1, 2])\n",
    "housing_dataset['furnishingstatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.562174</td>\n",
       "      <td>1.045766</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>1.376952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.516299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.000809</td>\n",
       "      <td>1.755397</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>5.400847</td>\n",
       "      <td>2.529700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.676950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000809</td>\n",
       "      <td>2.216196</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.516299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.982096</td>\n",
       "      <td>1.082630</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>1.420507</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.676950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.551716</td>\n",
       "      <td>1.045766</td>\n",
       "      <td>1.402131</td>\n",
       "      <td>-0.569663</td>\n",
       "      <td>0.224204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.516299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price      area  bedrooms  bathrooms   stories  mainroad  guestroom  \\\n",
       "0  4.562174  1.045766  1.402131   1.420507  1.376952         1          0   \n",
       "1  4.000809  1.755397  1.402131   5.400847  2.529700         1          0   \n",
       "2  4.000809  2.216196  0.047235   1.420507  0.224204         1          0   \n",
       "3  3.982096  1.082630  1.402131   1.420507  0.224204         1          0   \n",
       "4  3.551716  1.045766  1.402131  -0.569663  0.224204         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning   parking  prefarea  \\\n",
       "0         0                0                1  1.516299         1   \n",
       "1         0                0                1  2.676950         0   \n",
       "2         1                0                0  1.516299         1   \n",
       "3         1                0                1  2.676950         1   \n",
       "4         1                0                1  1.516299         0   \n",
       "\n",
       "   furnishingstatus  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset[categorical_cols] = housing_dataset[categorical_cols].apply(\n",
    "    lambda col: pd.Categorical(col).codes\n",
    ")\n",
    "housing_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def split_dataset(dataset, training_ratio = 0.8, val_ratio = 0.1):\n",
    "    random_indices = np.random.permutation(len(dataset))\n",
    "    \n",
    "    train_size = int(len(dataset) * training_ratio)\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "\n",
    "    train_indices = random_indices[:train_size]\n",
    "    val_indices = random_indices[train_size:train_size + val_size]\n",
    "    test_indices = random_indices[train_size + val_size:]\n",
    "\n",
    "    train_ds = dataset.iloc[train_indices]\n",
    "    val_ds = dataset.iloc[val_indices]\n",
    "    test_ds = dataset.iloc[test_indices]    \n",
    "\n",
    "    train_X = train_ds.iloc[:, :-1]\n",
    "    train_y = train_ds.iloc[:, -1]\n",
    "\n",
    "    val_X = val_ds.iloc[:, :-1]\n",
    "    val_y = val_ds.iloc[:, -1]\n",
    "\n",
    "    test_X = test_ds.iloc[:, :-1]\n",
    "    test_y = test_ds.iloc[:, -1]\n",
    "\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y\n",
    "\n",
    "train_X, train_y, val_X, val_y, test_X, test_y = split_dataset(housing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_price(X, w, b):\n",
    "    return np.dot(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [716 295 925 600 725 592 174 512 475 519 828 376], b = 860\n"
     ]
    }
   ],
   "source": [
    "w = np.random.randint(low=100, high=1000, size=(train_X.columns.size))\n",
    "b = np.random.randint(low=100, high=1000)\n",
    "\n",
    "print(f\"w = {w}, b = {b}\")\n",
    "y_pred = get_house_price(train_X, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 12025352.400294252 (Parameters not learned yet)\n"
     ]
    }
   ],
   "source": [
    "def cost_function(x, y_true, w, b):\n",
    "    y_pred = get_house_price(x, w, b)\n",
    "    mse = np.mean((y_pred - y_true) ** 2)\n",
    "    return mse\n",
    "\n",
    "mse  = cost_function(train_X, train_y, w, b)\n",
    "print(f\"Mean Squared Error: {mse} (Parameters not learned yet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y_true, w, b):\n",
    "    delta = 1e-9\n",
    "\n",
    "    cost_1 = cost_function(x, y_true, w, b)\n",
    "    cost_2 = cost_function(x, y_true, w + delta, b)\n",
    "    cost_3 = cost_function(x, y_true, w, b + delta)\n",
    "    dw = (cost_2 - cost_1) / delta\n",
    "    db = (cost_3 - cost_1) / delta\n",
    "    return dw, db  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6857798165137614\n",
      "Validation Loss: 1.8333333333333333\n",
      "Epoch: 10000, Train Loss: 1.69, Validation Loss: 1.83\n",
      "=====================================\n",
      "Train Loss: 1.654465814864641\n",
      "Validation Loss: 1.8143716680828585\n",
      "Train Loss: 1.628934369228102\n",
      "Validation Loss: 1.7991627856809866\n",
      "Train Loss: 1.6076463114215382\n",
      "Validation Loss: 1.7864467454428932\n",
      "Train Loss: 1.589478863868599\n",
      "Validation Loss: 1.7753449778864374\n",
      "Train Loss: 1.5736129220064619\n",
      "Validation Loss: 1.7652510256738874\n",
      "Train Loss: 1.559450867019634\n",
      "Validation Loss: 1.7557517731469514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5465566018480645\n",
      "Validation Loss: 1.7465707423281884\n",
      "Train Loss: 1.5346118355679248\n",
      "Validation Loss: 1.7375273935436661\n",
      "Train Loss: 1.5233841914851796\n",
      "Validation Loss: 1.7285079853134175\n",
      "Train Loss: 1.5127039598051513\n",
      "Validation Loss: 1.7194448041784236\n",
      "Train Loss: 1.5024471313952512\n",
      "Validation Loss: 1.7103014075381162\n",
      "Train Loss: 1.4925230304251236\n",
      "Validation Loss: 1.7010622071258814\n",
      "Train Loss: 1.4828652982304353\n",
      "Validation Loss: 1.6917251554638202\n",
      "Train Loss: 1.4734253061102207\n",
      "Validation Loss: 1.6822966653787543\n",
      "Train Loss: 1.4641673606259389\n",
      "Validation Loss: 1.6727881150281017\n",
      "Train Loss: 1.4550652059135971\n",
      "Validation Loss: 1.663213470626568\n",
      "Train Loss: 1.4460994718948958\n",
      "Validation Loss: 1.6535877199660616\n",
      "Train Loss: 1.4372558075358948\n",
      "Validation Loss: 1.6439258363734626\n",
      "Train Loss: 1.4285235281582833\n",
      "Validation Loss: 1.6342421619974628\n",
      "Train Loss: 1.4198946259263379\n",
      "Validation Loss: 1.6245500330393297\n",
      "Train Loss: 1.411363043727909\n",
      "Validation Loss: 1.6148615932060346\n",
      "Train Loss: 1.4029241545383881\n",
      "Validation Loss: 1.6051877230443647\n",
      "Train Loss: 1.3945743713456056\n",
      "Validation Loss: 1.5955380522111609\n",
      "Train Loss: 1.3863108671964386\n",
      "Validation Loss: 1.5859210106486483\n",
      "Train Loss: 1.3781313758039142\n",
      "Validation Loss: 1.5763439166103879\n",
      "Train Loss: 1.3700340407246931\n",
      "Validation Loss: 1.5668130728072518\n",
      "Train Loss: 1.3620173049311342\n",
      "Validation Loss: 1.5573338611799752\n",
      "Train Loss: 1.354079832525286\n",
      "Validation Loss: 1.5479108535361847\n",
      "Train Loss: 1.3462204474652677\n",
      "Validation Loss: 1.5385478916838555\n",
      "Train Loss: 1.338438099029292\n",
      "Validation Loss: 1.5292481907818896\n",
      "Train Loss: 1.3307318260196033\n",
      "Validation Loss: 1.5200144148586188\n",
      "Train Loss: 1.3231007307753226\n",
      "Validation Loss: 1.5108487386679514\n",
      "Train Loss: 1.3155439729940832\n",
      "Validation Loss: 1.501752932198599\n",
      "Train Loss: 1.3080607469810681\n",
      "Validation Loss: 1.492728400529391\n",
      "Train Loss: 1.3006502779320157\n",
      "Validation Loss: 1.4837762438283493\n",
      "Train Loss: 1.293311817716338\n",
      "Validation Loss: 1.474897294697268\n",
      "Train Loss: 1.2860446308418865\n",
      "Validation Loss: 1.4660921559135187\n",
      "Train Loss: 1.2788480048898387\n",
      "Validation Loss: 1.4573612438578762\n",
      "Train Loss: 1.2717212390790165\n",
      "Validation Loss: 1.448704807994335\n",
      "Train Loss: 1.2646636435383596\n",
      "Validation Loss: 1.440122957473938\n",
      "Train Loss: 1.2576745346360292\n",
      "Validation Loss: 1.4316156785163177\n",
      "Train Loss: 1.2507532463802031\n",
      "Validation Loss: 1.4231828640628739\n",
      "Train Loss: 1.2438991109019366\n",
      "Validation Loss: 1.4148243106004432\n",
      "Train Loss: 1.237111476295086\n",
      "Validation Loss: 1.406539754536144\n",
      "Train Loss: 1.2303896944827502\n",
      "Validation Loss: 1.3983288638077094\n",
      "Train Loss: 1.2237331231903177\n",
      "Validation Loss: 1.390191256076931\n",
      "Train Loss: 1.217141129912346\n",
      "Validation Loss: 1.3821265070933788\n",
      "Train Loss: 1.2106130882451214\n",
      "Validation Loss: 1.374134165463561\n",
      "Train Loss: 1.2041483750253181\n",
      "Validation Loss: 1.3662137401593943\n",
      "Train Loss: 1.1977463742060168\n",
      "Validation Loss: 1.3583647182275598\n",
      "Train Loss: 1.1914064808300815\n",
      "Validation Loss: 1.350586572822798\n",
      "Train Loss: 1.1851280888982492\n",
      "Validation Loss: 1.3428787562174482\n",
      "Train Loss: 1.1789106027933622\n",
      "Validation Loss: 1.3352407118494394\n",
      "Train Loss: 1.1727534312459467\n",
      "Validation Loss: 1.3276718656235817\n",
      "Train Loss: 1.1666559905402418\n",
      "Validation Loss: 1.320171646724353\n",
      "Train Loss: 1.1606176999001647\n",
      "Validation Loss: 1.3127394729546922\n",
      "Train Loss: 1.1546379854806443\n",
      "Validation Loss: 1.3053747585716502\n",
      "Train Loss: 1.148716279601225\n",
      "Validation Loss: 1.298076916704222\n",
      "Train Loss: 1.142852018911819\n",
      "Validation Loss: 1.2908453584178023\n",
      "Train Loss: 1.1370446462077934\n",
      "Validation Loss: 1.2836794948449135\n",
      "Train Loss: 1.131293609446363\n",
      "Validation Loss: 1.2765787361486376\n",
      "Train Loss: 1.125598363022489\n",
      "Validation Loss: 1.2695424982567443\n",
      "Train Loss: 1.1199583637410884\n",
      "Validation Loss: 1.26257019415266\n",
      "Train Loss: 1.1143730764120958\n",
      "Validation Loss: 1.2556612423552012\n",
      "Train Loss: 1.1088419719404468\n",
      "Validation Loss: 1.2488150647962972\n",
      "Train Loss: 1.1033645230317604\n",
      "Validation Loss: 1.2420310850863685\n",
      "Train Loss: 1.097940209158982\n",
      "Validation Loss: 1.2353087289961981\n",
      "Train Loss: 1.0925685160691125\n",
      "Validation Loss: 1.2286474301354264\n",
      "Train Loss: 1.0872489328287662\n",
      "Validation Loss: 1.222046623508666\n",
      "Train Loss: 1.081980952773978\n",
      "Validation Loss: 1.2155057476427333\n",
      "Train Loss: 1.0767640770470623\n",
      "Validation Loss: 1.209024249647203\n",
      "Train Loss: 1.071597808174951\n",
      "Validation Loss: 1.2026015748534458\n",
      "Train Loss: 1.066481657325962\n",
      "Validation Loss: 1.1962371791803827\n",
      "Train Loss: 1.0614151362870918\n",
      "Validation Loss: 1.1899305179632567\n",
      "Train Loss: 1.056397765137557\n",
      "Validation Loss: 1.1836810536907632\n",
      "Train Loss: 1.0514290664711787\n",
      "Validation Loss: 1.1774882534974531\n",
      "Train Loss: 1.0465085686395812\n",
      "Validation Loss: 1.1713515908211092\n",
      "Train Loss: 1.0416358029275379\n",
      "Validation Loss: 1.165270539161848\n",
      "Train Loss: 1.0368103072824337\n",
      "Validation Loss: 1.1592445813995622\n",
      "Train Loss: 1.0320316226588435\n",
      "Validation Loss: 1.1532732025949515\n",
      "Train Loss: 1.0272992948984503\n",
      "Validation Loss: 1.1473558951524023\n",
      "Train Loss: 1.0226128742321656\n",
      "Validation Loss: 1.1414921522380497\n",
      "Train Loss: 1.017971915685096\n",
      "Validation Loss: 1.135681474271414\n",
      "Train Loss: 1.0133759780606888\n",
      "Validation Loss: 1.1299233657558196\n",
      "Train Loss: 1.0088246246552914\n",
      "Validation Loss: 1.124217335105052\n",
      "Train Loss: 1.004317422622915\n",
      "Validation Loss: 1.1185628969031625\n",
      "Train Loss: 0.9998539442677317\n",
      "Validation Loss: 1.1129595694107628\n",
      "Train Loss: 0.9954337647926366\n",
      "Validation Loss: 1.1074068749708892\n",
      "Train Loss: 0.9910564653777367\n",
      "Validation Loss: 1.1019043420523271\n",
      "Train Loss: 0.9867216287991696\n",
      "Validation Loss: 1.0964515012176244\n",
      "Train Loss: 0.9824288436584062\n",
      "Validation Loss: 1.0910478880081538\n",
      "Train Loss: 0.9781777014739886\n",
      "Validation Loss: 1.08569304403266\n",
      "Train Loss: 0.9739677989178229\n",
      "Validation Loss: 1.0803865126666026\n",
      "Train Loss: 0.9697987351952015\n",
      "Validation Loss: 1.0751278438881302\n",
      "Train Loss: 0.9656701147600143\n",
      "Validation Loss: 1.0699165920078184\n",
      "Train Loss: 0.9615815457029756\n",
      "Validation Loss: 1.064752313834893\n",
      "Train Loss: 0.9575326388119072\n",
      "Validation Loss: 1.0596345710056208\n",
      "Train Loss: 0.9535230096498835\n",
      "Validation Loss: 1.054562929454954\n",
      "Train Loss: 0.9495522767325248\n",
      "Validation Loss: 1.049536959262536\n",
      "Train Loss: 0.945620063234322\n",
      "Validation Loss: 1.0445562342018189\n",
      "Epoch: 10000, Train Loss: 0.95, Validation Loss: 1.04\n",
      "=====================================\n",
      "Train Loss: 0.9417259949439412\n",
      "Validation Loss: 1.0396203332489562\n",
      "Train Loss: 0.9378697018258129\n",
      "Validation Loss: 1.0347288380409965\n",
      "Train Loss: 0.934050818854142\n",
      "Validation Loss: 1.0298813357789163\n",
      "Train Loss: 0.930268982301739\n",
      "Validation Loss: 1.025077415902813\n",
      "Train Loss: 0.926523831977879\n",
      "Validation Loss: 1.0203166726661044\n",
      "Train Loss: 0.9228150128016055\n",
      "Validation Loss: 1.0155987036141911\n",
      "Train Loss: 0.9191421720358839\n",
      "Validation Loss: 1.0109231097426539\n",
      "Train Loss: 0.9155049607386275\n",
      "Validation Loss: 1.0062894971676601\n",
      "Train Loss: 0.9119030325707531\n",
      "Validation Loss: 1.0016974747927252\n",
      "Train Loss: 0.9083360462096575\n",
      "Validation Loss: 0.9971466556881098\n",
      "Train Loss: 0.9048036622123143\n",
      "Validation Loss: 0.9926366558339398\n",
      "Train Loss: 0.901305545518131\n",
      "Validation Loss: 0.9881670970134739\n",
      "Train Loss: 0.8978413634566391\n",
      "Validation Loss: 0.9837376021471523\n",
      "Train Loss: 0.8944107868946569\n",
      "Validation Loss: 0.9793477980460324\n",
      "Train Loss: 0.8910134885676454\n",
      "Validation Loss: 0.9749973153498769\n",
      "Train Loss: 0.8876491477620493\n",
      "Validation Loss: 0.9706857906796954\n",
      "Train Loss: 0.8843174433325508\n",
      "Validation Loss: 0.9664128599414273\n",
      "Train Loss: 0.8810180589276078\n",
      "Validation Loss: 0.9621781639335877\n",
      "Train Loss: 0.877750682041117\n",
      "Validation Loss: 0.9579813495795523\n",
      "Train Loss: 0.8745150006906901\n",
      "Validation Loss: 0.9538220632613786\n",
      "Train Loss: 0.8713107070206915\n",
      "Validation Loss: 0.9496999573391165\n",
      "Train Loss: 0.868137497900114\n",
      "Validation Loss: 0.9456146852937231\n",
      "Train Loss: 0.8649950713428799\n",
      "Validation Loss: 0.9415659059025828\n",
      "Train Loss: 0.8618831301392204\n",
      "Validation Loss: 0.93755328098946\n",
      "Train Loss: 0.8588013764819995\n",
      "Validation Loss: 0.9335764751538753\n",
      "Train Loss: 0.8557495181210936\n",
      "Validation Loss: 0.9296351542024267\n",
      "Train Loss: 0.8527272655232715\n",
      "Validation Loss: 0.9257289905889065\n",
      "Train Loss: 0.8497343312214918\n",
      "Validation Loss: 0.92185765804884\n",
      "Train Loss: 0.8467704307928959\n",
      "Validation Loss: 0.9180208327530194\n",
      "Train Loss: 0.8438352820822499\n",
      "Validation Loss: 0.9142181960548713\n",
      "Train Loss: 0.8409286070554981\n",
      "Validation Loss: 0.9104494302714318\n",
      "Train Loss: 0.8380501285594307\n",
      "Validation Loss: 0.9067142208256634\n",
      "Train Loss: 0.8351995740039927\n",
      "Validation Loss: 0.9030122573708499\n",
      "Train Loss: 0.8323766715895489\n",
      "Validation Loss: 0.8993432316402663\n",
      "Train Loss: 0.8295811533744764\n",
      "Validation Loss: 0.8957068387769078\n",
      "Train Loss: 0.8268127543549306\n",
      "Validation Loss: 0.8921027776190912\n",
      "Train Loss: 0.8240712113711404\n",
      "Validation Loss: 0.8885307476136084\n",
      "Train Loss: 0.8213562627278802\n",
      "Validation Loss: 0.884990452424626\n",
      "Train Loss: 0.8186676519267722\n",
      "Validation Loss: 0.8814815989214272\n",
      "Train Loss: 0.816005122254747\n",
      "Validation Loss: 0.8780038953153547\n",
      "Train Loss: 0.8133684210811183\n",
      "Validation Loss: 0.8745570548620392\n",
      "Train Loss: 0.8107572986767031\n",
      "Validation Loss: 0.8711407913494187\n",
      "Train Loss: 0.8081715057785008\n",
      "Validation Loss: 0.8677548220412404\n",
      "Train Loss: 0.8056107966712388\n",
      "Validation Loss: 0.8643988663935944\n",
      "Train Loss: 0.8030749292475744\n",
      "Validation Loss: 0.8610726479233968\n",
      "Train Loss: 0.800563661712093\n",
      "Validation Loss: 0.8577758916477266\n",
      "Train Loss: 0.7980767554557977\n",
      "Validation Loss: 0.8545083248139249\n",
      "Train Loss: 0.7956139742779869\n",
      "Validation Loss: 0.8512696786451578\n",
      "Train Loss: 0.7931750833883034\n",
      "Validation Loss: 0.8480596858272628\n",
      "Train Loss: 0.7907598519426093\n",
      "Validation Loss: 0.8448780813126424\n",
      "Train Loss: 0.7883680502700646\n",
      "Validation Loss: 0.841724603013738\n",
      "Train Loss: 0.7859994507331411\n",
      "Validation Loss: 0.8385989923685927\n",
      "Train Loss: 0.7836538278462647\n",
      "Validation Loss: 0.8355009918446806\n",
      "Train Loss: 0.7813309597112604\n",
      "Validation Loss: 0.8324303466575088\n",
      "Train Loss: 0.7790306255152524\n",
      "Validation Loss: 0.8293868044336448\n",
      "Train Loss: 0.7767526060869816\n",
      "Validation Loss: 0.8263701154242326\n",
      "Train Loss: 0.7744966855057768\n",
      "Validation Loss: 0.8233800326731426\n",
      "Train Loss: 0.7722626488503422\n",
      "Validation Loss: 0.8204163106525942\n",
      "Train Loss: 0.7700502846327799\n",
      "Validation Loss: 0.8174787059903443\n",
      "Train Loss: 0.7678593816630604\n",
      "Validation Loss: 0.8145669789475776\n",
      "Train Loss: 0.7656897322961193\n",
      "Validation Loss: 0.8116808899127285\n",
      "Train Loss: 0.7635411305427041\n",
      "Validation Loss: 0.8088202040903477\n",
      "Train Loss: 0.7614133712771824\n",
      "Validation Loss: 0.8059846866532491\n",
      "Train Loss: 0.7593062535958134\n",
      "Validation Loss: 0.803174107192753\n",
      "Train Loss: 0.7572195766843052\n",
      "Validation Loss: 0.8003882360776446\n",
      "Train Loss: 0.7551531417158553\n",
      "Validation Loss: 0.7976268458569995\n",
      "Train Loss: 0.7531067528505805\n",
      "Validation Loss: 0.7948897111755302\n",
      "Train Loss: 0.7510802151415609\n",
      "Validation Loss: 0.7921766084174309\n",
      "Train Loss: 0.7490733369261637\n",
      "Validation Loss: 0.7894873177127026\n",
      "Train Loss: 0.7470859268643925\n",
      "Validation Loss: 0.7868216202423198\n",
      "Train Loss: 0.7451177960043273\n",
      "Validation Loss: 0.784179299006721\n",
      "Train Loss: 0.7431687580427719\n",
      "Validation Loss: 0.7815601395749303\n",
      "Train Loss: 0.7412386269744936\n",
      "Validation Loss: 0.778963928538475\n",
      "Train Loss: 0.7393272202306356\n",
      "Validation Loss: 0.7763904564310531\n",
      "Train Loss: 0.7374343551860831\n",
      "Validation Loss: 0.7738395131084256\n",
      "Train Loss: 0.7355598521321776\n",
      "Validation Loss: 0.7713108925953499\n",
      "Train Loss: 0.7337035338087984\n",
      "Validation Loss: 0.7688043895712551\n",
      "Train Loss: 0.7318652228519136\n",
      "Validation Loss: 0.7663198022031735\n",
      "Train Loss: 0.7300447448210746\n",
      "Validation Loss: 0.7638569294642833\n",
      "Train Loss: 0.728241927222132\n",
      "Validation Loss: 0.7614155716577256\n",
      "Train Loss: 0.7264565986496434\n",
      "Validation Loss: 0.7589955327405451\n",
      "Train Loss: 0.7246885885113352\n",
      "Validation Loss: 0.7565966149513669\n",
      "Train Loss: 0.7229377295792169\n",
      "Validation Loss: 0.7542186269291712\n",
      "Train Loss: 0.7212038554904393\n",
      "Validation Loss: 0.7518613773390703\n",
      "Train Loss: 0.7194868012509559\n",
      "Validation Loss: 0.749524675488312\n",
      "Train Loss: 0.7177864037917405\n",
      "Validation Loss: 0.7472083332559415\n",
      "Train Loss: 0.7161025012034963\n",
      "Validation Loss: 0.7449121641638575\n",
      "Train Loss: 0.7144349341665722\n",
      "Validation Loss: 0.742635984282571\n",
      "Train Loss: 0.7127835437270803\n",
      "Validation Loss: 0.7403796099503235\n",
      "Train Loss: 0.7111481730636149\n",
      "Validation Loss: 0.7381428607467296\n",
      "Train Loss: 0.709528667150393\n",
      "Validation Loss: 0.7359255578429513\n",
      "Train Loss: 0.7079248713085714\n",
      "Validation Loss: 0.7337275226546359\n",
      "Train Loss: 0.7063366336254733\n",
      "Validation Loss: 0.7315485797893833\n",
      "Train Loss: 0.7047638030173\n",
      "Validation Loss: 0.7293885551009335\n",
      "Train Loss: 0.7032062303147545\n",
      "Validation Loss: 0.7272472749596638\n",
      "Train Loss: 0.7016637674831152\n",
      "Validation Loss: 0.7251245690029319\n",
      "Train Loss: 0.7001362674890739\n",
      "Validation Loss: 0.723020267503088\n",
      "Train Loss: 0.6986235854082241\n",
      "Validation Loss: 0.7209342015004879\n",
      "Train Loss: 0.6971255772258137\n",
      "Validation Loss: 0.7188662058390954\n",
      "Train Loss: 0.6956421009581132\n",
      "Validation Loss: 0.7168161152242505\n",
      "Epoch: 10000, Train Loss: 0.70, Validation Loss: 0.72\n",
      "=====================================\n",
      "Train Loss: 0.6941730159076683\n",
      "Validation Loss: 0.7147837673996419\n",
      "Train Loss: 0.6927181818379708\n",
      "Validation Loss: 0.7127689996864777\n",
      "Train Loss: 0.6912774610856602\n",
      "Validation Loss: 0.7107716523936884\n",
      "Train Loss: 0.6898507165084538\n",
      "Validation Loss: 0.7087915671124948\n",
      "Train Loss: 0.6884378125450485\n",
      "Validation Loss: 0.7068285863949851\n",
      "Train Loss: 0.6870386148065513\n",
      "Validation Loss: 0.7048825544717393\n",
      "Train Loss: 0.6856529902520956\n",
      "Validation Loss: 0.7029533166598934\n",
      "Train Loss: 0.684280807419588\n",
      "Validation Loss: 0.7010407200555802\n",
      "Train Loss: 0.6829219358399027\n",
      "Validation Loss: 0.6991446148256985\n",
      "Train Loss: 0.6815762462553313\n",
      "Validation Loss: 0.6972648500451574\n",
      "Train Loss: 0.6802436109488197\n",
      "Validation Loss: 0.6954012765294583\n",
      "Train Loss: 0.6789239035656683\n",
      "Validation Loss: 0.6935537478193482\n",
      "Train Loss: 0.6776169979495149\n",
      "Validation Loss: 0.6917221175334033\n",
      "Train Loss: 0.6763227703465526\n",
      "Validation Loss: 0.6899062424960689\n",
      "Train Loss: 0.675041097579139\n",
      "Validation Loss: 0.688105979280441\n",
      "Train Loss: 0.6737718587698446\n",
      "Validation Loss: 0.6863211863524085\n",
      "Train Loss: 0.6725149321911396\n",
      "Validation Loss: 0.684551722159844\n",
      "Train Loss: 0.6712701988846268\n",
      "Validation Loss: 0.6827974488209579\n",
      "Train Loss: 0.6700375404358957\n",
      "Validation Loss: 0.6810582281722288\n",
      "Train Loss: 0.6688168400519549\n",
      "Validation Loss: 0.6793339235105255\n",
      "Train Loss: 0.6676079811652387\n",
      "Validation Loss: 0.6776243998395062\n",
      "Train Loss: 0.6664108492302717\n",
      "Validation Loss: 0.6759295241206226\n",
      "Train Loss: 0.6652253303702298\n",
      "Validation Loss: 0.6742491620134135\n",
      "Train Loss: 0.6640513116384975\n",
      "Validation Loss: 0.6725831837350106\n",
      "Train Loss: 0.6628886821007218\n",
      "Validation Loss: 0.6709314579088205\n",
      "Train Loss: 0.6617373308640896\n",
      "Validation Loss: 0.6692938558163617\n",
      "Train Loss: 0.6605971487611287\n",
      "Validation Loss: 0.6676702499496959\n",
      "Train Loss: 0.6594680273286079\n",
      "Validation Loss: 0.6660605131340758\n",
      "Train Loss: 0.6583498592464416\n",
      "Validation Loss: 0.6644645198645412\n",
      "Train Loss: 0.6572425383440152\n",
      "Validation Loss: 0.6628821467048641\n",
      "Train Loss: 0.6561459591343877\n",
      "Validation Loss: 0.661313270527283\n",
      "Train Loss: 0.6550600174098825\n",
      "Validation Loss: 0.6597577692640573\n",
      "Train Loss: 0.6539846104244587\n",
      "Validation Loss: 0.6582155221426805\n",
      "Train Loss: 0.6529196357452751\n",
      "Validation Loss: 0.6566864094134395\n",
      "Train Loss: 0.6518649919910576\n",
      "Validation Loss: 0.6551703121072441\n",
      "Train Loss: 0.650820579264432\n",
      "Validation Loss: 0.6536671137506955\n",
      "Train Loss: 0.6497862980905267\n",
      "Validation Loss: 0.6521766974736986\n",
      "Train Loss: 0.6487620502113007\n",
      "Validation Loss: 0.6506989474046379\n",
      "Train Loss: 0.6477477384651018\n",
      "Validation Loss: 0.6492337504577655\n",
      "Train Loss: 0.646743266271329\n",
      "Validation Loss: 0.6477809929687931\n",
      "Train Loss: 0.6457485382873613\n",
      "Validation Loss: 0.6463405634640321\n",
      "Train Loss: 0.6447634604626065\n",
      "Validation Loss: 0.6449123500295992\n",
      "Train Loss: 0.6437879382028242\n",
      "Validation Loss: 0.6434962437703\n",
      "Train Loss: 0.6428218794350009\n",
      "Validation Loss: 0.6420921349852174\n",
      "Train Loss: 0.6418651920128461\n",
      "Validation Loss: 0.6406999156617589\n",
      "Train Loss: 0.6409177851510072\n",
      "Validation Loss: 0.6393194797520612\n",
      "Train Loss: 0.6399795689526345\n",
      "Validation Loss: 0.6379507206574517\n",
      "Train Loss: 0.6390504541162055\n",
      "Validation Loss: 0.6365935327786215\n",
      "Train Loss: 0.6381303525164198\n",
      "Validation Loss: 0.6352478130193973\n",
      "Train Loss: 0.6372191765438247\n",
      "Validation Loss: 0.6339134576490311\n",
      "Train Loss: 0.6363168399446975\n",
      "Validation Loss: 0.6325903660519663\n",
      "Train Loss: 0.6354232562604072\n",
      "Validation Loss: 0.6312784364403354\n",
      "Train Loss: 0.6345383411301084\n",
      "Validation Loss: 0.6299775676637109\n",
      "Train Loss: 0.6336620105130562\n",
      "Validation Loss: 0.6286876622682813\n",
      "Train Loss: 0.6327941809861363\n",
      "Validation Loss: 0.6274086211650237\n",
      "Train Loss: 0.6319347700457216\n",
      "Validation Loss: 0.6261403470637944\n",
      "Train Loss: 0.6310836963862394\n",
      "Validation Loss: 0.6248827433150468\n",
      "Train Loss: 0.630240878544926\n",
      "Validation Loss: 0.6236357136860173\n",
      "Train Loss: 0.6294062366766408\n",
      "Validation Loss: 0.6223991650171773\n",
      "Train Loss: 0.628579691660645\n",
      "Validation Loss: 0.6211730019197965\n",
      "Train Loss: 0.6277611647947146\n",
      "Validation Loss: 0.6199571316758177\n",
      "Train Loss: 0.6269505782655606\n",
      "Validation Loss: 0.6187514637029531\n",
      "Train Loss: 0.6261478548137568\n",
      "Validation Loss: 0.6175559053569634\n",
      "Train Loss: 0.6253529184108712\n",
      "Validation Loss: 0.6163703669553116\n",
      "Train Loss: 0.6245656938107678\n",
      "Validation Loss: 0.615194758940586\n",
      "Train Loss: 0.6237861057449312\n",
      "Validation Loss: 0.6140289919667684\n",
      "Train Loss: 0.6230140804581812\n",
      "Validation Loss: 0.6128729792627102\n",
      "Train Loss: 0.6222495440911376\n",
      "Validation Loss: 0.6117266322881625\n",
      "Train Loss: 0.6214924244886981\n",
      "Validation Loss: 0.610589866453281\n",
      "Train Loss: 0.6207426493831838\n",
      "Validation Loss: 0.6094625953917127\n",
      "Train Loss: 0.6200001477823871\n",
      "Validation Loss: 0.608344734265692\n",
      "Train Loss: 0.6192648488481116\n",
      "Validation Loss: 0.607236199424362\n",
      "Train Loss: 0.6185366831321435\n",
      "Validation Loss: 0.6061369081511125\n",
      "Train Loss: 0.6178155812858259\n",
      "Validation Loss: 0.6050467777290621\n",
      "Train Loss: 0.6171014745661433\n",
      "Validation Loss: 0.603965726472333\n",
      "Train Loss: 0.6163942951666443\n",
      "Validation Loss: 0.6028936745293985\n",
      "Train Loss: 0.6156939760896716\n",
      "Validation Loss: 0.6018305407526819\n",
      "Train Loss: 0.6150004506586317\n",
      "Validation Loss: 0.6007762461410363\n",
      "Train Loss: 0.6143136528946833\n",
      "Validation Loss: 0.5997307117379143\n",
      "Train Loss: 0.6136335175805556\n",
      "Validation Loss: 0.5986938605664832\n",
      "Train Loss: 0.6129599801670692\n",
      "Validation Loss: 0.5976656152907777\n",
      "Train Loss: 0.6122929764969719\n",
      "Validation Loss: 0.5966458989640123\n",
      "Train Loss: 0.611632443284166\n",
      "Validation Loss: 0.5956346360288555\n",
      "Train Loss: 0.6109783177794312\n",
      "Validation Loss: 0.5946317515094245\n",
      "Train Loss: 0.6103305380600209\n",
      "Validation Loss: 0.5936371710280866\n",
      "Train Loss: 0.6096890420178702\n",
      "Validation Loss: 0.5926508213043914\n",
      "Train Loss: 0.6090537693516821\n",
      "Validation Loss: 0.591672628753694\n",
      "Train Loss: 0.6084246590125371\n",
      "Validation Loss: 0.590702521610914\n",
      "Train Loss: 0.6078016514914122\n",
      "Validation Loss: 0.589740428924069\n",
      "Train Loss: 0.6071846875782294\n",
      "Validation Loss: 0.5887862785526826\n",
      "Train Loss: 0.6065737087826681\n",
      "Validation Loss: 0.5878400010187492\n",
      "Train Loss: 0.605968657056548\n",
      "Validation Loss: 0.586901525849291\n",
      "Train Loss: 0.6053694748982227\n",
      "Validation Loss: 0.5859707846366367\n",
      "Train Loss: 0.6047761051346117\n",
      "Validation Loss: 0.5850477089223234\n",
      "Train Loss: 0.6041884913605229\n",
      "Validation Loss: 0.5841322307860036\n",
      "Train Loss: 0.6036065785106974\n",
      "Validation Loss: 0.583224283615828\n",
      "Train Loss: 0.6030303104382926\n",
      "Validation Loss: 0.5823238006862836\n",
      "Train Loss: 0.6024596325971555\n",
      "Validation Loss: 0.581430716202025\n",
      "Train Loss: 0.6018944906284835\n",
      "Validation Loss: 0.5805449648624303\n",
      "Train Loss: 0.6013348307539528\n",
      "Validation Loss: 0.5796664813022632\n",
      "Epoch: 10000, Train Loss: 0.60, Validation Loss: 0.58\n",
      "=====================================\n",
      "Train Loss: 0.600780600389101\n",
      "Validation Loss: 0.578795202367501\n",
      "Train Loss: 0.6002317465544446\n",
      "Validation Loss: 0.5779310646164748\n",
      "Train Loss: 0.5996882169675093\n",
      "Validation Loss: 0.5770740043433809\n",
      "Train Loss: 0.599149959944215\n",
      "Validation Loss: 0.5762239588938921\n",
      "Train Loss: 0.5986169244297292\n",
      "Validation Loss: 0.5753808677866753\n",
      "Train Loss: 0.5980890600044578\n",
      "Validation Loss: 0.5745446691217515\n",
      "Train Loss: 0.5975663162100191\n",
      "Validation Loss: 0.5737153033490997\n",
      "Train Loss: 0.5970486433330133\n",
      "Validation Loss: 0.5728927089346965\n",
      "Train Loss: 0.5965359924178725\n",
      "Validation Loss: 0.5720768270552115\n",
      "Train Loss: 0.5960283147866031\n",
      "Validation Loss: 0.5712675991491906\n",
      "Train Loss: 0.595525561621138\n",
      "Validation Loss: 0.5704649659904627\n",
      "Train Loss: 0.5950276858589317\n",
      "Validation Loss: 0.5696688702696454\n",
      "Train Loss: 0.5945346397940492\n",
      "Validation Loss: 0.5688792547626689\n",
      "Train Loss: 0.5940463763729619\n",
      "Validation Loss: 0.5680960623043192\n",
      "Train Loss: 0.5935628495957901\n",
      "Validation Loss: 0.5673192366995727\n",
      "Train Loss: 0.5930840135852435\n",
      "Validation Loss: 0.5665487218125995\n",
      "Train Loss: 0.592609822637775\n",
      "Validation Loss: 0.5657844630587363\n",
      "Train Loss: 0.5921402315241036\n",
      "Validation Loss: 0.5650264049655399\n",
      "Train Loss: 0.5916751959334818\n",
      "Validation Loss: 0.5642744935670965\n",
      "Train Loss: 0.5912146716694118\n",
      "Validation Loss: 0.5635286749462035\n",
      "Train Loss: 0.5907586145709799\n",
      "Validation Loss: 0.5627888965426865\n",
      "Train Loss: 0.5903069816737329\n",
      "Validation Loss: 0.5620551048497251\n",
      "Train Loss: 0.5898597298869152\n",
      "Validation Loss: 0.5613272467911647\n",
      "Train Loss: 0.589416816926152\n",
      "Validation Loss: 0.5606052720650013\n",
      "Train Loss: 0.5889782005657994\n",
      "Validation Loss: 0.5598891289258887\n",
      "Train Loss: 0.5885438389746217\n",
      "Validation Loss: 0.5591787671253986\n",
      "Train Loss: 0.5881136910776641\n",
      "Validation Loss: 0.5584741341790489\n",
      "Train Loss: 0.5876877159304807\n",
      "Validation Loss: 0.5577751826182783\n",
      "Train Loss: 0.5872658730735456\n",
      "Validation Loss: 0.5570818620125353\n",
      "Train Loss: 0.586848122525478\n",
      "Validation Loss: 0.5563941228458883\n",
      "Train Loss: 0.5864344245429811\n",
      "Validation Loss: 0.5557119165340022\n",
      "Train Loss: 0.586024739609933\n",
      "Validation Loss: 0.5550351950546086\n",
      "Train Loss: 0.5856190290125806\n",
      "Validation Loss: 0.554363910697496\n",
      "Train Loss: 0.5852172541546817\n",
      "Validation Loss: 0.553698016866191\n",
      "Train Loss: 0.5848193769658462\n",
      "Validation Loss: 0.5530374661933389\n",
      "Train Loss: 0.584425359371137\n",
      "Validation Loss: 0.5523822122540708\n",
      "Train Loss: 0.5840351639797354\n",
      "Validation Loss: 0.5517322094781494\n",
      "Train Loss: 0.5836487539125602\n",
      "Validation Loss: 0.5510874115143061\n",
      "Train Loss: 0.5832660922041458\n",
      "Validation Loss: 0.550447774234967\n",
      "Train Loss: 0.5828871427085284\n",
      "Validation Loss: 0.5498132517702986\n",
      "Train Loss: 0.5825118693182376\n",
      "Validation Loss: 0.5491838009967277\n",
      "Train Loss: 0.5821402362871717\n",
      "Validation Loss: 0.5485593771065097\n",
      "Train Loss: 0.5817722085317217\n",
      "Validation Loss: 0.5479399364787955\n",
      "Train Loss: 0.581407750865478\n",
      "Validation Loss: 0.5473254373348597\n",
      "Train Loss: 0.5810468287689806\n",
      "Validation Loss: 0.5467158356104759\n",
      "Train Loss: 0.5806894079522861\n",
      "Validation Loss: 0.5461110892086427\n",
      "Train Loss: 0.5803354543032997\n",
      "Validation Loss: 0.5455111561855835\n",
      "Train Loss: 0.579984934320041\n",
      "Validation Loss: 0.5449159946736658\n",
      "Train Loss: 0.5796378145995387\n",
      "Validation Loss: 0.5443255642352351\n",
      "Train Loss: 0.5792940623190647\n",
      "Validation Loss: 0.5437398237769144\n",
      "Train Loss: 0.5789536446191741\n",
      "Validation Loss: 0.5431587327492443\n",
      "Train Loss: 0.5786165292342367\n",
      "Validation Loss: 0.5425822506638819\n",
      "Train Loss: 0.5782826842017972\n",
      "Validation Loss: 0.5420103384081177\n",
      "Train Loss: 0.5779520777106758\n",
      "Validation Loss: 0.5414429566445087\n",
      "Train Loss: 0.5776246784197128\n",
      "Validation Loss: 0.5408800659258802\n",
      "Train Loss: 0.5773004551740546\n",
      "Validation Loss: 0.5403216280128966\n",
      "Train Loss: 0.5769793769662525\n",
      "Validation Loss: 0.5397676044380574\n",
      "Train Loss: 0.5766614134655814\n",
      "Validation Loss: 0.5392179569275706\n",
      "Train Loss: 0.5763465344216337\n",
      "Validation Loss: 0.5386726486063592\n",
      "Train Loss: 0.5760347101131569\n",
      "Validation Loss: 0.5381316415536972\n",
      "Train Loss: 0.5757259107025356\n",
      "Validation Loss: 0.5375948996482764\n",
      "Train Loss: 0.5754201069730199\n",
      "Validation Loss: 0.5370623855169969\n",
      "Train Loss: 0.5751172697637242\n",
      "Validation Loss: 0.536534062464011\n",
      "Train Loss: 0.5748173702098275\n",
      "Validation Loss: 0.5360098958428866\n",
      "Train Loss: 0.5745203799297912\n",
      "Validation Loss: 0.535489848880792\n",
      "Train Loss: 0.5742262706403846\n",
      "Validation Loss: 0.5349738872528994\n",
      "Train Loss: 0.5739350145712625\n",
      "Validation Loss: 0.5344619759247199\n",
      "Train Loss: 0.5736465838695021\n",
      "Validation Loss: 0.5339540793115103\n",
      "Train Loss: 0.5733609511707687\n",
      "Validation Loss: 0.5334501641594992\n",
      "Train Loss: 0.5730780893062488\n",
      "Validation Loss: 0.5329501960474383\n",
      "Train Loss: 0.5727979714393414\n",
      "Validation Loss: 0.5324541409541542\n",
      "Train Loss: 0.5725205707963238\n",
      "Validation Loss: 0.5319619662235229\n",
      "Train Loss: 0.5722458612697022\n",
      "Validation Loss: 0.5314736377109935\n",
      "Train Loss: 0.5719738167353667\n",
      "Validation Loss: 0.5309891235420718\n",
      "Train Loss: 0.5717044111745544\n",
      "Validation Loss: 0.5305083912285927\n",
      "Train Loss: 0.5714376189708326\n",
      "Validation Loss: 0.5300314081106845\n",
      "Train Loss: 0.5711734150110965\n",
      "Validation Loss: 0.5295581418504965\n",
      "Train Loss: 0.5709117740466633\n",
      "Validation Loss: 0.5290885615188112\n",
      "Train Loss: 0.5706526710274851\n",
      "Validation Loss: 0.5286226357150636\n",
      "Train Loss: 0.5703960815756421\n",
      "Validation Loss: 0.5281603329379916\n",
      "Train Loss: 0.5701419813427451\n",
      "Validation Loss: 0.5277016223247075\n",
      "Train Loss: 0.5698903460127918\n",
      "Validation Loss: 0.5272464736511792\n",
      "Train Loss: 0.56964115175549\n",
      "Validation Loss: 0.5267948569952479\n",
      "Train Loss: 0.5693943748303335\n",
      "Validation Loss: 0.5263467418106957\n",
      "Train Loss: 0.5691499919134443\n",
      "Validation Loss: 0.525902099104207\n",
      "Train Loss: 0.5689079797585559\n",
      "Validation Loss: 0.5254608989050559\n",
      "Train Loss: 0.5686683152490848\n",
      "Validation Loss: 0.5250231123647439\n",
      "Train Loss: 0.568430975635396\n",
      "Validation Loss: 0.5245887104303887\n",
      "Train Loss: 0.5681959384451332\n",
      "Validation Loss: 0.5241576640500414\n",
      "Train Loss: 0.5679631811447822\n",
      "Validation Loss: 0.5237299450060786\n",
      "Train Loss: 0.5677326818443408\n",
      "Validation Loss: 0.5233055256355024\n",
      "Train Loss: 0.5675044186468396\n",
      "Validation Loss: 0.5228843778494977\n",
      "Train Loss: 0.5672783697588029\n",
      "Validation Loss: 0.5224664739708934\n",
      "Train Loss: 0.5670545137536744\n",
      "Validation Loss: 0.5220517867989396\n",
      "Train Loss: 0.5668328293702346\n",
      "Validation Loss: 0.5216402886354208\n",
      "Train Loss: 0.5666132953893402\n",
      "Validation Loss: 0.5212319534395204\n",
      "Train Loss: 0.5663958911626017\n",
      "Validation Loss: 0.5208267536202732\n",
      "Train Loss: 0.566180595835971\n",
      "Validation Loss: 0.5204246638687028\n",
      "Train Loss: 0.5659673889514496\n",
      "Validation Loss: 0.5200256573965764\n",
      "Train Loss: 0.5657562505677569\n",
      "Validation Loss: 0.5196297077991184\n",
      "Epoch: 10000, Train Loss: 0.57, Validation Loss: 0.52\n",
      "=====================================\n",
      "Train Loss: 0.5655471603460394\n",
      "Validation Loss: 0.5192367899860373\n",
      "Train Loss: 0.5653400983681391\n",
      "Validation Loss: 0.5188468787660125\n",
      "Train Loss: 0.5651350450351933\n",
      "Validation Loss: 0.5184599483630401\n",
      "Train Loss: 0.5649319810155848\n",
      "Validation Loss: 0.5180759740046267\n",
      "Train Loss: 0.564730886883619\n",
      "Validation Loss: 0.5176949306967669\n",
      "Train Loss: 0.5645317433877898\n",
      "Validation Loss: 0.5173167939697846\n",
      "Train Loss: 0.5643345318425684\n",
      "Validation Loss: 0.516941539159038\n",
      "Train Loss: 0.5641392333198243\n",
      "Validation Loss: 0.5165691421453479\n",
      "Train Loss: 0.5639458293900292\n",
      "Validation Loss: 0.5161995795085441\n",
      "Train Loss: 0.5637543016043549\n",
      "Validation Loss: 0.5158328273919418\n",
      "Train Loss: 0.5635646318302667\n",
      "Validation Loss: 0.5154688620267556\n",
      "Train Loss: 0.5633768020208281\n",
      "Validation Loss: 0.5151076603669646\n",
      "Train Loss: 0.5631907942078686\n",
      "Validation Loss: 0.5147491997454292\n",
      "Train Loss: 0.5630065909498262\n",
      "Validation Loss: 0.5143934565934618\n",
      "Train Loss: 0.5628241744985767\n",
      "Validation Loss: 0.5140404084422955\n",
      "Train Loss: 0.5626435276504007\n",
      "Validation Loss: 0.5136900329442322\n",
      "Train Loss: 0.5624646332656842\n",
      "Validation Loss: 0.5133423077811983\n",
      "Train Loss: 0.5622874742698868\n",
      "Validation Loss: 0.5129972106656977\n",
      "Train Loss: 0.5621120338942655\n",
      "Validation Loss: 0.5126547197219457\n",
      "Train Loss: 0.5619382953599851\n",
      "Validation Loss: 0.5123148133161151\n",
      "Train Loss: 0.5617662422694515\n",
      "Validation Loss: 0.5119774703472857\n",
      "Train Loss: 0.5615958581985975\n",
      "Validation Loss: 0.5116426692724733\n",
      "Train Loss: 0.5614271270205339\n",
      "Validation Loss: 0.5113103889512813\n",
      "Train Loss: 0.5612600326667487\n",
      "Validation Loss: 0.510980608266665\n",
      "Train Loss: 0.56109455921968\n",
      "Validation Loss: 0.5106533069293258\n",
      "Train Loss: 0.5609306909608103\n",
      "Validation Loss: 0.5103284642410424\n",
      "Train Loss: 0.5607684123051697\n",
      "Validation Loss: 0.5100060596486152\n",
      "Train Loss: 0.5606077079534001\n",
      "Validation Loss: 0.5096860729892067\n",
      "Train Loss: 0.560448562589478\n",
      "Validation Loss: 0.5093684843329679\n",
      "Train Loss: 0.5602909610280448\n",
      "Validation Loss: 0.5090532738911853\n",
      "Train Loss: 0.56013488835747\n",
      "Validation Loss: 0.5087404219211406\n",
      "Train Loss: 0.5599803295056157\n",
      "Validation Loss: 0.508429909006519\n",
      "Train Loss: 0.5598272701081358\n",
      "Validation Loss: 0.5081217158282025\n",
      "Train Loss: 0.5596756956288068\n",
      "Validation Loss: 0.5078158230510057\n",
      "Train Loss: 0.5595255915269862\n",
      "Validation Loss: 0.5075122122448731\n",
      "Train Loss: 0.5593769434407828\n",
      "Validation Loss: 0.5072108642222082\n",
      "Train Loss: 0.5592297374243067\n",
      "Validation Loss: 0.5069117604083008\n",
      "Train Loss: 0.5590839594362536\n",
      "Validation Loss: 0.5066148823338699\n",
      "Train Loss: 0.5589395955552373\n",
      "Validation Loss: 0.5063202116592773\n",
      "Train Loss: 0.5587966321954021\n",
      "Validation Loss: 0.5060277305296231\n",
      "Train Loss: 0.5586550556695287\n",
      "Validation Loss: 0.5057374208585669\n",
      "Train Loss: 0.5585148525378613\n",
      "Validation Loss: 0.505449264250974\n",
      "Train Loss: 0.5583760094939622\n",
      "Validation Loss: 0.505163243443424\n",
      "Train Loss: 0.5582385133506954\n",
      "Validation Loss: 0.5048793416293954\n",
      "Train Loss: 0.5581023510652686\n",
      "Validation Loss: 0.5045975402278747\n",
      "Train Loss: 0.5579675096032568\n",
      "Validation Loss: 0.5043178225573112\n",
      "Train Loss: 0.5578339761626674\n",
      "Validation Loss: 0.5040401712836808\n",
      "Train Loss: 0.5577017381952434\n",
      "Validation Loss: 0.5037645697575253\n",
      "Train Loss: 0.5575707829878602\n",
      "Validation Loss: 0.5034910013158788\n",
      "Train Loss: 0.557441098205727\n",
      "Validation Loss: 0.5032194495399485\n",
      "Train Loss: 0.5573126713503355\n",
      "Validation Loss: 0.5029498979982248\n",
      "Train Loss: 0.5571854904150914\n",
      "Validation Loss: 0.5026823297269041\n",
      "Train Loss: 0.5570595431852329\n",
      "Validation Loss: 0.5024167289701068\n",
      "Train Loss: 0.556934817741249\n",
      "Validation Loss: 0.5021530797589301\n",
      "Train Loss: 0.5568113023314794\n",
      "Validation Loss: 0.5018913663471042\n",
      "Train Loss: 0.5566889850908063\n",
      "Validation Loss: 0.5016315720903909\n",
      "Train Loss: 0.5565678544191107\n",
      "Validation Loss: 0.5013736823458879\n",
      "Train Loss: 0.5564478987907913\n",
      "Validation Loss: 0.5011176812449835\n",
      "Train Loss: 0.5563291068500752\n",
      "Validation Loss: 0.500863553470523\n",
      "Train Loss: 0.5562114672122449\n",
      "Validation Loss: 0.5006112839182885\n",
      "Train Loss: 0.556094968774052\n",
      "Validation Loss: 0.5003608572595287\n",
      "Train Loss: 0.5559796005374926\n",
      "Validation Loss: 0.5001122589312899\n",
      "Train Loss: 0.5558653513979407\n",
      "Validation Loss: 0.49986547380674745\n",
      "Train Loss: 0.555752210545039\n",
      "Validation Loss: 0.49962048752564053\n",
      "Train Loss: 0.5556401673064189\n",
      "Validation Loss: 0.49937728494259553\n",
      "Train Loss: 0.5555292109375255\n",
      "Validation Loss: 0.4991358523370743\n",
      "Train Loss: 0.5554193309531427\n",
      "Validation Loss: 0.4988961750916233\n",
      "Train Loss: 0.555310516904944\n",
      "Validation Loss: 0.498658239237751\n",
      "Train Loss: 0.5552027584165445\n",
      "Validation Loss: 0.4984220299113004\n",
      "Train Loss: 0.5550960452962025\n",
      "Validation Loss: 0.4981875344358668\n",
      "Train Loss: 0.5549903674047287\n",
      "Validation Loss: 0.4979547382452874\n",
      "Train Loss: 0.5548857146440609\n",
      "Validation Loss: 0.4977236277501837\n",
      "Train Loss: 0.5547820771199004\n",
      "Validation Loss: 0.49749418933969564\n",
      "Train Loss: 0.5546794448436153\n",
      "Validation Loss: 0.4972664095016281\n",
      "Train Loss: 0.5545778082116983\n",
      "Validation Loss: 0.4970402750221586\n",
      "Train Loss: 0.5544771575904903\n",
      "Validation Loss: 0.4968157732197393\n",
      "Train Loss: 0.5543774833405459\n",
      "Validation Loss: 0.49659288974873483\n",
      "Train Loss: 0.5542787760574966\n",
      "Validation Loss: 0.49637161254042267\n",
      "Train Loss: 0.5541810262264394\n",
      "Validation Loss: 0.4961519286358943\n",
      "Train Loss: 0.5540842247009645\n",
      "Validation Loss: 0.4959338250350179\n",
      "Train Loss: 0.5539883622389411\n",
      "Validation Loss: 0.49571728883424043\n",
      "Train Loss: 0.5538934297466573\n",
      "Validation Loss: 0.49550230797703826\n",
      "Train Loss: 0.5537994181490145\n",
      "Validation Loss: 0.4952888703850698\n",
      "Train Loss: 0.5537063184328919\n",
      "Validation Loss: 0.4950769630798099\n",
      "Train Loss: 0.5536141220102975\n",
      "Validation Loss: 0.4948665737910684\n",
      "Train Loss: 0.5535228198704754\n",
      "Validation Loss: 0.4946576910305629\n",
      "Train Loss: 0.5534324034474135\n",
      "Validation Loss: 0.49445030182590277\n",
      "Train Loss: 0.5533428641063036\n",
      "Validation Loss: 0.49424439493819405\n",
      "Train Loss: 0.5532541933844763\n",
      "Validation Loss: 0.4940399584317486\n",
      "Train Loss: 0.5531663828957928\n",
      "Validation Loss: 0.4938369807754864\n",
      "Train Loss: 0.5530794241561435\n",
      "Validation Loss: 0.493635450208336\n",
      "Train Loss: 0.5529933090249449\n",
      "Validation Loss: 0.4934353549052722\n",
      "Train Loss: 0.5529080292823938\n",
      "Validation Loss: 0.4932366841162378\n",
      "Train Loss: 0.5528235768648624\n",
      "Validation Loss: 0.49303942573789594\n",
      "Train Loss: 0.5527399436460918\n",
      "Validation Loss: 0.49284356972098176\n",
      "Train Loss: 0.5526571217500551\n",
      "Validation Loss: 0.49264910388631616\n",
      "Train Loss: 0.5525751032822322\n",
      "Validation Loss: 0.49245601755585894\n",
      "Train Loss: 0.552493880469852\n",
      "Validation Loss: 0.492264300224091\n",
      "Train Loss: 0.5524134455913451\n",
      "Validation Loss: 0.4920739404801303\n",
      "Train Loss: 0.5523337910005179\n",
      "Validation Loss: 0.4918849276355864\n",
      "Epoch: 10000, Train Loss: 0.55, Validation Loss: 0.49\n",
      "=====================================\n",
      "Train Loss: 0.552254909072267\n",
      "Validation Loss: 0.49169725162305306\n",
      "Train Loss: 0.5521767923391542\n",
      "Validation Loss: 0.4915109016684611\n",
      "Train Loss: 0.5520994334451987\n",
      "Validation Loss: 0.49132586684081186\n",
      "Train Loss: 0.5520228250048649\n",
      "Validation Loss: 0.4911421370535635\n",
      "Train Loss: 0.5519469597483221\n",
      "Validation Loss: 0.49095970238630277\n",
      "Train Loss: 0.551871830405688\n",
      "Validation Loss: 0.49077855223828487\n",
      "Train Loss: 0.5517974298783248\n",
      "Validation Loss: 0.4905986765965746\n",
      "Train Loss: 0.551723751122824\n",
      "Validation Loss: 0.4904200651891766\n",
      "Train Loss: 0.5516507871131027\n",
      "Validation Loss: 0.49024270835944245\n",
      "Train Loss: 0.5515785308784404\n",
      "Validation Loss: 0.4900665961915064\n",
      "Train Loss: 0.5515069756098627\n",
      "Validation Loss: 0.4898917190276257\n",
      "Train Loss: 0.5514361144632142\n",
      "Validation Loss: 0.48971806772578064\n",
      "Train Loss: 0.5513659407267552\n",
      "Validation Loss: 0.48954563145980867\n",
      "Train Loss: 0.5512964476812284\n",
      "Validation Loss: 0.48937440185948344\n",
      "Train Loss: 0.5512276288291805\n",
      "Validation Loss: 0.48920436841484166\n",
      "Train Loss: 0.5511594775594035\n",
      "Validation Loss: 0.4890355225538689\n",
      "Train Loss: 0.5510919874529723\n",
      "Validation Loss: 0.48886785508266734\n",
      "Train Loss: 0.551025152086671\n",
      "Validation Loss: 0.4887013561259484\n",
      "Train Loss: 0.5509589650159258\n",
      "Validation Loss: 0.488536017290765\n",
      "Train Loss: 0.5508934200253531\n",
      "Validation Loss: 0.48837182901026827\n",
      "Train Loss: 0.5508285108232789\n",
      "Validation Loss: 0.4882087827804095\n",
      "Train Loss: 0.550764231343909\n",
      "Validation Loss: 0.48804686892147897\n",
      "Train Loss: 0.5507005754053582\n",
      "Validation Loss: 0.4878860793654063\n",
      "Train Loss: 0.5506375370055403\n",
      "Validation Loss: 0.48772640509464604\n",
      "Train Loss: 0.5505751100627372\n",
      "Validation Loss: 0.487567837831505\n",
      "Train Loss: 0.5505132887723181\n",
      "Validation Loss: 0.48741036885566735\n",
      "Train Loss: 0.5504520671930005\n",
      "Validation Loss: 0.48725398944942894\n",
      "Train Loss: 0.5503914394859435\n",
      "Validation Loss: 0.487098691364215\n",
      "Train Loss: 0.5503313999472518\n",
      "Validation Loss: 0.4869444659479318\n",
      "Train Loss: 0.5502719428362182\n",
      "Validation Loss: 0.4867913050583113\n",
      "Train Loss: 0.5502130624571397\n",
      "Validation Loss: 0.48663920028535484\n",
      "Train Loss: 0.5501547533056149\n",
      "Validation Loss: 0.48648814386748523\n",
      "Train Loss: 0.5500970097854798\n",
      "Validation Loss: 0.48633812781832836\n",
      "Train Loss: 0.5500398264276583\n",
      "Validation Loss: 0.4861891434249696\n",
      "Train Loss: 0.5499831977762354\n",
      "Validation Loss: 0.48604118289504045\n",
      "Train Loss: 0.5499271185122881\n",
      "Validation Loss: 0.48589423866773385\n",
      "Train Loss: 0.5498715832265179\n",
      "Validation Loss: 0.4857483029588315\n",
      "Train Loss: 0.5498165867233751\n",
      "Validation Loss: 0.485603367436408\n",
      "Train Loss: 0.5497621236925236\n",
      "Validation Loss: 0.4854594250542577\n",
      "Train Loss: 0.5497081890309645\n",
      "Validation Loss: 0.485316467896284\n",
      "Train Loss: 0.5496547775098348\n",
      "Validation Loss: 0.48517448837352056\n",
      "Train Loss: 0.5496018841652761\n",
      "Validation Loss: 0.485033479392744\n",
      "Train Loss: 0.5495495039752538\n",
      "Validation Loss: 0.4848934327696054\n",
      "Train Loss: 0.5494976318534933\n",
      "Validation Loss: 0.4847543420137415\n",
      "Train Loss: 0.5494462629942384\n",
      "Validation Loss: 0.48461619930068567\n",
      "Train Loss: 0.5493953923454862\n",
      "Validation Loss: 0.4844789975052848\n",
      "Train Loss: 0.5493450152310874\n",
      "Validation Loss: 0.4843427293005196\n",
      "Train Loss: 0.549295126811346\n",
      "Validation Loss: 0.48420738791637946\n",
      "Train Loss: 0.5492457223192148\n",
      "Validation Loss: 0.48407296576033176\n",
      "Train Loss: 0.54919679712048\n",
      "Validation Loss: 0.48393945609617456\n",
      "Train Loss: 0.5491483465738708\n",
      "Validation Loss: 0.4838068518240904\n",
      "Train Loss: 0.5491003660432131\n",
      "Validation Loss: 0.48367514643575377\n",
      "Train Loss: 0.5490528509245864\n",
      "Validation Loss: 0.4835443328296995\n",
      "Train Loss: 0.5490057966988133\n",
      "Validation Loss: 0.4834144043519892\n",
      "Train Loss: 0.5489591989601342\n",
      "Validation Loss: 0.4832853539281886\n",
      "Train Loss: 0.5489130532723236\n",
      "Validation Loss: 0.4831571756213447\n",
      "Train Loss: 0.5488673552593558\n",
      "Validation Loss: 0.4830298620341039\n",
      "Train Loss: 0.5488221005157495\n",
      "Validation Loss: 0.4829034069072072\n",
      "Train Loss: 0.5487772847917027\n",
      "Validation Loss: 0.48277780396219977\n",
      "Train Loss: 0.5487329038291637\n",
      "Validation Loss: 0.4826530465565958\n",
      "Train Loss: 0.548688953366261\n",
      "Validation Loss: 0.48252912800204095\n",
      "Train Loss: 0.548645429231998\n",
      "Validation Loss: 0.48240604300209466\n",
      "Train Loss: 0.5486023273414385\n",
      "Validation Loss: 0.48228378393448257\n",
      "Train Loss: 0.548559643593397\n",
      "Validation Loss: 0.4821623455781563\n",
      "Train Loss: 0.5485173739039194\n",
      "Validation Loss: 0.482041721166807\n",
      "Train Loss: 0.5484755142701471\n",
      "Validation Loss: 0.48192190468949114\n",
      "Train Loss: 0.5484340607230945\n",
      "Validation Loss: 0.48180289017185146\n",
      "Train Loss: 0.5483930092922379\n",
      "Validation Loss: 0.48168467190794995\n",
      "Train Loss: 0.5483523560726806\n",
      "Validation Loss: 0.4815672436801969\n",
      "Train Loss: 0.5483120972275991\n",
      "Validation Loss: 0.4814505990750411\n",
      "Train Loss: 0.5482722289246995\n",
      "Validation Loss: 0.48133473257830633\n",
      "Train Loss: 0.5482327473643342\n",
      "Validation Loss: 0.48121963871069906\n",
      "Train Loss: 0.548193648806801\n",
      "Validation Loss: 0.4811053111641879\n",
      "Train Loss: 0.548154929547439\n",
      "Validation Loss: 0.4809917439810501\n",
      "Train Loss: 0.5481165858517013\n",
      "Validation Loss: 0.48087893233358975\n",
      "Train Loss: 0.5480786141831943\n",
      "Validation Loss: 0.48076686994917545\n",
      "Train Loss: 0.5480410108627423\n",
      "Validation Loss: 0.48065555143661093\n",
      "Train Loss: 0.548003772313536\n",
      "Validation Loss: 0.4805449712880468\n",
      "Train Loss: 0.5479668949892081\n",
      "Validation Loss: 0.48043512402854527\n",
      "Train Loss: 0.5479303754100868\n",
      "Validation Loss: 0.4803260042974991\n",
      "Train Loss: 0.5478942100862499\n",
      "Validation Loss: 0.4802176063699808\n",
      "Train Loss: 0.5478583956298774\n",
      "Validation Loss: 0.4801099247162853\n",
      "Train Loss: 0.5478229286192579\n",
      "Validation Loss: 0.480002954618569\n",
      "Train Loss: 0.547787805652289\n",
      "Validation Loss: 0.4798966904471601\n",
      "Train Loss: 0.5477530233917197\n",
      "Validation Loss: 0.4797911266851156\n",
      "Train Loss: 0.5477185785382408\n",
      "Validation Loss: 0.47968625878867993\n",
      "Train Loss: 0.5476844678462357\n",
      "Validation Loss: 0.47958208138222647\n",
      "Train Loss: 0.5476506880623034\n",
      "Validation Loss: 0.4794785890398358\n",
      "Train Loss: 0.5476172359322162\n",
      "Validation Loss: 0.479375776913448\n",
      "Train Loss: 0.5475841083656846\n",
      "Validation Loss: 0.4792736401908436\n",
      "Train Loss: 0.5475513021217944\n",
      "Validation Loss: 0.47917217337537615\n",
      "Train Loss: 0.5475188141350675\n",
      "Validation Loss: 0.4790713722598721\n",
      "Train Loss: 0.5474866412504958\n",
      "Validation Loss: 0.4789712311728296\n",
      "Train Loss: 0.5474547805201441\n",
      "Validation Loss: 0.47887174580866965\n",
      "Train Loss: 0.5474232288782533\n",
      "Validation Loss: 0.4787729109452398\n",
      "Train Loss: 0.5473919832946558\n",
      "Validation Loss: 0.47867472232845326\n",
      "Train Loss: 0.5473610408508567\n",
      "Validation Loss: 0.4785771744030739\n",
      "Train Loss: 0.5473303985400819\n",
      "Validation Loss: 0.47848026351713346\n",
      "Train Loss: 0.5473000534635796\n",
      "Validation Loss: 0.4783839844042579\n",
      "Train Loss: 0.5472700027801777\n",
      "Validation Loss: 0.4782883319034387\n",
      "Epoch: 10000, Train Loss: 0.55, Validation Loss: 0.48\n",
      "=====================================\n",
      "Train Loss: 0.5472402436513442\n",
      "Validation Loss: 0.47819330205222715\n",
      "Train Loss: 0.5472107731940146\n",
      "Validation Loss: 0.4780988904454354\n",
      "Train Loss: 0.5471815886095488\n",
      "Validation Loss: 0.4780050922353001\n",
      "Train Loss: 0.5471526871260017\n",
      "Validation Loss: 0.47791190291241037\n",
      "Train Loss: 0.5471240659978862\n",
      "Validation Loss: 0.4778193183050481\n",
      "Train Loss: 0.5470957225293772\n",
      "Validation Loss: 0.47772733371950266\n",
      "Train Loss: 0.5470676540210977\n",
      "Validation Loss: 0.4776359450339264\n",
      "Train Loss: 0.547039857793811\n",
      "Validation Loss: 0.4775451478392372\n",
      "Train Loss: 0.5470123312199895\n",
      "Validation Loss: 0.477454937516077\n",
      "Train Loss: 0.5469850716713033\n",
      "Validation Loss: 0.4773653103280402\n",
      "Train Loss: 0.5469580765647728\n",
      "Validation Loss: 0.477276261704042\n",
      "Train Loss: 0.5469313433449182\n",
      "Validation Loss: 0.47718778772006054\n",
      "Train Loss: 0.5469048694412278\n",
      "Validation Loss: 0.47709988377639206\n",
      "Train Loss: 0.5468786523727321\n",
      "Validation Loss: 0.4770125460720686\n",
      "Train Loss: 0.5468526896149059\n",
      "Validation Loss: 0.47692577036567724\n",
      "Train Loss: 0.5468269786956405\n",
      "Validation Loss: 0.4768395525150291\n",
      "Train Loss: 0.5468015171998348\n",
      "Validation Loss: 0.47675388909831334\n",
      "Train Loss: 0.5467763026913844\n",
      "Validation Loss: 0.4766687753960281\n",
      "Train Loss: 0.5467513327906619\n",
      "Validation Loss: 0.4765842074087877\n",
      "Train Loss: 0.5467266051407929\n",
      "Validation Loss: 0.476500181469784\n",
      "Train Loss: 0.546702117345039\n",
      "Validation Loss: 0.4764166937839106\n",
      "Train Loss: 0.5466778671140131\n",
      "Validation Loss: 0.47633374049174804\n",
      "Train Loss: 0.5466538521182367\n",
      "Validation Loss: 0.4762513176056326\n",
      "Train Loss: 0.5466300701045061\n",
      "Validation Loss: 0.47616942099796106\n",
      "Train Loss: 0.5466065188170905\n",
      "Validation Loss: 0.4760880474187631\n",
      "Train Loss: 0.5465831959823615\n",
      "Validation Loss: 0.47600719263346475\n",
      "Train Loss: 0.546560099383246\n",
      "Validation Loss: 0.47592685343360314\n",
      "Train Loss: 0.5465372268163231\n",
      "Validation Loss: 0.475847026010474\n",
      "Train Loss: 0.5465145761257161\n",
      "Validation Loss: 0.47576770664945794\n",
      "Train Loss: 0.5464921451996864\n",
      "Validation Loss: 0.4756888914192344\n",
      "Train Loss: 0.5464699318663709\n",
      "Validation Loss: 0.4756105771173869\n",
      "Train Loss: 0.5464479340243052\n",
      "Validation Loss: 0.47553276008831813\n",
      "Train Loss: 0.5464261495897846\n",
      "Validation Loss: 0.47545543669577195\n",
      "Train Loss: 0.546404576468715\n",
      "Validation Loss: 0.4753786032498067\n",
      "Train Loss: 0.546383212615468\n",
      "Validation Loss: 0.4753022564623737\n",
      "Train Loss: 0.5463620560270103\n",
      "Validation Loss: 0.47522639282722806\n",
      "Train Loss: 0.5463411046667772\n",
      "Validation Loss: 0.47515100933010246\n",
      "Train Loss: 0.5463203565608596\n",
      "Validation Loss: 0.47507610188296\n",
      "Train Loss: 0.5462998097046328\n",
      "Validation Loss: 0.4750016671995439\n",
      "Train Loss: 0.5462794621677641\n",
      "Validation Loss: 0.4749277024654541\n",
      "Train Loss: 0.546259312028764\n",
      "Validation Loss: 0.4748542039563461\n",
      "Train Loss: 0.5462393573602474\n",
      "Validation Loss: 0.47478116851190355\n",
      "Train Loss: 0.5462195962977431\n",
      "Validation Loss: 0.4747085922062599\n",
      "Train Loss: 0.546200026899942\n",
      "Validation Loss: 0.4746364726976332\n",
      "Train Loss: 0.5461806473370104\n",
      "Validation Loss: 0.47456480640386783\n",
      "Train Loss: 0.546161455794347\n",
      "Validation Loss: 0.4744935897597159\n",
      "Train Loss: 0.5461424504293522\n",
      "Validation Loss: 0.47442282030867633\n",
      "Train Loss: 0.5461236294058517\n",
      "Validation Loss: 0.47435249437688537\n",
      "Train Loss: 0.5461049909864597\n",
      "Validation Loss: 0.47428260913740733\n",
      "Train Loss: 0.5460865333443031\n",
      "Validation Loss: 0.4742131614957574\n",
      "Train Loss: 0.5460682547437136\n",
      "Validation Loss: 0.4741441482782531\n",
      "Train Loss: 0.5460501534635799\n",
      "Validation Loss: 0.47407556632712156\n",
      "Train Loss: 0.5460322277995515\n",
      "Validation Loss: 0.47400741280847525\n",
      "Train Loss: 0.5460144760061596\n",
      "Validation Loss: 0.4739396841474103\n",
      "Train Loss: 0.5459968964359734\n",
      "Validation Loss: 0.4738723779199343\n",
      "Train Loss: 0.5459794874025111\n",
      "Validation Loss: 0.47380549126868104\n",
      "Train Loss: 0.5459622472565951\n",
      "Validation Loss: 0.4737390211138883\n",
      "Train Loss: 0.5459451743630089\n",
      "Validation Loss: 0.4736729643910537\n",
      "Train Loss: 0.5459282670778257\n",
      "Validation Loss: 0.4736073182889104\n",
      "Train Loss: 0.5459115237960176\n",
      "Validation Loss: 0.4735420800808818\n",
      "Train Loss: 0.54589494294854\n",
      "Validation Loss: 0.47347724681685643\n",
      "Train Loss: 0.5458785229327459\n",
      "Validation Loss: 0.4734128157301188\n",
      "Train Loss: 0.5458622622063772\n",
      "Validation Loss: 0.4733487838996695\n",
      "Train Loss: 0.5458461592180577\n",
      "Validation Loss: 0.47328514865699195\n",
      "Train Loss: 0.5458302124515892\n",
      "Validation Loss: 0.4732219071094264\n",
      "Train Loss: 0.5458144203816908\n",
      "Validation Loss: 0.47315905661670243\n",
      "Train Loss: 0.5457987815200158\n",
      "Validation Loss: 0.47309659462117576\n",
      "Train Loss: 0.545783294364846\n",
      "Validation Loss: 0.47303451820322456\n",
      "Train Loss: 0.5457679574510281\n",
      "Validation Loss: 0.47297282452569994\n",
      "Train Loss: 0.5457527693065151\n",
      "Validation Loss: 0.47291151131051423\n",
      "Train Loss: 0.5457377284932238\n",
      "Validation Loss: 0.472850576054277\n",
      "Train Loss: 0.545722833606429\n",
      "Validation Loss: 0.47279001602795484\n",
      "Train Loss: 0.5457080832046377\n",
      "Validation Loss: 0.47272982807295433\n",
      "Train Loss: 0.545693475867208\n",
      "Validation Loss: 0.47267001027094724\n",
      "Train Loss: 0.5456790102484271\n",
      "Validation Loss: 0.47261055999968854\n",
      "Train Loss: 0.5456646849450437\n",
      "Validation Loss: 0.4725514744464776\n",
      "Train Loss: 0.5456504986155986\n",
      "Validation Loss: 0.47249275155954934\n",
      "Train Loss: 0.5456364499196249\n",
      "Validation Loss: 0.47243438776740226\n",
      "Train Loss: 0.5456225375196614\n",
      "Validation Loss: 0.4723763815881825\n",
      "Train Loss: 0.5456087600632026\n",
      "Validation Loss: 0.4723187308722115\n",
      "Train Loss: 0.5455951162663926\n",
      "Validation Loss: 0.47226143215254895\n",
      "Train Loss: 0.5455816048236483\n",
      "Validation Loss: 0.47220448367726287\n",
      "Train Loss: 0.5455682244346126\n",
      "Validation Loss: 0.4721478827880748\n",
      "Train Loss: 0.5455549738560727\n",
      "Validation Loss: 0.4720916272781449\n",
      "Train Loss: 0.5455418518332167\n",
      "Validation Loss: 0.4720357148852139\n",
      "Train Loss: 0.5455288570981367\n",
      "Validation Loss: 0.47198014298628876\n",
      "Train Loss: 0.5455159883997828\n",
      "Validation Loss: 0.47192490988761654\n",
      "Train Loss: 0.5455032445743743\n",
      "Validation Loss: 0.4718700126429964\n",
      "Train Loss: 0.5454906243464875\n",
      "Validation Loss: 0.47181544914294493\n",
      "Train Loss: 0.5454781265531339\n",
      "Validation Loss: 0.4717612167032861\n",
      "Train Loss: 0.545465749984785\n",
      "Validation Loss: 0.4717073136749032\n",
      "Train Loss: 0.5454534934789702\n",
      "Validation Loss: 0.4716537376348103\n",
      "Train Loss: 0.5454413558848472\n",
      "Validation Loss: 0.4716004864760872\n",
      "Train Loss: 0.545429336036512\n",
      "Validation Loss: 0.47154755742611093\n",
      "Train Loss: 0.5454174327647934\n",
      "Validation Loss: 0.47149494887898763\n",
      "Train Loss: 0.5454056449861534\n",
      "Validation Loss: 0.47144265828000337\n",
      "Train Loss: 0.545393971567613\n",
      "Validation Loss: 0.4713906834988604\n",
      "Train Loss: 0.5453824113915092\n",
      "Validation Loss: 0.4713390233309181\n",
      "Train Loss: 0.5453709633387258\n",
      "Validation Loss: 0.47128767475135724\n",
      "Train Loss: 0.5453596263645013\n",
      "Validation Loss: 0.4712366355509964\n",
      "Epoch: 10000, Train Loss: 0.55, Validation Loss: 0.47\n",
      "=====================================\n",
      "Train Loss: 0.5453483993368582\n",
      "Validation Loss: 0.47118590412059075\n",
      "Train Loss: 0.5453372812291976\n",
      "Validation Loss: 0.47113547827051544\n",
      "Train Loss: 0.5453262710013825\n",
      "Validation Loss: 0.47108535545098934\n",
      "Train Loss: 0.5453153675693451\n",
      "Validation Loss: 0.47103553414727095\n",
      "Train Loss: 0.5453045699127651\n",
      "Validation Loss: 0.4709860121338583\n",
      "Train Loss: 0.5452938769839173\n",
      "Validation Loss: 0.4709367876752015\n",
      "Train Loss: 0.5452832877799505\n",
      "Validation Loss: 0.4708878585647592\n",
      "Train Loss: 0.5452728013259359\n",
      "Validation Loss: 0.47083922266933687\n",
      "Train Loss: 0.5452624165806126\n",
      "Validation Loss: 0.4707908782173677\n",
      "Train Loss: 0.5452521325507583\n",
      "Validation Loss: 0.4707428235749229\n",
      "Train Loss: 0.5452419483024937\n",
      "Validation Loss: 0.4706950560913281\n",
      "Train Loss: 0.545231862877989\n",
      "Validation Loss: 0.47064757421409453\n",
      "Train Loss: 0.5452218752910227\n",
      "Validation Loss: 0.4706003765761907\n",
      "Train Loss: 0.5452119845779022\n",
      "Validation Loss: 0.4705534609707267\n",
      "Train Loss: 0.545202189800469\n",
      "Validation Loss: 0.4705068249593663\n",
      "Train Loss: 0.54519249003191\n",
      "Validation Loss: 0.4704604667207555\n",
      "Train Loss: 0.5451828843736364\n",
      "Validation Loss: 0.47041438480918\n",
      "Train Loss: 0.545173371897223\n",
      "Validation Loss: 0.47036857766048856\n",
      "Train Loss: 0.5451639516974864\n",
      "Validation Loss: 0.4703230431744007\n",
      "Train Loss: 0.5451546228769512\n",
      "Validation Loss: 0.4702777792591528\n",
      "Train Loss: 0.5451453845657899\n",
      "Validation Loss: 0.4702327841980142\n",
      "Train Loss: 0.5451362358665286\n",
      "Validation Loss: 0.47018805646023476\n",
      "Train Loss: 0.5451271759209487\n",
      "Validation Loss: 0.4701435937378009\n",
      "Train Loss: 0.5451182038828934\n",
      "Validation Loss: 0.47009939464153533\n",
      "Train Loss: 0.5451093188592753\n",
      "Validation Loss: 0.4700554576022617\n",
      "Train Loss: 0.5451005200350225\n",
      "Validation Loss: 0.4700117810053648\n",
      "Train Loss: 0.5450918065482373\n",
      "Validation Loss: 0.4699683630565176\n",
      "Train Loss: 0.5450831776123364\n",
      "Validation Loss: 0.46992520161171497\n",
      "Train Loss: 0.5450746323635437\n",
      "Validation Loss: 0.469882295133417\n",
      "Train Loss: 0.5450661700320881\n",
      "Validation Loss: 0.46983964209922074\n",
      "Train Loss: 0.5450577898018766\n",
      "Validation Loss: 0.469797240807523\n",
      "Train Loss: 0.5450494908496306\n",
      "Validation Loss: 0.46975509010880795\n",
      "Train Loss: 0.5450412724034632\n",
      "Validation Loss: 0.4697131875308776\n",
      "Train Loss: 0.5450331336711968\n",
      "Validation Loss: 0.46967153200086637\n",
      "Train Loss: 0.5450250739111819\n",
      "Validation Loss: 0.4696301211227584\n",
      "Train Loss: 0.5450170923272198\n",
      "Validation Loss: 0.46958895377625515\n",
      "Train Loss: 0.5450091881626089\n",
      "Validation Loss: 0.4695480286683149\n",
      "Train Loss: 0.5450013606809002\n",
      "Validation Loss: 0.46950734396831234\n",
      "Train Loss: 0.5449936091379739\n",
      "Validation Loss: 0.46946689839676387\n",
      "Train Loss: 0.5449859327763042\n",
      "Validation Loss: 0.4694266900142131\n",
      "Train Loss: 0.5449783308949454\n",
      "Validation Loss: 0.4693867170718117\n",
      "Train Loss: 0.5449708027519146\n",
      "Validation Loss: 0.46934697824934263\n",
      "Train Loss: 0.5449633476297095\n",
      "Validation Loss: 0.46930747259698613\n",
      "Train Loss: 0.544955964827435\n",
      "Validation Loss: 0.4692681980218403\n",
      "Train Loss: 0.5449486536530135\n",
      "Validation Loss: 0.4692291530427213\n",
      "Train Loss: 0.5449414134039093\n",
      "Validation Loss: 0.46919033612405675\n",
      "Train Loss: 0.5449342433836424\n",
      "Validation Loss: 0.4691517457368339\n",
      "Train Loss: 0.5449271429192738\n",
      "Validation Loss: 0.469113380721415\n",
      "Train Loss: 0.5449201113406089\n",
      "Validation Loss: 0.46907523931948425\n",
      "Train Loss: 0.5449131479700471\n",
      "Validation Loss: 0.46903732032321516\n",
      "Train Loss: 0.5449062521661131\n",
      "Validation Loss: 0.46899962234926645\n",
      "Train Loss: 0.544899423243835\n",
      "Validation Loss: 0.46896214353728544\n",
      "Train Loss: 0.5448926605742916\n",
      "Validation Loss: 0.4689248828182695\n",
      "Train Loss: 0.5448859635166667\n",
      "Validation Loss: 0.4688878387665422\n",
      "Train Loss: 0.5448793314200301\n",
      "Validation Loss: 0.46885100990238016\n",
      "Train Loss: 0.544872763640536\n",
      "Validation Loss: 0.4688143950542152\n",
      "Train Loss: 0.5448662595819677\n",
      "Validation Loss: 0.46877799232993056\n",
      "Train Loss: 0.5448598186110714\n",
      "Validation Loss: 0.46874180056950215\n",
      "Train Loss: 0.5448534401292476\n",
      "Validation Loss: 0.4687058184361645\n",
      "Train Loss: 0.5448471235138735\n",
      "Validation Loss: 0.46867004478123997\n",
      "Train Loss: 0.544840868190354\n",
      "Validation Loss: 0.4686344780367215\n",
      "Train Loss: 0.5448346735326847\n",
      "Validation Loss: 0.46859911730734993\n",
      "Train Loss: 0.5448285389898655\n",
      "Validation Loss: 0.4685639607935965\n",
      "Train Loss: 0.5448224639610406\n",
      "Validation Loss: 0.4685290076704564\n",
      "Train Loss: 0.5448164478479852\n",
      "Validation Loss: 0.468494256515191\n",
      "Train Loss: 0.54481049009932\n",
      "Validation Loss: 0.46845970548501986\n",
      "Train Loss: 0.5448045901294449\n",
      "Validation Loss: 0.46842535377127514\n",
      "Train Loss: 0.5447987474123497\n",
      "Validation Loss: 0.4683911999020386\n",
      "Train Loss: 0.5447929613719832\n",
      "Validation Loss: 0.4683572430787717\n",
      "Train Loss: 0.5447872314479544\n",
      "Validation Loss: 0.4683234816628754\n",
      "Train Loss: 0.5447815571278741\n",
      "Validation Loss: 0.4682899141973842\n",
      "Train Loss: 0.5447759378344161\n",
      "Validation Loss: 0.46825653953915625\n",
      "Train Loss: 0.5447703730654667\n",
      "Validation Loss: 0.4682233565423401\n",
      "Train Loss: 0.5447648622687253\n",
      "Validation Loss: 0.46819036443374074\n",
      "Train Loss: 0.5447594049340484\n",
      "Validation Loss: 0.4681575614159139\n",
      "Train Loss: 0.5447540005452476\n",
      "Validation Loss: 0.46812494654126957\n",
      "Train Loss: 0.544748648589237\n",
      "Validation Loss: 0.4680925185657462\n",
      "Train Loss: 0.5447433485560336\n",
      "Validation Loss: 0.46806027594898325\n",
      "Train Loss: 0.5447380999160932\n",
      "Validation Loss: 0.46802821794217525\n",
      "Train Loss: 0.5447329021972045\n",
      "Validation Loss: 0.4679963434318668\n",
      "Train Loss: 0.544727754915958\n",
      "Validation Loss: 0.4679646509497487\n",
      "Train Loss: 0.5447226575569779\n",
      "Validation Loss: 0.4679331400616701\n",
      "Train Loss: 0.5447176096441165\n",
      "Validation Loss: 0.4679018090075851\n",
      "Train Loss: 0.544712610707617\n",
      "Validation Loss: 0.46787065663363986\n",
      "Train Loss: 0.544707660255965\n",
      "Validation Loss: 0.46783968197549125\n",
      "Train Loss: 0.5447027578408815\n",
      "Validation Loss: 0.4678088839457114\n",
      "Train Loss: 0.5446979029777692\n",
      "Validation Loss: 0.46777826128795297\n",
      "Train Loss: 0.5446930951995841\n",
      "Validation Loss: 0.46774781280810696\n",
      "Train Loss: 0.5446883340708357\n",
      "Validation Loss: 0.46771753773201546\n",
      "Train Loss: 0.5446836191309352\n",
      "Validation Loss: 0.4676874345732448\n",
      "Train Loss: 0.5446789499268223\n",
      "Validation Loss: 0.4676575027514276\n",
      "Train Loss: 0.5446743260058334\n",
      "Validation Loss: 0.4676277407887301\n",
      "Train Loss: 0.5446697469462405\n",
      "Validation Loss: 0.46759814762662344\n",
      "Train Loss: 0.5446652123191749\n",
      "Validation Loss: 0.4675687227539737\n",
      "Train Loss: 0.5446607216819461\n",
      "Validation Loss: 0.46753946440472316\n",
      "Train Loss: 0.5446562746003418\n",
      "Validation Loss: 0.46751037201864803\n",
      "Train Loss: 0.5446518706658248\n",
      "Validation Loss: 0.46748144425239746\n",
      "Train Loss: 0.5446475094261778\n",
      "Validation Loss: 0.46745268043960564\n",
      "Train Loss: 0.5446431904927072\n",
      "Validation Loss: 0.46742407930168756\n",
      "Train Loss: 0.5446389134683904\n",
      "Validation Loss: 0.46739563980694\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.47\n",
      "=====================================\n",
      "Train Loss: 0.5446346779232962\n",
      "Validation Loss: 0.46736736105724647\n",
      "Train Loss: 0.5446304834920814\n",
      "Validation Loss: 0.4673392421416965\n",
      "Train Loss: 0.5446263297495029\n",
      "Validation Loss: 0.4673112815694083\n",
      "Train Loss: 0.5446222163009036\n",
      "Validation Loss: 0.46728347856697466\n",
      "Train Loss: 0.5446181427571766\n",
      "Validation Loss: 0.4672558329645445\n",
      "Train Loss: 0.5446141087138273\n",
      "Validation Loss: 0.46722834273928754\n",
      "Train Loss: 0.5446101138105218\n",
      "Validation Loss: 0.46720100724141667\n",
      "Train Loss: 0.5446061576646527\n",
      "Validation Loss: 0.46717382541168756\n",
      "Train Loss: 0.5446022398990498\n",
      "Validation Loss: 0.4671467967941735\n",
      "Train Loss: 0.5445983601257329\n",
      "Validation Loss: 0.4671199202804238\n",
      "Train Loss: 0.544594517993543\n",
      "Validation Loss: 0.4670931943344477\n",
      "Train Loss: 0.5445907131465894\n",
      "Validation Loss: 0.46706661856657555\n",
      "Train Loss: 0.5445869452074225\n",
      "Validation Loss: 0.4670401921784495\n",
      "Train Loss: 0.544583213800922\n",
      "Validation Loss: 0.46701391407558895\n",
      "Train Loss: 0.5445795186006969\n",
      "Validation Loss: 0.46698778309094385\n",
      "Train Loss: 0.5445758592513157\n",
      "Validation Loss: 0.46696179879180016\n",
      "Train Loss: 0.5445722353962723\n",
      "Validation Loss: 0.4669359595502173\n",
      "Train Loss: 0.5445686466987697\n",
      "Validation Loss: 0.46691026529534674\n",
      "Train Loss: 0.5445650928082885\n",
      "Validation Loss: 0.4668847144058314\n",
      "Train Loss: 0.5445615733938146\n",
      "Validation Loss: 0.4668593068169076\n",
      "Train Loss: 0.5445580881332633\n",
      "Validation Loss: 0.4668340410247214\n",
      "Train Loss: 0.5445546366653414\n",
      "Validation Loss: 0.4668089162049811\n",
      "Train Loss: 0.5445512186980853\n",
      "Validation Loss: 0.46678393156993864\n",
      "Train Loss: 0.5445478338770114\n",
      "Validation Loss: 0.46675908660087595\n",
      "Train Loss: 0.5445444818921759\n",
      "Validation Loss: 0.4667343801056302\n",
      "Train Loss: 0.5445411624261388\n",
      "Validation Loss: 0.46670981113898086\n",
      "Train Loss: 0.5445378751651334\n",
      "Validation Loss: 0.4666853790579137\n",
      "Train Loss: 0.5445346197970599\n",
      "Validation Loss: 0.46666108292298897\n",
      "Train Loss: 0.5445313960035859\n",
      "Validation Loss: 0.46663692234100523\n",
      "Train Loss: 0.5445282034868595\n",
      "Validation Loss: 0.46661289583497334\n",
      "Train Loss: 0.5445250419241152\n",
      "Validation Loss: 0.46658900326161096\n",
      "Train Loss: 0.5445219110344023\n",
      "Validation Loss: 0.4665652435037256\n",
      "Train Loss: 0.5445188105283216\n",
      "Validation Loss: 0.4665416153918048\n",
      "Train Loss: 0.5445157400794093\n",
      "Validation Loss: 0.4665181184370142\n",
      "Train Loss: 0.5445126994246112\n",
      "Validation Loss: 0.46649475158509224\n",
      "Train Loss: 0.544509688263745\n",
      "Validation Loss: 0.4664715144622299\n",
      "Train Loss: 0.5445067063286837\n",
      "Validation Loss: 0.46644840626333306\n",
      "Train Loss: 0.5445037533109695\n",
      "Validation Loss: 0.46642542566840417\n",
      "Train Loss: 0.5445008289491062\n",
      "Validation Loss: 0.46640257247544287\n",
      "Train Loss: 0.5444979329416111\n",
      "Validation Loss: 0.4663798459677444\n",
      "Train Loss: 0.5444950650381523\n",
      "Validation Loss: 0.46635724480720997\n",
      "Train Loss: 0.544492224953245\n",
      "Validation Loss: 0.46633476863571316\n",
      "Train Loss: 0.5444894124122668\n",
      "Validation Loss: 0.46631241655452704\n",
      "Train Loss: 0.5444866271722864\n",
      "Validation Loss: 0.4662901875316127\n",
      "Train Loss: 0.5444838689265362\n",
      "Validation Loss: 0.4662680816510494\n",
      "Train Loss: 0.5444811374556779\n",
      "Validation Loss: 0.46624609769528386\n",
      "Train Loss: 0.5444784324939397\n",
      "Validation Loss: 0.4662242347752742\n",
      "Train Loss: 0.5444757537599021\n",
      "Validation Loss: 0.4662024924936325\n",
      "Train Loss: 0.5444731010123439\n",
      "Validation Loss: 0.46618087007455783\n",
      "Train Loss: 0.5444704739932709\n",
      "Validation Loss: 0.46615936693499554\n",
      "Train Loss: 0.5444678724637801\n",
      "Validation Loss: 0.46613798170652215\n",
      "Train Loss: 0.5444652961613183\n",
      "Validation Loss: 0.4661167140554305\n",
      "Train Loss: 0.5444627448625471\n",
      "Validation Loss: 0.4660955632687745\n",
      "Train Loss: 0.5444602183091555\n",
      "Validation Loss: 0.46607452901728097\n",
      "Train Loss: 0.544457716261709\n",
      "Validation Loss: 0.4660536101862769\n",
      "Train Loss: 0.5444552384940128\n",
      "Validation Loss: 0.4660328063138688\n",
      "Train Loss: 0.5444527847610595\n",
      "Validation Loss: 0.46601211623610106\n",
      "Train Loss: 0.5444503548319781\n",
      "Validation Loss: 0.46599153974008195\n",
      "Train Loss: 0.5444479484761475\n",
      "Validation Loss: 0.4659710760182685\n",
      "Train Loss: 0.5444455654564279\n",
      "Validation Loss: 0.46595072451007363\n",
      "Train Loss: 0.544443205555492\n",
      "Validation Loss: 0.4659304844657574\n",
      "Train Loss: 0.5444408685401428\n",
      "Validation Loss: 0.46591035532896863\n",
      "Train Loss: 0.5444385541959683\n",
      "Validation Loss: 0.46589033605584734\n",
      "Train Loss: 0.5444362623119428\n",
      "Validation Loss: 0.4658704262008918\n",
      "Train Loss: 0.5444339926605551\n",
      "Validation Loss: 0.46585062521389764\n",
      "Train Loss: 0.5444317450163331\n",
      "Validation Loss: 0.46583093254681124\n",
      "Train Loss: 0.5444295191812132\n",
      "Validation Loss: 0.46581134721701634\n",
      "Train Loss: 0.5444273149423444\n",
      "Validation Loss: 0.46579186873357825\n",
      "Train Loss: 0.5444251320878953\n",
      "Validation Loss: 0.4657724963094547\n",
      "Train Loss: 0.5444229704102593\n",
      "Validation Loss: 0.4657532300536443\n",
      "Train Loss: 0.5444208296996172\n",
      "Validation Loss: 0.4657340685869283\n",
      "Train Loss: 0.544418709759143\n",
      "Validation Loss: 0.4657150114790863\n",
      "Train Loss: 0.5444166103848685\n",
      "Validation Loss: 0.46569605824870436\n",
      "Train Loss: 0.5444145313738025\n",
      "Validation Loss: 0.4656772081183242\n",
      "Train Loss: 0.544412472525497\n",
      "Validation Loss: 0.465658460610316\n",
      "Train Loss: 0.5444104336576963\n",
      "Validation Loss: 0.4656398150565449\n",
      "Train Loss: 0.5444084145645974\n",
      "Validation Loss: 0.4656212709301368\n",
      "Train Loss: 0.5444064150585739\n",
      "Validation Loss: 0.46560282751373916\n",
      "Train Loss: 0.5444044349450569\n",
      "Validation Loss: 0.46558448403909586\n",
      "Train Loss: 0.544402474048843\n",
      "Validation Loss: 0.46556624014275594\n",
      "Train Loss: 0.5444005321708502\n",
      "Validation Loss: 0.4655480953050727\n",
      "Train Loss: 0.5443986091214403\n",
      "Validation Loss: 0.4655300487631254\n",
      "Train Loss: 0.544396704730049\n",
      "Validation Loss: 0.46551210015843186\n",
      "Train Loss: 0.5443948188266828\n",
      "Validation Loss: 0.4654942488362532\n",
      "Train Loss: 0.5443929512104299\n",
      "Validation Loss: 0.46547649423147336\n",
      "Train Loss: 0.5443911017136678\n",
      "Validation Loss: 0.4654588353951386\n",
      "Train Loss: 0.5443892701485371\n",
      "Validation Loss: 0.4654412724133093\n",
      "Train Loss: 0.544387456357752\n",
      "Validation Loss: 0.46542380409491707\n",
      "Train Loss: 0.5443856601638356\n",
      "Validation Loss: 0.465406430283872\n",
      "Train Loss: 0.5443838813974716\n",
      "Validation Loss: 0.4653891502828025\n",
      "Train Loss: 0.544382119876194\n",
      "Validation Loss: 0.46537196388664115\n",
      "Train Loss: 0.5443803754496769\n",
      "Validation Loss: 0.46535487050545093\n",
      "Train Loss: 0.5443786479448934\n",
      "Validation Loss: 0.4653378693943974\n",
      "Train Loss: 0.5443769371982586\n",
      "Validation Loss: 0.4653209598623666\n",
      "Train Loss: 0.5443752430482798\n",
      "Validation Loss: 0.46530414151717886\n",
      "Train Loss: 0.5443735653341205\n",
      "Validation Loss: 0.4652874136707241\n",
      "Train Loss: 0.5443719038892328\n",
      "Validation Loss: 0.46527077588187205\n",
      "Train Loss: 0.5443702585647402\n",
      "Validation Loss: 0.46525422811208844\n",
      "Train Loss: 0.5443686292094624\n",
      "Validation Loss: 0.46523776883749524\n",
      "Train Loss: 0.544367015647623\n",
      "Validation Loss: 0.4652213984096879\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.47\n",
      "=====================================\n",
      "Train Loss: 0.5443654177474972\n",
      "Validation Loss: 0.4652051160059565\n",
      "Train Loss: 0.5443638353416597\n",
      "Validation Loss: 0.465188921140687\n",
      "Train Loss: 0.5443622682869392\n",
      "Validation Loss: 0.4651728134849083\n",
      "Train Loss: 0.5443607164331087\n",
      "Validation Loss: 0.4651567923620496\n",
      "Train Loss: 0.5443591796312324\n",
      "Validation Loss: 0.46514085709698033\n",
      "Train Loss: 0.5443576577424428\n",
      "Validation Loss: 0.46512500766182996\n",
      "Train Loss: 0.5443561506195638\n",
      "Validation Loss: 0.46510924308694834\n",
      "Train Loss: 0.5443546581173614\n",
      "Validation Loss: 0.46509356270128516\n",
      "Train Loss: 0.544353180086506\n",
      "Validation Loss: 0.4650779666749996\n",
      "Train Loss: 0.5443517163909878\n",
      "Validation Loss: 0.46506245409408214\n",
      "Train Loss: 0.5443502668972152\n",
      "Validation Loss: 0.465047024639916\n",
      "Train Loss: 0.544348831465443\n",
      "Validation Loss: 0.4650316779437042\n",
      "Train Loss: 0.5443474099564861\n",
      "Validation Loss: 0.46501641334093397\n",
      "Train Loss: 0.5443460022466927\n",
      "Validation Loss: 0.4650012302709374\n",
      "Train Loss: 0.5443446081861224\n",
      "Validation Loss: 0.4649861285631658\n",
      "Train Loss: 0.5443432276469159\n",
      "Validation Loss: 0.46497110790511686\n",
      "Train Loss: 0.544341860507399\n",
      "Validation Loss: 0.4649561671457946\n",
      "Train Loss: 0.5443405066353169\n",
      "Validation Loss: 0.46494130622075375\n",
      "Train Loss: 0.5443391658849591\n",
      "Validation Loss: 0.46492652466768863\n",
      "Train Loss: 0.5443378381392261\n",
      "Validation Loss: 0.46491182193307273\n",
      "Train Loss: 0.5443365232825257\n",
      "Validation Loss: 0.46489719776121463\n",
      "Train Loss: 0.5443352211857411\n",
      "Validation Loss: 0.4648826514986124\n",
      "Train Loss: 0.5443339317146623\n",
      "Validation Loss: 0.4648681827388981\n",
      "Train Loss: 0.5443326547499723\n",
      "Validation Loss: 0.4648537911788117\n",
      "Train Loss: 0.5443313901733337\n",
      "Validation Loss: 0.4648394765161292\n",
      "Train Loss: 0.544330137859412\n",
      "Validation Loss: 0.46482523780537943\n",
      "Train Loss: 0.5443288976986465\n",
      "Validation Loss: 0.46481107479740363\n",
      "Train Loss: 0.5443276695689298\n",
      "Validation Loss: 0.4647969871424106\n",
      "Train Loss: 0.5443264533425838\n",
      "Validation Loss: 0.46478297444102995\n",
      "Train Loss: 0.5443252489250544\n",
      "Validation Loss: 0.4647690359553091\n",
      "Train Loss: 0.5443240561851967\n",
      "Validation Loss: 0.4647551718306262\n",
      "Train Loss: 0.5443228750176216\n",
      "Validation Loss: 0.46474138152625105\n",
      "Train Loss: 0.5443217053112228\n",
      "Validation Loss: 0.4647276644517898\n",
      "Train Loss: 0.5443205469505024\n",
      "Validation Loss: 0.46471402056048433\n",
      "Train Loss: 0.5443193998251238\n",
      "Validation Loss: 0.46470044867091426\n",
      "Train Loss: 0.5443182638280104\n",
      "Validation Loss: 0.46468694878897804\n",
      "Train Loss: 0.5443171388518211\n",
      "Validation Loss: 0.4646735203284225\n",
      "Train Loss: 0.5443160247854734\n",
      "Validation Loss: 0.46466016354307554\n",
      "Train Loss: 0.5443149215344614\n",
      "Validation Loss: 0.46464687706000557\n",
      "Train Loss: 0.5443138289837088\n",
      "Validation Loss: 0.4646336613810135\n",
      "Train Loss: 0.5443127470346644\n",
      "Validation Loss: 0.46462051538121335\n",
      "Train Loss: 0.5443116755798793\n",
      "Validation Loss: 0.46460743931824133\n",
      "Train Loss: 0.5443106145168429\n",
      "Validation Loss: 0.46459443231528263\n",
      "Train Loss: 0.5443095637506675\n",
      "Validation Loss: 0.4645814938431954\n",
      "Train Loss: 0.54430852316985\n",
      "Validation Loss: 0.46456862381580455\n",
      "Train Loss: 0.5443074926934857\n",
      "Validation Loss: 0.46455582180617605\n",
      "Train Loss: 0.5443064722056858\n",
      "Validation Loss: 0.4645430876797686\n",
      "Train Loss: 0.5443054616204328\n",
      "Validation Loss: 0.46453042066484396\n",
      "Train Loss: 0.5443044608413361\n",
      "Validation Loss: 0.46451782048286233\n",
      "Train Loss: 0.5443034697613548\n",
      "Validation Loss: 0.4645052870523289\n",
      "Train Loss: 0.5443024882973226\n",
      "Validation Loss: 0.464492819900347\n",
      "Train Loss: 0.54430151635964\n",
      "Validation Loss: 0.46448041791223305\n",
      "Train Loss: 0.5443005538507897\n",
      "Validation Loss: 0.46446808165166736\n",
      "Train Loss: 0.5442996006779064\n",
      "Validation Loss: 0.46445581054819035\n",
      "Train Loss: 0.5442986567484009\n",
      "Validation Loss: 0.46444360373606286\n",
      "Train Loss: 0.5442977219779052\n",
      "Validation Loss: 0.46443146128890295\n",
      "Train Loss: 0.5442967962816636\n",
      "Validation Loss: 0.46441938268866045\n",
      "Train Loss: 0.5442958795645619\n",
      "Validation Loss: 0.4644073676145713\n",
      "Train Loss: 0.5442949717386392\n",
      "Validation Loss: 0.4643954160927092\n",
      "Train Loss: 0.5442940727161758\n",
      "Validation Loss: 0.4643835278537864\n",
      "Train Loss: 0.5442931824143682\n",
      "Validation Loss: 0.4643717017907846\n",
      "Train Loss: 0.5442923007474649\n",
      "Validation Loss: 0.4643599379321558\n",
      "Train Loss: 0.5442914276345701\n",
      "Validation Loss: 0.4643482354685855\n",
      "Train Loss: 0.5442905629923616\n",
      "Validation Loss: 0.46433659502211244\n",
      "Train Loss: 0.5442897067352095\n",
      "Validation Loss: 0.4643250154392356\n",
      "Train Loss: 0.5442888587858097\n",
      "Validation Loss: 0.46431349680103007\n",
      "Train Loss: 0.5442880190609445\n",
      "Validation Loss: 0.46430203854763347\n",
      "Train Loss: 0.5442871874841311\n",
      "Validation Loss: 0.46429064046551444\n",
      "Train Loss: 0.5442863639735308\n",
      "Validation Loss: 0.46427930199633743\n",
      "Train Loss: 0.544285548453481\n",
      "Validation Loss: 0.4642680226320591\n",
      "Train Loss: 0.544284740844977\n",
      "Validation Loss: 0.4642568027036674\n",
      "Train Loss: 0.5442839410677566\n",
      "Validation Loss: 0.46424564135913904\n",
      "Train Loss: 0.5442831490495842\n",
      "Validation Loss: 0.46423453898027356\n",
      "Train Loss: 0.5442823647163894\n",
      "Validation Loss: 0.4642234944699936\n",
      "Train Loss: 0.5442815879913173\n",
      "Validation Loss: 0.4642125078661376\n",
      "Train Loss: 0.5442808188025297\n",
      "Validation Loss: 0.4642015786648275\n",
      "Train Loss: 0.544280057073511\n",
      "Validation Loss: 0.4641907063135784\n",
      "Train Loss: 0.5442793027346191\n",
      "Validation Loss: 0.46417989090156725\n",
      "Train Loss: 0.5442785557158338\n",
      "Validation Loss: 0.46416913192691645\n",
      "Train Loss: 0.5442778159387349\n",
      "Validation Loss: 0.46415842967735405\n",
      "Train Loss: 0.544277083338817\n",
      "Validation Loss: 0.4641477831099845\n",
      "Train Loss: 0.5442763578440966\n",
      "Validation Loss: 0.46413719256304276\n",
      "Train Loss: 0.5442756393911528\n",
      "Validation Loss: 0.4641266569948979\n",
      "Train Loss: 0.5442749279040674\n",
      "Validation Loss: 0.4641161766958948\n",
      "Train Loss: 0.5442742233256288\n",
      "Validation Loss: 0.46410575067480003\n",
      "Train Loss: 0.5442735255806536\n",
      "Validation Loss: 0.4640953789275094\n",
      "Train Loss: 0.5442728346042662\n",
      "Validation Loss: 0.4640850612530007\n",
      "Train Loss: 0.5442721503275858\n",
      "Validation Loss: 0.4640747976974853\n",
      "Train Loss: 0.544271472685976\n",
      "Validation Loss: 0.464064587469807\n",
      "Train Loss: 0.5442708016216261\n",
      "Validation Loss: 0.4640544307153331\n",
      "Train Loss: 0.5442701370659765\n",
      "Validation Loss: 0.4640443265951273\n",
      "Train Loss: 0.5442694789617756\n",
      "Validation Loss: 0.46403427496002325\n",
      "Train Loss: 0.5442688272380185\n",
      "Validation Loss: 0.46402427581027683\n",
      "Train Loss: 0.5442681818380651\n",
      "Validation Loss: 0.46401432870221804\n",
      "Train Loss: 0.5442675427008756\n",
      "Validation Loss: 0.4640044331438527\n",
      "Train Loss: 0.5442669097619899\n",
      "Validation Loss: 0.46399458918607556\n",
      "Train Loss: 0.5442662829614525\n",
      "Validation Loss: 0.4639847963380619\n",
      "Train Loss: 0.5442656622445703\n",
      "Validation Loss: 0.46397505415832235\n",
      "Train Loss: 0.5442650475488787\n",
      "Validation Loss: 0.4639653629949141\n",
      "Train Loss: 0.5442644388159169\n",
      "Validation Loss: 0.4639557223586288\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.544263835986877\n",
      "Validation Loss: 0.463946131169876\n",
      "Train Loss: 0.544263239006403\n",
      "Validation Loss: 0.4639365904179908\n",
      "Train Loss: 0.5442626478162433\n",
      "Validation Loss: 0.4639270987289976\n",
      "Train Loss: 0.5442620623611547\n",
      "Validation Loss: 0.46391765650226513\n",
      "Train Loss: 0.5442614825851111\n",
      "Validation Loss: 0.4639082632512871\n",
      "Train Loss: 0.5442609084329789\n",
      "Validation Loss: 0.4638989187855203\n",
      "Train Loss: 0.5442603398455437\n",
      "Validation Loss: 0.4638896228663786\n",
      "Train Loss: 0.544259776781441\n",
      "Validation Loss: 0.46388037485915884\n",
      "Train Loss: 0.5442592191786149\n",
      "Validation Loss: 0.4638711750684901\n",
      "Train Loss: 0.5442586669829804\n",
      "Validation Loss: 0.4638620227150806\n",
      "Train Loss: 0.5442581201376692\n",
      "Validation Loss: 0.46385291785780686\n",
      "Train Loss: 0.5442575786069465\n",
      "Validation Loss: 0.4638438596168687\n",
      "Train Loss: 0.5442570423266615\n",
      "Validation Loss: 0.4638348485458193\n",
      "Train Loss: 0.544256511244953\n",
      "Validation Loss: 0.4638258841627233\n",
      "Train Loss: 0.5442559853239339\n",
      "Validation Loss: 0.4638169664265315\n",
      "Train Loss: 0.5442554644993803\n",
      "Validation Loss: 0.4638080947110993\n",
      "Train Loss: 0.5442549487294374\n",
      "Validation Loss: 0.46379926863263277\n",
      "Train Loss: 0.5442544379603624\n",
      "Validation Loss: 0.4637904882532997\n",
      "Train Loss: 0.5442539321467312\n",
      "Validation Loss: 0.463781753141822\n",
      "Train Loss: 0.5442534312395858\n",
      "Validation Loss: 0.4637730631143164\n",
      "Train Loss: 0.544252935194644\n",
      "Validation Loss: 0.4637644180355766\n",
      "Train Loss: 0.5442524439633535\n",
      "Validation Loss: 0.4637558174273492\n",
      "Train Loss: 0.5442519574945186\n",
      "Validation Loss: 0.46374726164925867\n",
      "Train Loss: 0.5442514757401066\n",
      "Validation Loss: 0.46373874992880987\n",
      "Train Loss: 0.5442509986616002\n",
      "Validation Loss: 0.46373028218065904\n",
      "Train Loss: 0.5442505262124354\n",
      "Validation Loss: 0.46372185822348483\n",
      "Train Loss: 0.5442500583498406\n",
      "Validation Loss: 0.4637134773342169\n",
      "Train Loss: 0.5442495950280176\n",
      "Validation Loss: 0.4637051393324048\n",
      "Train Loss: 0.5442491361945013\n",
      "Validation Loss: 0.4636968448272552\n",
      "Train Loss: 0.5442486818114358\n",
      "Validation Loss: 0.4636885928499443\n",
      "Train Loss: 0.5442482318386361\n",
      "Validation Loss: 0.46368038356439994\n",
      "Train Loss: 0.5442477862311091\n",
      "Validation Loss: 0.46367221620159743\n",
      "Train Loss: 0.5442473449460746\n",
      "Validation Loss: 0.46366409146836524\n",
      "Train Loss: 0.5442469079425931\n",
      "Validation Loss: 0.4636560080543592\n",
      "Train Loss: 0.5442464751746272\n",
      "Validation Loss: 0.463647966619194\n",
      "Train Loss: 0.5442460466062953\n",
      "Validation Loss: 0.4636399661963786\n",
      "Train Loss: 0.5442456221958727\n",
      "Validation Loss: 0.46363200719912084\n",
      "Train Loss: 0.5442452019009428\n",
      "Validation Loss: 0.4636240891559044\n",
      "Train Loss: 0.544244785687258\n",
      "Validation Loss: 0.463616211691371\n",
      "Train Loss: 0.5442443735095267\n",
      "Validation Loss: 0.46360837458192\n",
      "Train Loss: 0.544243965334123\n",
      "Validation Loss: 0.4636005774528995\n",
      "Train Loss: 0.5442435611133376\n",
      "Validation Loss: 0.4635928206236358\n",
      "Train Loss: 0.5442431608142029\n",
      "Validation Loss: 0.46358510372016337\n",
      "Train Loss: 0.544242764396374\n",
      "Validation Loss: 0.46357742627327075\n",
      "Train Loss: 0.5442423718281175\n",
      "Validation Loss: 0.46356978849951674\n",
      "Train Loss: 0.5442419830659392\n",
      "Validation Loss: 0.46356218988263576\n",
      "Train Loss: 0.5442415980783519\n",
      "Validation Loss: 0.463554630344877\n",
      "Train Loss: 0.5442412168225629\n",
      "Validation Loss: 0.46354710937076177\n",
      "Train Loss: 0.5442408392676684\n",
      "Validation Loss: 0.4635396268831847\n",
      "Train Loss: 0.5442404653722326\n",
      "Validation Loss: 0.4635321829571953\n",
      "Train Loss: 0.544240095105586\n",
      "Validation Loss: 0.4635247772213938\n",
      "Train Loss: 0.5442397284266344\n",
      "Validation Loss: 0.4635174094566649\n",
      "Train Loss: 0.5442393653052783\n",
      "Validation Loss: 0.4635100792922575\n",
      "Train Loss: 0.5442390057086565\n",
      "Validation Loss: 0.4635027868997683\n",
      "Train Loss: 0.5442386495963176\n",
      "Validation Loss: 0.4634955317662813\n",
      "Train Loss: 0.5442382969425571\n",
      "Validation Loss: 0.46348831356949427\n",
      "Train Loss: 0.5442379477081783\n",
      "Validation Loss: 0.46348113238681166\n",
      "Train Loss: 0.5442376018640666\n",
      "Validation Loss: 0.4634739875541448\n",
      "Train Loss: 0.5442372593723072\n",
      "Validation Loss: 0.4634668797391483\n",
      "Train Loss: 0.544236920204005\n",
      "Validation Loss: 0.4634598079835397\n",
      "Train Loss: 0.5442365843250527\n",
      "Validation Loss: 0.4634527727082673\n",
      "Train Loss: 0.5442362517038786\n",
      "Validation Loss: 0.46344577320296715\n",
      "Train Loss: 0.5442359223132633\n",
      "Validation Loss: 0.4634388093945155\n",
      "Train Loss: 0.5442355961161425\n",
      "Validation Loss: 0.4634318813625306\n",
      "Train Loss: 0.544235273082379\n",
      "Validation Loss: 0.46342498898702733\n",
      "Train Loss: 0.5442349531814679\n",
      "Validation Loss: 0.4634181315588652\n",
      "Train Loss: 0.5442346363840799\n",
      "Validation Loss: 0.4634113092533398\n",
      "Train Loss: 0.5442343226605141\n",
      "Validation Loss: 0.4634045216565871\n",
      "Train Loss: 0.5442340119816207\n",
      "Validation Loss: 0.4633977686497176\n",
      "Train Loss: 0.5442337043151433\n",
      "Validation Loss: 0.4633910500668056\n",
      "Train Loss: 0.5442333996327606\n",
      "Validation Loss: 0.4633843660841785\n",
      "Train Loss: 0.5442330979054856\n",
      "Validation Loss: 0.4633777159944272\n",
      "Train Loss: 0.5442327991081742\n",
      "Validation Loss: 0.46337109943234894\n",
      "Train Loss: 0.5442325032071935\n",
      "Validation Loss: 0.46336451706980963\n",
      "Train Loss: 0.5442322101775807\n",
      "Validation Loss: 0.46335796824745673\n",
      "Train Loss: 0.5442319199918865\n",
      "Validation Loss: 0.4633514528482233\n",
      "Train Loss: 0.544231632616129\n",
      "Validation Loss: 0.46334497036633465\n",
      "Train Loss: 0.5442313480333608\n",
      "Validation Loss: 0.4633385211213986\n",
      "Train Loss: 0.5442310662100717\n",
      "Validation Loss: 0.4633321046081541\n",
      "Train Loss: 0.5442307871200562\n",
      "Validation Loss: 0.4633257210051423\n",
      "Train Loss: 0.5442305107428127\n",
      "Validation Loss: 0.4633193697016303\n",
      "Train Loss: 0.5442302370430168\n",
      "Validation Loss: 0.4633130507352594\n",
      "Train Loss: 0.5442299659977429\n",
      "Validation Loss: 0.4633067637432792\n",
      "Train Loss: 0.5442296975816642\n",
      "Validation Loss: 0.4633005089051511\n",
      "Train Loss: 0.5442294317691039\n",
      "Validation Loss: 0.4632942858114761\n",
      "Train Loss: 0.5442291685348842\n",
      "Validation Loss: 0.4632880943476354\n",
      "Train Loss: 0.5442289078543184\n",
      "Validation Loss: 0.4632819346937444\n",
      "Train Loss: 0.5442286497023731\n",
      "Validation Loss: 0.46327580644110705\n",
      "Train Loss: 0.5442283940539556\n",
      "Validation Loss: 0.46326970888679675\n",
      "Train Loss: 0.5442281408855613\n",
      "Validation Loss: 0.46326364280058446\n",
      "Train Loss: 0.5442278901694931\n",
      "Validation Loss: 0.4632576074330384\n",
      "Train Loss: 0.5442276418906279\n",
      "Validation Loss: 0.4632516025172921\n",
      "Train Loss: 0.5442273960194547\n",
      "Validation Loss: 0.4632456281408429\n",
      "Train Loss: 0.5442271525354418\n",
      "Validation Loss: 0.46323968423776674\n",
      "Train Loss: 0.544226911412008\n",
      "Validation Loss: 0.46323377035406993\n",
      "Train Loss: 0.5442266726287327\n",
      "Validation Loss: 0.46322788612982013\n",
      "Train Loss: 0.544226436160531\n",
      "Validation Loss: 0.4632220322892238\n",
      "Train Loss: 0.5442262019868185\n",
      "Validation Loss: 0.4632162078838816\n",
      "Train Loss: 0.5442259700824009\n",
      "Validation Loss: 0.463210413049588\n",
      "Train Loss: 0.5442257404275926\n",
      "Validation Loss: 0.46320464742721806\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442255130036279\n",
      "Validation Loss: 0.4631989115409819\n",
      "Train Loss: 0.5442252877822437\n",
      "Validation Loss: 0.463193204597291\n",
      "Train Loss: 0.5442250647499951\n",
      "Validation Loss: 0.46318752633118543\n",
      "Train Loss: 0.5442248438772163\n",
      "Validation Loss: 0.46318187708028297\n",
      "Train Loss: 0.5442246251502468\n",
      "Validation Loss: 0.4631762559912235\n",
      "Train Loss: 0.5442244085454948\n",
      "Validation Loss: 0.4631706634955626\n",
      "Train Loss: 0.5442241940393467\n",
      "Validation Loss: 0.4631650997307072\n",
      "Train Loss: 0.5442239816160149\n",
      "Validation Loss: 0.4631595640914125\n",
      "Train Loss: 0.54422377125451\n",
      "Validation Loss: 0.46315405617351985\n",
      "Train Loss: 0.54422356293202\n",
      "Validation Loss: 0.4631485764093514\n",
      "Train Loss: 0.5442233566306979\n",
      "Validation Loss: 0.463143124441827\n",
      "Train Loss: 0.5442231523301001\n",
      "Validation Loss: 0.4631376998673843\n",
      "Train Loss: 0.544222950010455\n",
      "Validation Loss: 0.4631323028712544\n",
      "Train Loss: 0.5442227496568349\n",
      "Validation Loss: 0.463126932849229\n",
      "Train Loss: 0.5442225512421638\n",
      "Validation Loss: 0.4631215904355568\n",
      "Train Loss: 0.5442223547569608\n",
      "Validation Loss: 0.46311627482531786\n",
      "Train Loss: 0.54422216017429\n",
      "Validation Loss: 0.46311098635886716\n",
      "Train Loss: 0.5442219674824732\n",
      "Validation Loss: 0.4631057244792514\n",
      "Train Loss: 0.5442217766573896\n",
      "Validation Loss: 0.46310048927955194\n",
      "Train Loss: 0.5442215876849701\n",
      "Validation Loss: 0.4630952801565693\n",
      "Train Loss: 0.5442214005469417\n",
      "Validation Loss: 0.46309009759107983\n",
      "Train Loss: 0.5442212152244871\n",
      "Validation Loss: 0.46308494118132687\n",
      "Train Loss: 0.5442210316966082\n",
      "Validation Loss: 0.46307981077346805\n",
      "Train Loss: 0.54422084995024\n",
      "Validation Loss: 0.46307470635335013\n",
      "Train Loss: 0.5442206699670303\n",
      "Validation Loss: 0.46306962751974595\n",
      "Train Loss: 0.544220491729254\n",
      "Validation Loss: 0.4630645744600029\n",
      "Train Loss: 0.5442203152216498\n",
      "Validation Loss: 0.46305954711387903\n",
      "Train Loss: 0.5442201404263177\n",
      "Validation Loss: 0.46305454508064453\n",
      "Train Loss: 0.5442199673255222\n",
      "Validation Loss: 0.46304956795976787\n",
      "Train Loss: 0.5442197959069128\n",
      "Validation Loss: 0.46304461573789124\n",
      "Train Loss: 0.5442196261511887\n",
      "Validation Loss: 0.46303968885082675\n",
      "Train Loss: 0.5442194580408276\n",
      "Validation Loss: 0.46303478660436154\n",
      "Train Loss: 0.5442192915591375\n",
      "Validation Loss: 0.46302990918690934\n",
      "Train Loss: 0.5442191266942554\n",
      "Validation Loss: 0.46302505658561055\n",
      "Train Loss: 0.5442189634268421\n",
      "Validation Loss: 0.46302022835450424\n",
      "Train Loss: 0.5442188017452602\n",
      "Validation Loss: 0.4630154244809889\n",
      "Train Loss: 0.5442186416306853\n",
      "Validation Loss: 0.46301064481355325\n",
      "Train Loss: 0.5442184830692967\n",
      "Validation Loss: 0.46300588929351677\n",
      "Train Loss: 0.5442183260449843\n",
      "Validation Loss: 0.4630011578160082\n",
      "Train Loss: 0.5442181705439519\n",
      "Validation Loss: 0.46299645002851575\n",
      "Train Loss: 0.5442180165527218\n",
      "Validation Loss: 0.46299176587274\n",
      "Train Loss: 0.54421786405556\n",
      "Validation Loss: 0.46298710524422515\n",
      "Train Loss: 0.5442177130370895\n",
      "Validation Loss: 0.4629824683327321\n",
      "Train Loss: 0.5442175634839868\n",
      "Validation Loss: 0.46297785478627274\n",
      "Train Loss: 0.5442174153807078\n",
      "Validation Loss: 0.4629732642067632\n",
      "Train Loss: 0.5442172687145831\n",
      "Validation Loss: 0.4629686968305984\n",
      "Train Loss: 0.5442171234726209\n",
      "Validation Loss: 0.46296415230617677\n",
      "Train Loss: 0.5442169796377649\n",
      "Validation Loss: 0.46295963077769914\n",
      "Train Loss: 0.5442168371993558\n",
      "Validation Loss: 0.4629551316460077\n",
      "Train Loss: 0.5442166961430764\n",
      "Validation Loss: 0.46295065539577823\n",
      "Train Loss: 0.5442165564539269\n",
      "Validation Loss: 0.46294620133573977\n",
      "Train Loss: 0.5442164181201052\n",
      "Validation Loss: 0.46294176999697756\n",
      "Train Loss: 0.5442162811290892\n",
      "Validation Loss: 0.4629373607346372\n",
      "Train Loss: 0.5442161454666338\n",
      "Validation Loss: 0.46293297344586887\n",
      "Train Loss: 0.5442160111212391\n",
      "Validation Loss: 0.4629286086620435\n",
      "Train Loss: 0.544215878078493\n",
      "Validation Loss: 0.46292426569256795\n",
      "Train Loss: 0.5442157463267093\n",
      "Validation Loss: 0.4629199444810717\n",
      "Train Loss: 0.544215615852307\n",
      "Validation Loss: 0.4629156452191623\n",
      "Train Loss: 0.5442154866434152\n",
      "Validation Loss: 0.4629113672627567\n",
      "Train Loss: 0.5442153586888415\n",
      "Validation Loss: 0.4629071108497684\n",
      "Train Loss: 0.5442152319749418\n",
      "Validation Loss: 0.46290287558424187\n",
      "Train Loss: 0.5442151064868368\n",
      "Validation Loss: 0.4628986622000984\n",
      "Train Loss: 0.5442149822210347\n",
      "Validation Loss: 0.4628944693560586\n",
      "Train Loss: 0.5442148591585726\n",
      "Validation Loss: 0.46289029769417384\n",
      "Train Loss: 0.5442147372905001\n",
      "Validation Loss: 0.4628861469110245\n",
      "Train Loss: 0.5442146166039091\n",
      "Validation Loss: 0.4628820169051884\n",
      "Train Loss: 0.5442144970882902\n",
      "Validation Loss: 0.46287790791526373\n",
      "Train Loss: 0.5442143787324643\n",
      "Validation Loss: 0.46287381900430835\n",
      "Train Loss: 0.5442142615243964\n",
      "Validation Loss: 0.4628697509529476\n",
      "Train Loss: 0.5442141454534777\n",
      "Validation Loss: 0.46286570341225797\n",
      "Train Loss: 0.5442140305091829\n",
      "Validation Loss: 0.46286167603342643\n",
      "Train Loss: 0.5442139166812552\n",
      "Validation Loss: 0.4628576687616257\n",
      "Train Loss: 0.5442138039556472\n",
      "Validation Loss: 0.4628536817441434\n",
      "Train Loss: 0.544213692326168\n",
      "Validation Loss: 0.4628497147243194\n",
      "Train Loss: 0.5442135817767787\n",
      "Validation Loss: 0.46284576750987877\n",
      "Train Loss: 0.5442134722996225\n",
      "Validation Loss: 0.46284184009231016\n",
      "Train Loss: 0.5442133638848936\n",
      "Validation Loss: 0.46283793241726384\n",
      "Train Loss: 0.5442132565228633\n",
      "Validation Loss: 0.46283404443047144\n",
      "Train Loss: 0.544213150201557\n",
      "Validation Loss: 0.4628301754442153\n",
      "Train Loss: 0.5442130449117848\n",
      "Validation Loss: 0.46282632599211226\n",
      "Train Loss: 0.5442129406419499\n",
      "Validation Loss: 0.4628224956805009\n",
      "Train Loss: 0.544212837384799\n",
      "Validation Loss: 0.4628186847951578\n",
      "Train Loss: 0.5442127351306603\n",
      "Validation Loss: 0.4628148926946188\n",
      "Train Loss: 0.5442126338667941\n",
      "Validation Loss: 0.46281111982114786\n",
      "Train Loss: 0.5442125335858181\n",
      "Validation Loss: 0.46280736587311966\n",
      "Train Loss: 0.5442124342784871\n",
      "Validation Loss: 0.4628036305031775\n",
      "Train Loss: 0.5442123359323575\n",
      "Validation Loss: 0.46279991415386945\n",
      "Train Loss: 0.544212238541809\n",
      "Validation Loss: 0.4627962159820187\n",
      "Train Loss: 0.5442121420945768\n",
      "Validation Loss: 0.46279253643035706\n",
      "Train Loss: 0.5442120465837915\n",
      "Validation Loss: 0.4627888754914355\n",
      "Train Loss: 0.544211952000427\n",
      "Validation Loss: 0.46278523252456166\n",
      "Train Loss: 0.5442118583345186\n",
      "Validation Loss: 0.4627816083122389\n",
      "Train Loss: 0.5442117655768753\n",
      "Validation Loss: 0.46277800162644106\n",
      "Train Loss: 0.5442116737195412\n",
      "Validation Loss: 0.46277441329556257\n",
      "Train Loss: 0.5442115827503222\n",
      "Validation Loss: 0.46277084288160686\n",
      "Train Loss: 0.5442114926662223\n",
      "Validation Loss: 0.4627672901752314\n",
      "Train Loss: 0.5442114034553593\n",
      "Validation Loss: 0.4627637550323694\n",
      "Train Loss: 0.5442113151115313\n",
      "Validation Loss: 0.4627602377398657\n",
      "Train Loss: 0.5442112276248329\n",
      "Validation Loss: 0.4627567381995122\n",
      "Train Loss: 0.5442111409869158\n",
      "Validation Loss: 0.4627532557714282\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442110551899806\n",
      "Validation Loss: 0.4627497906969872\n",
      "Train Loss: 0.5442109702227718\n",
      "Validation Loss: 0.46274634312632396\n",
      "Train Loss: 0.5442108860808491\n",
      "Validation Loss: 0.46274291280482055\n",
      "Train Loss: 0.5442108027562874\n",
      "Validation Loss: 0.46273949938662534\n",
      "Train Loss: 0.5442107202364959\n",
      "Validation Loss: 0.4627361032702048\n",
      "Train Loss: 0.5442106385189255\n",
      "Validation Loss: 0.46273272424673917\n",
      "Train Loss: 0.544210557594125\n",
      "Validation Loss: 0.4627293619249918\n",
      "Train Loss: 0.544210477454604\n",
      "Validation Loss: 0.46272601625311666\n",
      "Train Loss: 0.5442103980930868\n",
      "Validation Loss: 0.4627226874730062\n",
      "Train Loss: 0.5442103195018982\n",
      "Validation Loss: 0.46271937494559134\n",
      "Train Loss: 0.5442102416723533\n",
      "Validation Loss: 0.46271607916099683\n",
      "Train Loss: 0.544210164595552\n",
      "Validation Loss: 0.46271280002208814\n",
      "Train Loss: 0.5442100882690548\n",
      "Validation Loss: 0.4627095370267122\n",
      "Train Loss: 0.5442100126823933\n",
      "Validation Loss: 0.4627062900323164\n",
      "Train Loss: 0.544209937830325\n",
      "Validation Loss: 0.4627030593267155\n",
      "Train Loss: 0.5442098637041967\n",
      "Validation Loss: 0.4626998448130484\n",
      "Train Loss: 0.5442097902954453\n",
      "Validation Loss: 0.4626966463945484\n",
      "Train Loss: 0.5442097175988511\n",
      "Validation Loss: 0.46269346406555584\n",
      "Train Loss: 0.5442096456089283\n",
      "Validation Loss: 0.4626902972331891\n",
      "Train Loss: 0.544209574316114\n",
      "Validation Loss: 0.46268714663626237\n",
      "Train Loss: 0.5442095037147555\n",
      "Validation Loss: 0.462684011094796\n",
      "Train Loss: 0.5442094338000983\n",
      "Validation Loss: 0.4626808911905766\n",
      "Train Loss: 0.5442093645625007\n",
      "Validation Loss: 0.46267778707537616\n",
      "Train Loss: 0.5442092959954528\n",
      "Validation Loss: 0.46267469869838546\n",
      "Train Loss: 0.5442092280967921\n",
      "Validation Loss: 0.46267162526441297\n",
      "Train Loss: 0.5442091608556432\n",
      "Validation Loss: 0.46266856717359284\n",
      "Train Loss: 0.5442090942672194\n",
      "Validation Loss: 0.46266552442073694\n",
      "Train Loss: 0.5442090283222475\n",
      "Validation Loss: 0.462662497157986\n",
      "Train Loss: 0.5442089630202626\n",
      "Validation Loss: 0.4626594846357789\n",
      "Train Loss: 0.5442088983506894\n",
      "Validation Loss: 0.4626564872545351\n",
      "Train Loss: 0.544208834307259\n",
      "Validation Loss: 0.4626535046702873\n",
      "Train Loss: 0.54420877088555\n",
      "Validation Loss: 0.46265053717166615\n",
      "Train Loss: 0.5442087080806165\n",
      "Validation Loss: 0.4626475838730677\n",
      "Train Loss: 0.5442086458824711\n",
      "Validation Loss: 0.46264464576233605\n",
      "Train Loss: 0.54420858429066\n",
      "Validation Loss: 0.4626417217965852\n",
      "Train Loss: 0.5442085232938245\n",
      "Validation Loss: 0.46263881291838976\n",
      "Train Loss: 0.5442084628885924\n",
      "Validation Loss: 0.462635917994231\n",
      "Train Loss: 0.5442084030695729\n",
      "Validation Loss: 0.46263303785472115\n",
      "Train Loss: 0.5442083438294189\n",
      "Validation Loss: 0.4626301721109947\n",
      "Train Loss: 0.5442082851651173\n",
      "Validation Loss: 0.46262732021676056\n",
      "Train Loss: 0.544208227069813\n",
      "Validation Loss: 0.46262448266387324\n",
      "Train Loss: 0.5442081695377788\n",
      "Validation Loss: 0.4626216591089917\n",
      "Train Loss: 0.5442081125635985\n",
      "Validation Loss: 0.46261884979587553\n",
      "Train Loss: 0.5442080561429469\n",
      "Validation Loss: 0.46261605413308743\n",
      "Train Loss: 0.5442080002691851\n",
      "Validation Loss: 0.46261327261268076\n",
      "Train Loss: 0.5442079449380722\n",
      "Validation Loss: 0.462610504643321\n",
      "Train Loss: 0.5442078901432024\n",
      "Validation Loss: 0.4626077510106591\n",
      "Train Loss: 0.544207835881441\n",
      "Validation Loss: 0.462605010288239\n",
      "Train Loss: 0.544207782145196\n",
      "Validation Loss: 0.46260228351002536\n",
      "Train Loss: 0.544207728930516\n",
      "Validation Loss: 0.46259957037837235\n",
      "Train Loss: 0.5442076762308241\n",
      "Validation Loss: 0.4625968707986433\n",
      "Train Loss: 0.5442076240448822\n",
      "Validation Loss: 0.4625941842703135\n",
      "Train Loss: 0.5442075723638086\n",
      "Validation Loss: 0.4625915114887809\n",
      "Train Loss: 0.5442075211849271\n",
      "Validation Loss: 0.46258885161487195\n",
      "Train Loss: 0.5442074705007384\n",
      "Validation Loss: 0.46258620509587844\n",
      "Train Loss: 0.5442074203089993\n",
      "Validation Loss: 0.4625835719731189\n",
      "Train Loss: 0.5442073706045251\n",
      "Validation Loss: 0.4625809516105567\n",
      "Train Loss: 0.5442073213813227\n",
      "Validation Loss: 0.46257834450084706\n",
      "Train Loss: 0.544207272636981\n",
      "Validation Loss: 0.4625757500984832\n",
      "Train Loss: 0.5442072243654656\n",
      "Validation Loss: 0.4625731686027412\n",
      "Train Loss: 0.5442071765606895\n",
      "Validation Loss: 0.46257059991951077\n",
      "Train Loss: 0.5442071292192596\n",
      "Validation Loss: 0.46256804404511387\n",
      "Train Loss: 0.5442070823388709\n",
      "Validation Loss: 0.46256550043419303\n",
      "Train Loss: 0.5442070359125987\n",
      "Validation Loss: 0.4625629698279031\n",
      "Train Loss: 0.5442069899357251\n",
      "Validation Loss: 0.46256045188405864\n",
      "Train Loss: 0.5442069444048636\n",
      "Validation Loss: 0.4625579463056873\n",
      "Train Loss: 0.5442068993180429\n",
      "Validation Loss: 0.4625554531344181\n",
      "Train Loss: 0.5442068546681819\n",
      "Validation Loss: 0.4625529722313048\n",
      "Train Loss: 0.5442068104496731\n",
      "Validation Loss: 0.46255050379604534\n",
      "Train Loss: 0.5442067666605328\n",
      "Validation Loss: 0.46254804757695617\n",
      "Train Loss: 0.5442067232962566\n",
      "Validation Loss: 0.4625456032321161\n",
      "Train Loss: 0.5442066803514696\n",
      "Validation Loss: 0.46254317125475053\n",
      "Train Loss: 0.5442066378253855\n",
      "Validation Loss: 0.462540751144967\n",
      "Train Loss: 0.544206595710205\n",
      "Validation Loss: 0.4625383433058276\n",
      "Train Loss: 0.5442065540039536\n",
      "Validation Loss: 0.4625359471924024\n",
      "Train Loss: 0.54420651270253\n",
      "Validation Loss: 0.4625335630497619\n",
      "Train Loss: 0.5442064718016497\n",
      "Validation Loss: 0.462531190536235\n",
      "Train Loss: 0.5442064312972873\n",
      "Validation Loss: 0.4625288298969662\n",
      "Train Loss: 0.5442063911852351\n",
      "Validation Loss: 0.46252648079037156\n",
      "Train Loss: 0.5442063514650418\n",
      "Validation Loss: 0.46252414330349345\n",
      "Train Loss: 0.5442063121303471\n",
      "Validation Loss: 0.4625218175914096\n",
      "Train Loss: 0.5442062731747648\n",
      "Validation Loss: 0.46251950351590426\n",
      "Train Loss: 0.5442062345978117\n",
      "Validation Loss: 0.4625172008707284\n",
      "Train Loss: 0.5442061963943621\n",
      "Validation Loss: 0.46251490956280283\n",
      "Train Loss: 0.5442061585616972\n",
      "Validation Loss: 0.46251262958918343\n",
      "Train Loss: 0.5442061210971114\n",
      "Validation Loss: 0.4625103609469408\n",
      "Train Loss: 0.5442060839954831\n",
      "Validation Loss: 0.4625081032497616\n",
      "Train Loss: 0.5442060472541685\n",
      "Validation Loss: 0.46250585649479026\n",
      "Train Loss: 0.5442060108683388\n",
      "Validation Loss: 0.46250362088250135\n",
      "Train Loss: 0.544205974835511\n",
      "Validation Loss: 0.4625013967034304\n",
      "Train Loss: 0.5442059391529052\n",
      "Validation Loss: 0.4624991833681072\n",
      "Train Loss: 0.5442059038157955\n",
      "Validation Loss: 0.46249698107710696\n",
      "Train Loss: 0.544205868821667\n",
      "Validation Loss: 0.46249478982770165\n",
      "Train Loss: 0.5442058341680169\n",
      "Validation Loss: 0.46249260961717664\n",
      "Train Loss: 0.5442057998499175\n",
      "Validation Loss: 0.46249043976623017\n",
      "Train Loss: 0.5442057658650262\n",
      "Validation Loss: 0.46248828056554603\n",
      "Train Loss: 0.5442057322076893\n",
      "Validation Loss: 0.46248613217090695\n",
      "Train Loss: 0.5442056988787392\n",
      "Validation Loss: 0.46248399442130705\n",
      "Train Loss: 0.5442056658725768\n",
      "Validation Loss: 0.46248186747258124\n",
      "Train Loss: 0.5442056331866555\n",
      "Validation Loss: 0.46247975073556513\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442056008166634\n",
      "Validation Loss: 0.4624776447044525\n",
      "Train Loss: 0.5442055687612878\n",
      "Validation Loss: 0.46247554912838823\n",
      "Train Loss: 0.5442055370170578\n",
      "Validation Loss: 0.46247346366665204\n",
      "Train Loss: 0.5442055055797557\n",
      "Validation Loss: 0.46247138881352046\n",
      "Train Loss: 0.5442054744490878\n",
      "Validation Loss: 0.4624693240698336\n",
      "Train Loss: 0.5442054436217465\n",
      "Validation Loss: 0.4624672693882457\n",
      "Train Loss: 0.5442054130924414\n",
      "Validation Loss: 0.46246522492490244\n",
      "Train Loss: 0.5442053828590063\n",
      "Validation Loss: 0.46246319067745395\n",
      "Train Loss: 0.5442053529191915\n",
      "Validation Loss: 0.46246116635028467\n",
      "Train Loss: 0.5442053232688683\n",
      "Validation Loss: 0.46245915214455746\n",
      "Train Loss: 0.5442052939067802\n",
      "Validation Loss: 0.4624571475163372\n",
      "Train Loss: 0.5442052648289479\n",
      "Validation Loss: 0.46245515296011763\n",
      "Train Loss: 0.5442052360342345\n",
      "Validation Loss: 0.4624531682252677\n",
      "Train Loss: 0.5442052075186212\n",
      "Validation Loss: 0.4624511935130563\n",
      "Train Loss: 0.5442051792798914\n",
      "Validation Loss: 0.462449228234756\n",
      "Train Loss: 0.5442051513132693\n",
      "Validation Loss: 0.4624472731333584\n",
      "Train Loss: 0.544205123618611\n",
      "Validation Loss: 0.46244532770992736\n",
      "Train Loss: 0.5442050961928389\n",
      "Validation Loss: 0.46244339162420406\n",
      "Train Loss: 0.5442050690330853\n",
      "Validation Loss: 0.46244146512246737\n",
      "Train Loss: 0.5442050421364208\n",
      "Validation Loss: 0.46243954815777016\n",
      "Train Loss: 0.5442050155008405\n",
      "Validation Loss: 0.4624376404347945\n",
      "Train Loss: 0.5442049891244394\n",
      "Validation Loss: 0.4624357419514824\n",
      "Train Loss: 0.5442049630035463\n",
      "Validation Loss: 0.4624338532025972\n",
      "Train Loss: 0.5442049371370962\n",
      "Validation Loss: 0.46243197364447297\n",
      "Train Loss: 0.5442049115204153\n",
      "Validation Loss: 0.462430103433865\n",
      "Train Loss: 0.5442048861517769\n",
      "Validation Loss: 0.46242824286203293\n",
      "Train Loss: 0.5442048610300733\n",
      "Validation Loss: 0.4624263910921477\n",
      "Train Loss: 0.5442048361517653\n",
      "Validation Loss: 0.4624245486190941\n",
      "Train Loss: 0.5442048115149947\n",
      "Validation Loss: 0.46242271514772876\n",
      "Train Loss: 0.5442047871179134\n",
      "Validation Loss: 0.46242089038292833\n",
      "Train Loss: 0.5442047629569771\n",
      "Validation Loss: 0.4624190745264338\n",
      "Train Loss: 0.5442047390296177\n",
      "Validation Loss: 0.4624172678248084\n",
      "Train Loss: 0.5442047153341378\n",
      "Validation Loss: 0.4624154702762072\n",
      "Train Loss: 0.5442046918687646\n",
      "Validation Loss: 0.4624136815855891\n",
      "Train Loss: 0.5442046686308981\n",
      "Validation Loss: 0.4624119017063624\n",
      "Train Loss: 0.5442046456197955\n",
      "Validation Loss: 0.462410130681499\n",
      "Train Loss: 0.5442046228318892\n",
      "Validation Loss: 0.46240836812647385\n",
      "Train Loss: 0.5442046002647267\n",
      "Validation Loss: 0.4624066142879649\n",
      "Train Loss: 0.5442045779157982\n",
      "Validation Loss: 0.46240486911947587\n",
      "Train Loss: 0.5442045557843341\n",
      "Validation Loss: 0.46240313237084696\n",
      "Train Loss: 0.5442045338679307\n",
      "Validation Loss: 0.4624014042888019\n",
      "Train Loss: 0.5442045121633187\n",
      "Validation Loss: 0.4623996850753389\n",
      "Train Loss: 0.5442044906696848\n",
      "Validation Loss: 0.4623979741871559\n",
      "Train Loss: 0.5442044693837262\n",
      "Validation Loss: 0.4623962715331236\n",
      "Train Loss: 0.5442044483056868\n",
      "Validation Loss: 0.4623945772010663\n",
      "Train Loss: 0.5442044274306308\n",
      "Validation Loss: 0.46239289130361455\n",
      "Train Loss: 0.5442044067596135\n",
      "Validation Loss: 0.4623912136801583\n",
      "Train Loss: 0.5442043862877596\n",
      "Validation Loss: 0.4623895444433877\n",
      "Train Loss: 0.5442043660144857\n",
      "Validation Loss: 0.46238788363644506\n",
      "Train Loss: 0.5442043459381897\n",
      "Validation Loss: 0.4623862306714313\n",
      "Train Loss: 0.5442043260566584\n",
      "Validation Loss: 0.46238458579525493\n",
      "Train Loss: 0.5442043063677008\n",
      "Validation Loss: 0.46238294925484014\n",
      "Train Loss: 0.5442042868706053\n",
      "Validation Loss: 0.4623813205070436\n",
      "Train Loss: 0.5442042675632791\n",
      "Validation Loss: 0.4623797000919681\n",
      "Train Loss: 0.544204248441755\n",
      "Validation Loss: 0.4623780875809009\n",
      "Train Loss: 0.5442042295063494\n",
      "Validation Loss: 0.4623764830617447\n",
      "Train Loss: 0.5442042107548741\n",
      "Validation Loss: 0.4623748864883489\n",
      "Train Loss: 0.5442041921843412\n",
      "Validation Loss: 0.46237329776991465\n",
      "Train Loss: 0.5442041737949275\n",
      "Validation Loss: 0.462371716408072\n",
      "Train Loss: 0.544204155583155\n",
      "Validation Loss: 0.46237014343995775\n",
      "Train Loss: 0.5442041375483253\n",
      "Validation Loss: 0.4623685780294117\n",
      "Train Loss: 0.5442041196883394\n",
      "Validation Loss: 0.462367020130383\n",
      "Train Loss: 0.5442041020011924\n",
      "Validation Loss: 0.46236546998997546\n",
      "Train Loss: 0.5442040844863538\n",
      "Validation Loss: 0.46236392735834253\n",
      "Train Loss: 0.54420406714191\n",
      "Validation Loss: 0.46236239277573143\n",
      "Train Loss: 0.5442040499640995\n",
      "Validation Loss: 0.4623608655206181\n",
      "Train Loss: 0.5442040329532929\n",
      "Validation Loss: 0.46235934568097076\n",
      "Train Loss: 0.5442040161091234\n",
      "Validation Loss: 0.4623578335932208\n",
      "Train Loss: 0.5442039994271758\n",
      "Validation Loss: 0.4623563287844108\n",
      "Train Loss: 0.5442039829077572\n",
      "Validation Loss: 0.462354831049401\n",
      "Train Loss: 0.5442039665482725\n",
      "Validation Loss: 0.4623533408838969\n",
      "Train Loss: 0.5442039503467202\n",
      "Validation Loss: 0.46235185794890693\n",
      "Train Loss: 0.5442039343034828\n",
      "Validation Loss: 0.46235038233241366\n",
      "Train Loss: 0.5442039184151155\n",
      "Validation Loss: 0.4623489138993357\n",
      "Train Loss: 0.5442039026806306\n",
      "Validation Loss: 0.4623474532346635\n",
      "Train Loss: 0.5442038870994573\n",
      "Validation Loss: 0.4623459995024677\n",
      "Train Loss: 0.5442038716690409\n",
      "Validation Loss: 0.4623445529054448\n",
      "Train Loss: 0.5442038563889635\n",
      "Validation Loss: 0.46234311319390203\n",
      "Train Loss: 0.5442038412567063\n",
      "Validation Loss: 0.46234168057056996\n",
      "Train Loss: 0.5442038262711939\n",
      "Validation Loss: 0.4623402550342833\n",
      "Train Loss: 0.5442038114306216\n",
      "Validation Loss: 0.46233883653930075\n",
      "Train Loss: 0.5442037967346667\n",
      "Validation Loss: 0.4623374251290572\n",
      "Train Loss: 0.5442037821814764\n",
      "Validation Loss: 0.46233602046474437\n",
      "Train Loss: 0.5442037677693486\n",
      "Validation Loss: 0.4623346227937504\n",
      "Train Loss: 0.5442037534965347\n",
      "Validation Loss: 0.4623332320703939\n",
      "Train Loss: 0.544203739362022\n",
      "Validation Loss: 0.4623318482935758\n",
      "Train Loss: 0.5442037253654528\n",
      "Validation Loss: 0.46233047121368426\n",
      "Train Loss: 0.544203711504458\n",
      "Validation Loss: 0.4623291010335907\n",
      "Train Loss: 0.5442036977773432\n",
      "Validation Loss: 0.4623277377076711\n",
      "Train Loss: 0.5442036841837131\n",
      "Validation Loss: 0.46232638069327453\n",
      "Train Loss: 0.5442036707220179\n",
      "Validation Loss: 0.46232503053094604\n",
      "Train Loss: 0.5442036573911694\n",
      "Validation Loss: 0.46232368663350476\n",
      "Train Loss: 0.544203644189012\n",
      "Validation Loss: 0.4623223497900425\n",
      "Train Loss: 0.5442036311151773\n",
      "Validation Loss: 0.4623210194579458\n",
      "Train Loss: 0.5442036181673544\n",
      "Validation Loss: 0.46231969554713936\n",
      "Train Loss: 0.544203605345997\n",
      "Validation Loss: 0.46231837814568943\n",
      "Train Loss: 0.5442035926481975\n",
      "Validation Loss: 0.4623170674120768\n",
      "Train Loss: 0.5442035800736766\n",
      "Validation Loss: 0.4623157630967926\n",
      "Train Loss: 0.5442035676215344\n",
      "Validation Loss: 0.4623144651988625\n",
      "Train Loss: 0.5442035552902055\n",
      "Validation Loss: 0.4623131736728037\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442035430780815\n",
      "Validation Loss: 0.4623118881801022\n",
      "Train Loss: 0.5442035309850197\n",
      "Validation Loss: 0.46231060905737836\n",
      "Train Loss: 0.5442035190088266\n",
      "Validation Loss: 0.4623093362146801\n",
      "Train Loss: 0.5442035071493102\n",
      "Validation Loss: 0.4623080696955872\n",
      "Train Loss: 0.5442034954049619\n",
      "Validation Loss: 0.4623068094546766\n",
      "Train Loss: 0.5442034837742316\n",
      "Validation Loss: 0.46230555515350374\n",
      "Train Loss: 0.5442034722569988\n",
      "Validation Loss: 0.46230430712870496\n",
      "Train Loss: 0.5442034608511419\n",
      "Validation Loss: 0.4623030652904035\n",
      "Train Loss: 0.5442034495564348\n",
      "Validation Loss: 0.46230182938917097\n",
      "Train Loss: 0.5442034383702635\n",
      "Validation Loss: 0.46230059987675043\n",
      "Train Loss: 0.5442034272929998\n",
      "Validation Loss: 0.4622993762551805\n",
      "Train Loss: 0.5442034163232712\n",
      "Validation Loss: 0.46229815877215497\n",
      "Train Loss: 0.5442034054602365\n",
      "Validation Loss: 0.46229694713379504\n",
      "Train Loss: 0.54420339470192\n",
      "Validation Loss: 0.4622957415433475\n",
      "Train Loss: 0.5442033840475626\n",
      "Validation Loss: 0.46229454199998704\n",
      "Train Loss: 0.5442033734975374\n",
      "Validation Loss: 0.46229334800577476\n",
      "Train Loss: 0.5442033630493369\n",
      "Validation Loss: 0.4622921600125486\n",
      "Train Loss: 0.5442033527028359\n",
      "Validation Loss: 0.4622909780639604\n",
      "Train Loss: 0.5442033424571804\n",
      "Validation Loss: 0.46228980157317057\n",
      "Train Loss: 0.5442033323099171\n",
      "Validation Loss: 0.4622886309920646\n",
      "Train Loss: 0.5442033222614913\n",
      "Validation Loss: 0.4622874661157499\n",
      "Train Loss: 0.5442033123106312\n",
      "Validation Loss: 0.4622863071920103\n",
      "Train Loss: 0.5442033024559718\n",
      "Validation Loss: 0.46228515388262315\n",
      "Train Loss: 0.54420329269741\n",
      "Validation Loss: 0.4622840062312684\n",
      "Train Loss: 0.5442032830324615\n",
      "Validation Loss: 0.4622828641038821\n",
      "Train Loss: 0.544203273462169\n",
      "Validation Loss: 0.4622817273400226\n",
      "Train Loss: 0.5442032639853014\n",
      "Validation Loss: 0.46228059618751366\n",
      "Train Loss: 0.5442032545994716\n",
      "Validation Loss: 0.46227947080533777\n",
      "Train Loss: 0.5442032453046041\n",
      "Validation Loss: 0.46227835123719996\n",
      "Train Loss: 0.5442032360999316\n",
      "Validation Loss: 0.4622772368963854\n",
      "Train Loss: 0.5442032269853724\n",
      "Validation Loss: 0.46227612782660166\n",
      "Train Loss: 0.5442032179591684\n",
      "Validation Loss: 0.46227502423130096\n",
      "Train Loss: 0.5442032090195857\n",
      "Validation Loss: 0.46227392631395536\n",
      "Train Loss: 0.5442032001665161\n",
      "Validation Loss: 0.4622728338253007\n",
      "Train Loss: 0.5442031913997936\n",
      "Validation Loss: 0.46227174622308315\n",
      "Train Loss: 0.544203182718886\n",
      "Validation Loss: 0.46227066409259704\n",
      "Train Loss: 0.544203174122043\n",
      "Validation Loss: 0.4622695873443599\n",
      "Train Loss: 0.5442031656080959\n",
      "Validation Loss: 0.46226851593331103\n",
      "Train Loss: 0.5442031571764434\n",
      "Validation Loss: 0.46226744985879775\n",
      "Train Loss: 0.5442031488274912\n",
      "Validation Loss: 0.4622663886229929\n",
      "Train Loss: 0.544203140558583\n",
      "Validation Loss: 0.46226533292662564\n",
      "Train Loss: 0.5442031323701845\n",
      "Validation Loss: 0.46226428256485846\n",
      "Train Loss: 0.5442031242616577\n",
      "Validation Loss: 0.4622632372440768\n",
      "Train Loss: 0.5442031162313353\n",
      "Validation Loss: 0.4622621968748891\n",
      "Train Loss: 0.544203108279237\n",
      "Validation Loss: 0.4622611617940315\n",
      "Train Loss: 0.5442031004036704\n",
      "Validation Loss: 0.462260131619163\n",
      "Train Loss: 0.5442030926051479\n",
      "Validation Loss: 0.4622591064384282\n",
      "Train Loss: 0.5442030848815593\n",
      "Validation Loss: 0.46225808641107585\n",
      "Train Loss: 0.5442030772338995\n",
      "Validation Loss: 0.46225707137664956\n",
      "Train Loss: 0.5442030696600316\n",
      "Validation Loss: 0.46225606120145346\n",
      "Train Loss: 0.5442030621594676\n",
      "Validation Loss: 0.4622550561778703\n",
      "Train Loss: 0.5442030547316269\n",
      "Validation Loss: 0.4622540560123594\n",
      "Train Loss: 0.5442030473759797\n",
      "Validation Loss: 0.46225306070434696\n",
      "Train Loss: 0.5442030400920447\n",
      "Validation Loss: 0.4622520705462201\n",
      "Train Loss: 0.5442030328786915\n",
      "Validation Loss: 0.46225108490714434\n",
      "Train Loss: 0.544203025735452\n",
      "Validation Loss: 0.46225010407952144\n",
      "Train Loss: 0.5442030186608442\n",
      "Validation Loss: 0.4622491282670596\n",
      "Train Loss: 0.544203011654832\n",
      "Validation Loss: 0.4622481572206091\n",
      "Train Loss: 0.5442030047173728\n",
      "Validation Loss: 0.4622471906910185\n",
      "Train Loss: 0.5442029978470522\n",
      "Validation Loss: 0.4622462291749681\n",
      "Train Loss: 0.5442029910428388\n",
      "Validation Loss: 0.4622452723346427\n",
      "Train Loss: 0.5442029843052006\n",
      "Validation Loss: 0.462244319965243\n",
      "Train Loss: 0.544202977633244\n",
      "Validation Loss: 0.46224337260780113\n",
      "Train Loss: 0.5442029710254178\n",
      "Validation Loss: 0.4622424295872512\n",
      "Train Loss: 0.5442029644817911\n",
      "Validation Loss: 0.46224149124036046\n",
      "Train Loss: 0.5442029580014089\n",
      "Validation Loss: 0.46224055752229803\n",
      "Train Loss: 0.5442029515838119\n",
      "Validation Loss: 0.4622396284325653\n",
      "Train Loss: 0.544202945228586\n",
      "Validation Loss: 0.46223870426360314\n",
      "Train Loss: 0.5442029389342316\n",
      "Validation Loss: 0.46223778434041174\n",
      "Train Loss: 0.5442029327021732\n",
      "Validation Loss: 0.4622368685468357\n",
      "Train Loss: 0.5442029265306109\n",
      "Validation Loss: 0.4622359573353144\n",
      "Train Loss: 0.5442029204186309\n",
      "Validation Loss: 0.4622350506610605\n",
      "Train Loss: 0.5442029143662286\n",
      "Validation Loss: 0.46223414827497994\n",
      "Train Loss: 0.5442029083721166\n",
      "Validation Loss: 0.4622332506738527\n",
      "Train Loss: 0.5442029024362961\n",
      "Validation Loss: 0.46223235760859016\n",
      "Train Loss: 0.5442028965582576\n",
      "Validation Loss: 0.46223146849287755\n",
      "Train Loss: 0.5442028907371592\n",
      "Validation Loss: 0.46223058357489044\n",
      "Train Loss: 0.5442028849726277\n",
      "Validation Loss: 0.4622297031471048\n",
      "Train Loss: 0.5442028792637937\n",
      "Validation Loss: 0.4622288271647796\n",
      "Train Loss: 0.5442028736102527\n",
      "Validation Loss: 0.46222795562747465\n",
      "Train Loss: 0.5442028680115614\n",
      "Validation Loss: 0.4622270882418325\n",
      "Train Loss: 0.5442028624669106\n",
      "Validation Loss: 0.4622262252560546\n",
      "Train Loss: 0.5442028569762751\n",
      "Validation Loss: 0.4622253661281633\n",
      "Train Loss: 0.5442028515388945\n",
      "Validation Loss: 0.4622245113992848\n",
      "Train Loss: 0.5442028461539372\n",
      "Validation Loss: 0.4622236610247185\n",
      "Train Loss: 0.5442028408213849\n",
      "Validation Loss: 0.4622228144625005\n",
      "Train Loss: 0.5442028355409332\n",
      "Validation Loss: 0.46222197229804296\n",
      "Train Loss: 0.5442028303117236\n",
      "Validation Loss: 0.4622211341937475\n",
      "Train Loss: 0.544202825132987\n",
      "Validation Loss: 0.4622203003978497\n",
      "Train Loss: 0.5442028200047117\n",
      "Validation Loss: 0.462219470368402\n",
      "Train Loss: 0.5442028149261752\n",
      "Validation Loss: 0.4622186446465556\n",
      "Train Loss: 0.5442028098969379\n",
      "Validation Loss: 0.4622178226461052\n",
      "Train Loss: 0.5442028049163291\n",
      "Validation Loss: 0.46221700520111536\n",
      "Train Loss: 0.5442027999842666\n",
      "Validation Loss: 0.4622161911838454\n",
      "Train Loss: 0.5442027951000867\n",
      "Validation Loss: 0.4622153814283642\n",
      "Train Loss: 0.5442027902634022\n",
      "Validation Loss: 0.4622145756413903\n",
      "Train Loss: 0.5442027854730306\n",
      "Validation Loss: 0.46221377373404415\n",
      "Train Loss: 0.5442027807290913\n",
      "Validation Loss: 0.46221297604311146\n",
      "Train Loss: 0.5442027760315855\n",
      "Validation Loss: 0.46221218202667746\n",
      "Train Loss: 0.544202771379348\n",
      "Validation Loss: 0.4622113915958845\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442027667724976\n",
      "Validation Loss: 0.46221060508751716\n",
      "Train Loss: 0.5442027622103301\n",
      "Validation Loss: 0.46220982274986616\n",
      "Train Loss: 0.5442027576924836\n",
      "Validation Loss: 0.46220904428968346\n",
      "Train Loss: 0.5442027532185615\n",
      "Validation Loss: 0.4622082691208376\n",
      "Train Loss: 0.5442027487879496\n",
      "Validation Loss: 0.4622074980774184\n",
      "Train Loss: 0.5442027443999329\n",
      "Validation Loss: 0.46220673111484745\n",
      "Train Loss: 0.5442027400548917\n",
      "Validation Loss: 0.46220596744258985\n",
      "Train Loss: 0.5442027357517891\n",
      "Validation Loss: 0.46220520755762096\n",
      "Train Loss: 0.5442027314907149\n",
      "Validation Loss: 0.4622044515038376\n",
      "Train Loss: 0.5442027272705764\n",
      "Validation Loss: 0.46220369919245424\n",
      "Train Loss: 0.5442027230910778\n",
      "Validation Loss: 0.4622029506231494\n",
      "Train Loss: 0.5442027189526315\n",
      "Validation Loss: 0.46220220529828426\n",
      "Train Loss: 0.5442027148542314\n",
      "Validation Loss: 0.4622014637148564\n",
      "Train Loss: 0.5442027107960052\n",
      "Validation Loss: 0.4622007262096452\n",
      "Train Loss: 0.5442027067768228\n",
      "Validation Loss: 0.46219999210814006\n",
      "Train Loss: 0.5442027027967824\n",
      "Validation Loss: 0.4621992614542504\n",
      "Train Loss: 0.5442026988552187\n",
      "Validation Loss: 0.4621985342034556\n",
      "Train Loss: 0.544202694951886\n",
      "Validation Loss: 0.4621978106483286\n",
      "Train Loss: 0.5442026910864717\n",
      "Validation Loss: 0.4621970904956928\n",
      "Train Loss: 0.5442026872583591\n",
      "Validation Loss: 0.4621963739939159\n",
      "Train Loss: 0.5442026834676491\n",
      "Validation Loss: 0.462195661186907\n",
      "Train Loss: 0.5442026797136641\n",
      "Validation Loss: 0.4621949517372953\n",
      "Train Loss: 0.5442026759961696\n",
      "Validation Loss: 0.46219424593766106\n",
      "Train Loss: 0.5442026723145327\n",
      "Validation Loss: 0.46219354374351507\n",
      "Train Loss: 0.544202668668825\n",
      "Validation Loss: 0.4621928449059042\n",
      "Train Loss: 0.5442026650584204\n",
      "Validation Loss: 0.4621921493803491\n",
      "Train Loss: 0.5442026614830618\n",
      "Validation Loss: 0.4621914571665726\n",
      "Train Loss: 0.5442026579421343\n",
      "Validation Loss: 0.4621907682201072\n",
      "Train Loss: 0.5442026544361036\n",
      "Validation Loss: 0.4621900826290621\n",
      "Train Loss: 0.5442026509633204\n",
      "Validation Loss: 0.4621894005092699\n",
      "Train Loss: 0.5442026475242239\n",
      "Validation Loss: 0.4621887216559823\n",
      "Train Loss: 0.5442026441189206\n",
      "Validation Loss: 0.46218804611311826\n",
      "Train Loss: 0.5442026407464915\n",
      "Validation Loss: 0.4621873740849018\n",
      "Train Loss: 0.5442026374066665\n",
      "Validation Loss: 0.4621867052782153\n",
      "Train Loss: 0.5442026340995246\n",
      "Validation Loss: 0.46218603944412484\n",
      "Train Loss: 0.5442026308242279\n",
      "Validation Loss: 0.46218537737258486\n",
      "Train Loss: 0.5442026275807658\n",
      "Validation Loss: 0.46218471793609944\n",
      "Train Loss: 0.544202624368656\n",
      "Validation Loss: 0.4621840619688079\n",
      "Train Loss: 0.5442026211876706\n",
      "Validation Loss: 0.462183409470461\n",
      "Train Loss: 0.544202618037583\n",
      "Validation Loss: 0.46218276044081086\n",
      "Train Loss: 0.5442026149181067\n",
      "Validation Loss: 0.4621821142939108\n",
      "Train Loss: 0.544202611828713\n",
      "Validation Loss: 0.46218147127820325\n",
      "Train Loss: 0.5442026087694875\n",
      "Validation Loss: 0.46218083114476916\n",
      "Train Loss: 0.5442026057399363\n",
      "Validation Loss: 0.4621801944349021\n",
      "Train Loss: 0.5442026027397835\n",
      "Validation Loss: 0.46217956056267306\n",
      "Train Loss: 0.5442025997688147\n",
      "Validation Loss: 0.46217892952785183\n",
      "Train Loss: 0.5442025968268754\n",
      "Validation Loss: 0.46217830191589815\n",
      "Train Loss: 0.5442025939130717\n",
      "Validation Loss: 0.46217767734542214\n",
      "Train Loss: 0.5442025910272302\n",
      "Validation Loss: 0.4621770561090465\n",
      "Train Loss: 0.5442025881697365\n",
      "Validation Loss: 0.46217643770917394\n",
      "Train Loss: 0.5442025853397681\n",
      "Validation Loss: 0.46217582235011684\n",
      "Train Loss: 0.5442025825374163\n",
      "Validation Loss: 0.4621752097829696\n",
      "Train Loss: 0.5442025797625071\n",
      "Validation Loss: 0.46217460030035346\n",
      "Train Loss: 0.5442025770145223\n",
      "Validation Loss: 0.4621739938579023\n",
      "Train Loss: 0.5442025742929506\n",
      "Validation Loss: 0.4621733904112575\n",
      "Train Loss: 0.5442025715975728\n",
      "Validation Loss: 0.4621727896673764\n",
      "Train Loss: 0.544202568928823\n",
      "Validation Loss: 0.462172191714339\n",
      "Train Loss: 0.5442025662859111\n",
      "Validation Loss: 0.46217159675648634\n",
      "Train Loss: 0.5442025636683957\n",
      "Validation Loss: 0.4621710053351411\n",
      "Train Loss: 0.5442025610763176\n",
      "Validation Loss: 0.4621704166157401\n",
      "Train Loss: 0.5442025585094911\n",
      "Validation Loss: 0.4621698305980836\n",
      "Train Loss: 0.544202555967454\n",
      "Validation Loss: 0.46216924753066907\n",
      "Train Loss: 0.5442025534505779\n",
      "Validation Loss: 0.4621686669159072\n",
      "Train Loss: 0.5442025509575514\n",
      "Validation Loss: 0.46216808945556004\n",
      "Train Loss: 0.5442025484887506\n",
      "Validation Loss: 0.4621675146520444\n",
      "Train Loss: 0.5442025460440253\n",
      "Validation Loss: 0.4621669427979966\n",
      "Train Loss: 0.5442025436228753\n",
      "Validation Loss: 0.4621663735562719\n",
      "Train Loss: 0.5442025412254784\n",
      "Validation Loss: 0.4621658075564617\n",
      "Train Loss: 0.5442025388512861\n",
      "Validation Loss: 0.462165243875777\n",
      "Train Loss: 0.5442025364999157\n",
      "Validation Loss: 0.46216468334838573\n",
      "Train Loss: 0.5442025341717324\n",
      "Validation Loss: 0.4621641254767028\n",
      "Train Loss: 0.5442025318656689\n",
      "Validation Loss: 0.4621635698353639\n",
      "Train Loss: 0.5442025295819334\n",
      "Validation Loss: 0.4621630173467807\n",
      "Train Loss: 0.5442025273208599\n",
      "Validation Loss: 0.462162467220547\n",
      "Train Loss: 0.5442025250814744\n",
      "Validation Loss: 0.46216191990977645\n",
      "Train Loss: 0.5442025228639042\n",
      "Validation Loss: 0.4621613754584117\n",
      "Train Loss: 0.544202520667707\n",
      "Validation Loss: 0.4621608338221666\n",
      "Train Loss: 0.5442025184929841\n",
      "Validation Loss: 0.4621602947521661\n",
      "Train Loss: 0.5442025163390174\n",
      "Validation Loss: 0.46215975816002164\n",
      "Train Loss: 0.5442025142062153\n",
      "Validation Loss: 0.46215922413378796\n",
      "Train Loss: 0.5442025120938919\n",
      "Validation Loss: 0.46215869287789824\n",
      "Train Loss: 0.5442025100021506\n",
      "Validation Loss: 0.4621581641434824\n",
      "Train Loss: 0.5442025079308406\n",
      "Validation Loss: 0.462157637930378\n",
      "Train Loss: 0.5442025058795631\n",
      "Validation Loss: 0.4621571144871321\n",
      "Train Loss: 0.5442025038479004\n",
      "Validation Loss: 0.46215659376948526\n",
      "Train Loss: 0.5442025018362041\n",
      "Validation Loss: 0.4621560752798616\n",
      "Train Loss: 0.5442024998440818\n",
      "Validation Loss: 0.4621555592668153\n",
      "Train Loss: 0.5442024978714143\n",
      "Validation Loss: 0.4621550460230002\n",
      "Train Loss: 0.5442024959177679\n",
      "Validation Loss: 0.4621545352113572\n",
      "Train Loss: 0.5442024939832466\n",
      "Validation Loss: 0.46215402658302424\n",
      "Train Loss: 0.5442024920674928\n",
      "Validation Loss: 0.46215352067937077\n",
      "Train Loss: 0.5442024901701068\n",
      "Validation Loss: 0.46215301745615567\n",
      "Train Loss: 0.5442024882911708\n",
      "Validation Loss: 0.4621525163717149\n",
      "Train Loss: 0.5442024864303363\n",
      "Validation Loss: 0.4621520179674229\n",
      "Train Loss: 0.5442024845877081\n",
      "Validation Loss: 0.46215152199442083\n",
      "Train Loss: 0.5442024827626135\n",
      "Validation Loss: 0.4621510280715893\n",
      "Train Loss: 0.5442024809552297\n",
      "Validation Loss: 0.4621505368284822\n",
      "Train Loss: 0.5442024791656368\n",
      "Validation Loss: 0.4621500477234396\n",
      "Train Loss: 0.5442024773934722\n",
      "Validation Loss: 0.4621495610050392\n",
      "Train Loss: 0.5442024756388609\n",
      "Validation Loss: 0.46214907671722366\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442024739006887\n",
      "Validation Loss: 0.46214859497633176\n",
      "Train Loss: 0.544202472179546\n",
      "Validation Loss: 0.4621481153288754\n",
      "Train Loss: 0.5442024704751028\n",
      "Validation Loss: 0.4621476383162379\n",
      "Train Loss: 0.544202468787193\n",
      "Validation Loss: 0.46214716335269296\n",
      "Train Loss: 0.5442024671157404\n",
      "Validation Loss: 0.4621466910237025\n",
      "Train Loss: 0.5442024654601109\n",
      "Validation Loss: 0.46214622094819263\n",
      "Train Loss: 0.5442024638206588\n",
      "Validation Loss: 0.4621457529213912\n",
      "Train Loss: 0.5442024621972873\n",
      "Validation Loss: 0.46214528723596476\n",
      "Train Loss: 0.5442024605898776\n",
      "Validation Loss: 0.46214482389178474\n",
      "Train Loss: 0.5442024589978304\n",
      "Validation Loss: 0.46214436280058663\n",
      "Train Loss: 0.5442024574212748\n",
      "Validation Loss: 0.4621439040063174\n",
      "Train Loss: 0.5442024558601191\n",
      "Validation Loss: 0.46214344780164474\n",
      "Train Loss: 0.5442024543139912\n",
      "Validation Loss: 0.46214299384958984\n",
      "Train Loss: 0.54420245278274\n",
      "Validation Loss: 0.46214254156445617\n",
      "Train Loss: 0.5442024512665354\n",
      "Validation Loss: 0.46214209157576935\n",
      "Train Loss: 0.5442024497650324\n",
      "Validation Loss: 0.46214164383934786\n",
      "Train Loss: 0.5442024482778908\n",
      "Validation Loss: 0.4621411983110153\n",
      "Train Loss: 0.5442024468054707\n",
      "Validation Loss: 0.46214075507877667\n",
      "Train Loss: 0.544202445347181\n",
      "Validation Loss: 0.46214031376161246\n",
      "Train Loss: 0.544202443902961\n",
      "Validation Loss: 0.4621398749449832\n",
      "Train Loss: 0.5442024424726879\n",
      "Validation Loss: 0.46213943833599197\n",
      "Train Loss: 0.544202441056447\n",
      "Validation Loss: 0.4621390033930155\n",
      "Train Loss: 0.5442024396539289\n",
      "Validation Loss: 0.4621385703646747\n",
      "Train Loss: 0.5442024382650743\n",
      "Validation Loss: 0.4621381398364269\n",
      "Train Loss: 0.5442024368895391\n",
      "Validation Loss: 0.4621377114713293\n",
      "Train Loss: 0.5442024355274498\n",
      "Validation Loss: 0.4621372853133267\n",
      "Train Loss: 0.5442024341786681\n",
      "Validation Loss: 0.46213686077675137\n",
      "Train Loss: 0.5442024328429151\n",
      "Validation Loss: 0.46213643840301166\n",
      "Train Loss: 0.544202431520116\n",
      "Validation Loss: 0.46213601848478375\n",
      "Train Loss: 0.5442024302099188\n",
      "Validation Loss: 0.46213560039236107\n",
      "Train Loss: 0.5442024289126677\n",
      "Validation Loss: 0.46213518421373484\n",
      "Train Loss: 0.5442024276278534\n",
      "Validation Loss: 0.46213477015349325\n",
      "Train Loss: 0.5442024263557977\n",
      "Validation Loss: 0.4621343580068459\n",
      "Train Loss: 0.5442024250959963\n",
      "Validation Loss: 0.4621339479783849\n",
      "Train Loss: 0.544202423848147\n",
      "Validation Loss: 0.4621335400239736\n",
      "Train Loss: 0.5442024226125889\n",
      "Validation Loss: 0.4621331342315962\n",
      "Train Loss: 0.5442024213887898\n",
      "Validation Loss: 0.462132730220304\n",
      "Train Loss: 0.544202420177086\n",
      "Validation Loss: 0.4621323280780806\n",
      "Train Loss: 0.5442024189770068\n",
      "Validation Loss: 0.4621319283023031\n",
      "Train Loss: 0.5442024177886206\n",
      "Validation Loss: 0.4621315300585968\n",
      "Train Loss: 0.5442024166118787\n",
      "Validation Loss: 0.46213113393241434\n",
      "Train Loss: 0.5442024154464895\n",
      "Validation Loss: 0.46213073987962966\n",
      "Train Loss: 0.5442024142923337\n",
      "Validation Loss: 0.46213034731461217\n",
      "Train Loss: 0.544202413149385\n",
      "Validation Loss: 0.4621299571155849\n",
      "Train Loss: 0.5442024120175251\n",
      "Validation Loss: 0.46212956869691874\n",
      "Train Loss: 0.5442024108966729\n",
      "Validation Loss: 0.46212918205852677\n",
      "Train Loss: 0.5442024097867482\n",
      "Validation Loss: 0.4621287972003223\n",
      "Train Loss: 0.5442024086874886\n",
      "Validation Loss: 0.46212841437096064\n",
      "Train Loss: 0.5442024075989984\n",
      "Validation Loss: 0.46212803332161556\n",
      "Train Loss: 0.5442024065210179\n",
      "Validation Loss: 0.46212765430094377\n",
      "Train Loss: 0.5442024054534531\n",
      "Validation Loss: 0.4621272770160964\n",
      "Train Loss: 0.5442024043964245\n",
      "Validation Loss: 0.4621269015110138\n",
      "Train Loss: 0.5442024033496765\n",
      "Validation Loss: 0.4621265280343557\n",
      "Train Loss: 0.5442024023129218\n",
      "Validation Loss: 0.46212615624925485\n",
      "Train Loss: 0.544202401286089\n",
      "Validation Loss: 0.4621257861556347\n",
      "Train Loss: 0.5442024002691237\n",
      "Validation Loss: 0.4621254180461808\n",
      "Train Loss: 0.5442023992621291\n",
      "Validation Loss: 0.46212505167206996\n",
      "Train Loss: 0.5442023982650317\n",
      "Validation Loss: 0.46212468703322296\n",
      "Train Loss: 0.544202397277396\n",
      "Validation Loss: 0.4621243243342917\n",
      "Train Loss: 0.5442023962995153\n",
      "Validation Loss: 0.4621239633704699\n",
      "Train Loss: 0.5442023953311292\n",
      "Validation Loss: 0.4621236040976665\n",
      "Train Loss: 0.5442023943719982\n",
      "Validation Loss: 0.46212324676455335\n",
      "Train Loss: 0.5442023934223778\n",
      "Validation Loss: 0.4621228905808043\n",
      "Train Loss: 0.5442023924820618\n",
      "Validation Loss: 0.4621225363806096\n",
      "Train Loss: 0.5442023915507979\n",
      "Validation Loss: 0.4621221841198848\n",
      "Train Loss: 0.5442023906283368\n",
      "Validation Loss: 0.46212183375454857\n",
      "Train Loss: 0.5442023897149482\n",
      "Validation Loss: 0.4621214847870344\n",
      "Train Loss: 0.5442023888103998\n",
      "Validation Loss: 0.46212113746602096\n",
      "Train Loss: 0.5442023879146436\n",
      "Validation Loss: 0.4621207920841937\n",
      "Train Loss: 0.5442023870275992\n",
      "Validation Loss: 0.46212044834872756\n",
      "Train Loss: 0.5442023861491866\n",
      "Validation Loss: 0.46212010596679887\n",
      "Train Loss: 0.544202385279197\n",
      "Validation Loss: 0.46211976547984546\n",
      "Train Loss: 0.5442023844177306\n",
      "Validation Loss: 0.4621194266390493\n",
      "Train Loss: 0.5442023835645485\n",
      "Validation Loss: 0.46211908940034135\n",
      "Train Loss: 0.544202382719782\n",
      "Validation Loss: 0.4621187541004094\n",
      "Train Loss: 0.5442023818831785\n",
      "Validation Loss: 0.4621184204024338\n",
      "Train Loss: 0.5442023810546786\n",
      "Validation Loss: 0.46211808830634965\n",
      "Train Loss: 0.5442023802342076\n",
      "Validation Loss: 0.4621177575193429\n",
      "Train Loss: 0.5442023794215662\n",
      "Validation Loss: 0.4621174285828549\n",
      "Train Loss: 0.5442023786168386\n",
      "Validation Loss: 0.4621171009553202\n",
      "Train Loss: 0.5442023778198269\n",
      "Validation Loss: 0.46211677517818056\n",
      "Train Loss: 0.5442023770306148\n",
      "Validation Loss: 0.46211645070987145\n",
      "Train Loss: 0.54420237624916\n",
      "Validation Loss: 0.4621161278430803\n",
      "Train Loss: 0.5442023754754052\n",
      "Validation Loss: 0.4621158065777451\n",
      "Train Loss: 0.5442023747091412\n",
      "Validation Loss: 0.4621154871625599\n",
      "Train Loss: 0.5442023739502988\n",
      "Validation Loss: 0.46211516930471686\n",
      "Train Loss: 0.5442023731986584\n",
      "Validation Loss: 0.46211485296016785\n",
      "Train Loss: 0.5442023724541685\n",
      "Validation Loss: 0.4621145381288567\n",
      "Train Loss: 0.5442023717171204\n",
      "Validation Loss: 0.4621142251914506\n",
      "Train Loss: 0.5442023709870883\n",
      "Validation Loss: 0.4621139131816776\n",
      "Train Loss: 0.544202370264228\n",
      "Validation Loss: 0.4621136030217061\n",
      "Train Loss: 0.544202369548472\n",
      "Validation Loss: 0.4621132944187333\n",
      "Train Loss: 0.544202368839607\n",
      "Validation Loss: 0.46211298732871703\n",
      "Train Loss: 0.544202368137569\n",
      "Validation Loss: 0.4621126814588603\n",
      "Train Loss: 0.5442023674424818\n",
      "Validation Loss: 0.4621123771458368\n",
      "Train Loss: 0.544202366753977\n",
      "Validation Loss: 0.4621120743016246\n",
      "Train Loss: 0.5442023660721514\n",
      "Validation Loss: 0.4621117726774134\n",
      "Train Loss: 0.5442023653968415\n",
      "Validation Loss: 0.4621114731073934\n",
      "Train Loss: 0.5442023647284127\n",
      "Validation Loss: 0.46211117455249034\n",
      "Train Loss: 0.5442023640663883\n",
      "Validation Loss: 0.4621108777589311\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442023634106945\n",
      "Validation Loss: 0.4621105821411848\n",
      "Train Loss: 0.5442023627612996\n",
      "Validation Loss: 0.46211028799194226\n",
      "Train Loss: 0.5442023621181717\n",
      "Validation Loss: 0.46210999560389304\n",
      "Train Loss: 0.5442023614812382\n",
      "Validation Loss: 0.46210970439150967\n",
      "Train Loss: 0.5442023608507709\n",
      "Validation Loss: 0.4621094147354341\n",
      "Train Loss: 0.5442023602262545\n",
      "Validation Loss: 0.46210912621095024\n",
      "Train Loss: 0.5442023596076602\n",
      "Validation Loss: 0.4621088391107502\n",
      "Train Loss: 0.5442023589952447\n",
      "Validation Loss: 0.46210855352273505\n",
      "Train Loss: 0.5442023583888129\n",
      "Validation Loss: 0.46210826940288174\n",
      "Train Loss: 0.5442023577881729\n",
      "Validation Loss: 0.4621079867071703\n",
      "Train Loss: 0.5442023571934174\n",
      "Validation Loss: 0.4621077051867915\n",
      "Train Loss: 0.544202356604236\n",
      "Validation Loss: 0.46210742533922766\n",
      "Train Loss: 0.5442023560210008\n",
      "Validation Loss: 0.4621071467108758\n",
      "Train Loss: 0.5442023554433896\n",
      "Validation Loss: 0.4621068695064835\n",
      "Train Loss: 0.5442023548713357\n",
      "Validation Loss: 0.4621065931405393\n",
      "Train Loss: 0.5442023543048378\n",
      "Validation Loss: 0.46210631849120104\n",
      "Train Loss: 0.5442023537438422\n",
      "Validation Loss: 0.46210604526569055\n",
      "Train Loss: 0.5442023531883089\n",
      "Validation Loss: 0.462105773463964\n",
      "Train Loss: 0.5442023526381853\n",
      "Validation Loss: 0.4621055027932461\n",
      "Train Loss: 0.544202352093444\n",
      "Validation Loss: 0.46210523354622585\n",
      "Train Loss: 0.5442023515540334\n",
      "Validation Loss: 0.4621049654301292\n",
      "Train Loss: 0.5442023510196475\n",
      "Validation Loss: 0.4621046986497183\n",
      "Train Loss: 0.5442023504905289\n",
      "Validation Loss: 0.4621044332928801\n",
      "Train Loss: 0.5442023499666385\n",
      "Validation Loss: 0.46210416935957177\n",
      "Train Loss: 0.5442023494477878\n",
      "Validation Loss: 0.4621039065130605\n",
      "Train Loss: 0.5442023489338279\n",
      "Validation Loss: 0.4621036452948048\n",
      "Train Loss: 0.5442023484249598\n",
      "Validation Loss: 0.46210338491449965\n",
      "Train Loss: 0.5442023479211581\n",
      "Validation Loss: 0.4621031256648336\n",
      "Train Loss: 0.5442023474221391\n",
      "Validation Loss: 0.4621028680433056\n",
      "Train Loss: 0.5442023469278567\n",
      "Validation Loss: 0.4621026117571492\n",
      "Train Loss: 0.5442023464383868\n",
      "Validation Loss: 0.46210235626483076\n",
      "Train Loss: 0.5442023459535971\n",
      "Validation Loss: 0.462102102400537\n",
      "Train Loss: 0.5442023454735622\n",
      "Validation Loss: 0.4621018496227336\n",
      "Train Loss: 0.544202344998259\n",
      "Validation Loss: 0.46210159822410873\n",
      "Train Loss: 0.5442023445275099\n",
      "Validation Loss: 0.46210134786794427\n",
      "Train Loss: 0.5442023440613054\n",
      "Validation Loss: 0.4621010991396555\n",
      "Train Loss: 0.5442023435995891\n",
      "Validation Loss: 0.4621008514537557\n",
      "Train Loss: 0.5442023431424575\n",
      "Validation Loss: 0.4621006048541628\n",
      "Train Loss: 0.5442023426898767\n",
      "Validation Loss: 0.46210035934084026\n",
      "Train Loss: 0.5442023422415568\n",
      "Validation Loss: 0.46210011482584934\n",
      "Train Loss: 0.5442023417976064\n",
      "Validation Loss: 0.46209987164583166\n",
      "Train Loss: 0.5442023413579936\n",
      "Validation Loss: 0.46209962980075225\n",
      "Train Loss: 0.5442023409225605\n",
      "Validation Loss: 0.4620993892466269\n",
      "Train Loss: 0.5442023404913912\n",
      "Validation Loss: 0.46209914973464883\n",
      "Train Loss: 0.5442023400644543\n",
      "Validation Loss: 0.4620989112647851\n",
      "Train Loss: 0.5442023396416058\n",
      "Validation Loss: 0.46209867408577604\n",
      "Train Loss: 0.5442023392229397\n",
      "Validation Loss: 0.462098438241536\n",
      "Train Loss: 0.5442023388082909\n",
      "Validation Loss: 0.4620982033953644\n",
      "Train Loss: 0.5442023383976415\n",
      "Validation Loss: 0.46209796983995033\n",
      "Train Loss: 0.5442023379909515\n",
      "Validation Loss: 0.4620977372825418\n",
      "Train Loss: 0.5442023375881924\n",
      "Validation Loss: 0.46209750572310826\n",
      "Train Loss: 0.5442023371893568\n",
      "Validation Loss: 0.4620972757470578\n",
      "Train Loss: 0.5442023367945041\n",
      "Validation Loss: 0.4620970465201441\n",
      "Train Loss: 0.5442023364032675\n",
      "Validation Loss: 0.4620968184959459\n",
      "Train Loss: 0.544202336015968\n",
      "Validation Loss: 0.46209659151354326\n",
      "Train Loss: 0.5442023356323394\n",
      "Validation Loss: 0.4620963654850216\n",
      "Train Loss: 0.5442023352524838\n",
      "Validation Loss: 0.46209614074701116\n",
      "Train Loss: 0.5442023348762456\n",
      "Validation Loss: 0.4620959169628242\n",
      "Train Loss: 0.5442023345037155\n",
      "Validation Loss: 0.4620956941763723\n",
      "Train Loss: 0.5442023341348765\n",
      "Validation Loss: 0.4620954726803425\n",
      "Train Loss: 0.5442023337694702\n",
      "Validation Loss: 0.4620952523868283\n",
      "Train Loss: 0.5442023334076818\n",
      "Validation Loss: 0.4620950327982464\n",
      "Train Loss: 0.5442023330494946\n",
      "Validation Loss: 0.4620948142072847\n",
      "Train Loss: 0.5442023326946748\n",
      "Validation Loss: 0.46209459711147155\n",
      "Train Loss: 0.5442023323431882\n",
      "Validation Loss: 0.46209438121806473\n",
      "Train Loss: 0.5442023319952265\n",
      "Validation Loss: 0.46209416632219474\n",
      "Train Loss: 0.5442023316506511\n",
      "Validation Loss: 0.4620939523798981\n",
      "Train Loss: 0.5442023313094373\n",
      "Validation Loss: 0.4620937393911484\n",
      "Train Loss: 0.5442023309714494\n",
      "Validation Loss: 0.4620935273119858\n",
      "Train Loss: 0.5442023306366746\n",
      "Validation Loss: 0.46209331643509827\n",
      "Train Loss: 0.5442023303051895\n",
      "Validation Loss: 0.46209310651168056\n",
      "Train Loss: 0.5442023299770697\n",
      "Validation Loss: 0.462092897292926\n",
      "Train Loss: 0.5442023296519924\n",
      "Validation Loss: 0.4620926895251501\n",
      "Train Loss: 0.5442023293301238\n",
      "Validation Loss: 0.46209248241805484\n",
      "Train Loss: 0.5442023290113517\n",
      "Validation Loss: 0.4620922765131081\n",
      "Train Loss: 0.5442023286957514\n",
      "Validation Loss: 0.46209207156150345\n",
      "Train Loss: 0.5442023283830951\n",
      "Validation Loss: 0.4620918677680682\n",
      "Train Loss: 0.544202328073459\n",
      "Validation Loss: 0.46209166488399744\n",
      "Train Loss: 0.5442023277669268\n",
      "Validation Loss: 0.4620914629531957\n",
      "Train Loss: 0.5442023274633607\n",
      "Validation Loss: 0.4620912616390004\n",
      "Train Loss: 0.5442023271627671\n",
      "Validation Loss: 0.46209106181951803\n",
      "Train Loss: 0.5442023268651055\n",
      "Validation Loss: 0.46209086290930484\n",
      "Train Loss: 0.54420232657026\n",
      "Validation Loss: 0.4620906651571206\n",
      "Train Loss: 0.5442023262783985\n",
      "Validation Loss: 0.462090468065377\n",
      "Train Loss: 0.5442023259892087\n",
      "Validation Loss: 0.46209027208769193\n",
      "Train Loss: 0.5442023257028583\n",
      "Validation Loss: 0.4620900767264778\n",
      "Train Loss: 0.5442023254193447\n",
      "Validation Loss: 0.46208988256712835\n",
      "Train Loss: 0.5442023251385453\n",
      "Validation Loss: 0.46208968956569685\n",
      "Train Loss: 0.5442023248604319\n",
      "Validation Loss: 0.4620894974294541\n",
      "Train Loss: 0.5442023245849849\n",
      "Validation Loss: 0.46208930615837934\n",
      "Train Loss: 0.5442023243123845\n",
      "Validation Loss: 0.46208911584029627\n",
      "Train Loss: 0.5442023240424104\n",
      "Validation Loss: 0.4620889263873378\n",
      "Train Loss: 0.5442023237750436\n",
      "Validation Loss: 0.46208873779948345\n",
      "Train Loss: 0.5442023235101757\n",
      "Validation Loss: 0.4620885503254985\n",
      "Train Loss: 0.5442023232478782\n",
      "Validation Loss: 0.4620883637165774\n",
      "Train Loss: 0.544202322988035\n",
      "Validation Loss: 0.4620881779287807\n",
      "Train Loss: 0.5442023227308223\n",
      "Validation Loss: 0.46208799304992787\n",
      "Train Loss: 0.544202322476124\n",
      "Validation Loss: 0.4620878090360786\n",
      "Train Loss: 0.5442023222239216\n",
      "Validation Loss: 0.46208762588721336\n",
      "Train Loss: 0.5442023219741013\n",
      "Validation Loss: 0.4620874435593947\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442023217267496\n",
      "Validation Loss: 0.46208726238922504\n",
      "Train Loss: 0.5442023214817369\n",
      "Validation Loss: 0.4620870817473605\n",
      "Train Loss: 0.5442023212391489\n",
      "Validation Loss: 0.4620869019704032\n",
      "Train Loss: 0.5442023209988823\n",
      "Validation Loss: 0.46208672330712086\n",
      "Train Loss: 0.5442023207610053\n",
      "Validation Loss: 0.4620865455087075\n",
      "Train Loss: 0.5442023205254918\n",
      "Validation Loss: 0.4620863682824414\n",
      "Train Loss: 0.5442023202921562\n",
      "Validation Loss: 0.4620861921258798\n",
      "Train Loss: 0.5442023200610835\n",
      "Validation Loss: 0.4620860173756216\n",
      "Train Loss: 0.5442023198322323\n",
      "Validation Loss: 0.4620858431535427\n",
      "Train Loss: 0.5442023196056778\n",
      "Validation Loss: 0.4620856695035392\n",
      "Train Loss: 0.5442023193813282\n",
      "Validation Loss: 0.4620854969670833\n",
      "Train Loss: 0.5442023191590695\n",
      "Validation Loss: 0.4620853252075436\n",
      "Train Loss: 0.544202318939066\n",
      "Validation Loss: 0.46208515431272756\n",
      "Train Loss: 0.5442023187212116\n",
      "Validation Loss: 0.4620849842387058\n",
      "Train Loss: 0.5442023185053938\n",
      "Validation Loss: 0.46208481464885026\n",
      "Train Loss: 0.5442023182917024\n",
      "Validation Loss: 0.46208464617245604\n",
      "Train Loss: 0.5442023180800261\n",
      "Validation Loss: 0.462084478472896\n",
      "Train Loss: 0.5442023178703581\n",
      "Validation Loss: 0.4620843118428543\n",
      "Train Loss: 0.5442023176628427\n",
      "Validation Loss: 0.46208414578473433\n",
      "Train Loss: 0.544202317457298\n",
      "Validation Loss: 0.46208398050340066\n",
      "Train Loss: 0.5442023172537098\n",
      "Validation Loss: 0.4620838159988383\n",
      "Train Loss: 0.5442023170521499\n",
      "Validation Loss: 0.4620836523149396\n",
      "Train Loss: 0.5442023168525179\n",
      "Validation Loss: 0.4620834894077808\n",
      "Train Loss: 0.5442023166548846\n",
      "Validation Loss: 0.4620833273212539\n",
      "Train Loss: 0.5442023164591507\n",
      "Validation Loss: 0.4620831660114361\n",
      "Train Loss: 0.544202316265379\n",
      "Validation Loss: 0.46208300522952145\n",
      "Train Loss: 0.5442023160734023\n",
      "Validation Loss: 0.46208284547307743\n",
      "Train Loss: 0.5442023158832842\n",
      "Validation Loss: 0.4620826864932984\n",
      "Train Loss: 0.5442023156949354\n",
      "Validation Loss: 0.46208252853896153\n",
      "Train Loss: 0.5442023155084114\n",
      "Validation Loss: 0.46208237106856437\n",
      "Train Loss: 0.5442023153237882\n",
      "Validation Loss: 0.4620822144186929\n",
      "Train Loss: 0.544202315140888\n",
      "Validation Loss: 0.4620820585015249\n",
      "Train Loss: 0.5442023149597801\n",
      "Validation Loss: 0.46208190336094995\n",
      "Train Loss: 0.5442023147804512\n",
      "Validation Loss: 0.4620817489969538\n",
      "Train Loss: 0.544202314602815\n",
      "Validation Loss: 0.46208159565831514\n",
      "Train Loss: 0.5442023144269251\n",
      "Validation Loss: 0.4620814428035325\n",
      "Train Loss: 0.5442023142526962\n",
      "Validation Loss: 0.4620812906813859\n",
      "Train Loss: 0.5442023140801956\n",
      "Validation Loss: 0.4620811393357631\n",
      "Train Loss: 0.5442023139094105\n",
      "Validation Loss: 0.4620809887666501\n",
      "Train Loss: 0.5442023137402425\n",
      "Validation Loss: 0.46208083863743965\n",
      "Train Loss: 0.5442023135727585\n",
      "Validation Loss: 0.46208068899201893\n",
      "Train Loss: 0.5442023134068887\n",
      "Validation Loss: 0.46208054066455584\n",
      "Train Loss: 0.5442023132426078\n",
      "Validation Loss: 0.4620803930696504\n",
      "Train Loss: 0.5442023130799744\n",
      "Validation Loss: 0.4620802459584955\n",
      "Train Loss: 0.5442023129189062\n",
      "Validation Loss: 0.46208009957987306\n",
      "Train Loss: 0.5442023127593988\n",
      "Validation Loss: 0.46207995422646303\n",
      "Train Loss: 0.544202312601434\n",
      "Validation Loss: 0.4620798096055604\n",
      "Train Loss: 0.544202312444994\n",
      "Validation Loss: 0.46207966542446083\n",
      "Train Loss: 0.544202312289999\n",
      "Validation Loss: 0.4620795219319482\n",
      "Train Loss: 0.544202312136514\n",
      "Validation Loss: 0.46207937917190756\n",
      "Train Loss: 0.5442023119846024\n",
      "Validation Loss: 0.4620792371882228\n",
      "Train Loss: 0.5442023118340298\n",
      "Validation Loss: 0.4620790958491945\n",
      "Train Loss: 0.5442023116850019\n",
      "Validation Loss: 0.4620789549938074\n",
      "Train Loss: 0.54420231153744\n",
      "Validation Loss: 0.46207881487084485\n",
      "Train Loss: 0.5442023113913336\n",
      "Validation Loss: 0.46207867548029535\n",
      "Train Loss: 0.5442023112465988\n",
      "Validation Loss: 0.4620785367782531\n",
      "Train Loss: 0.5442023111033644\n",
      "Validation Loss: 0.46207839855980476\n",
      "Train Loss: 0.5442023109614876\n",
      "Validation Loss: 0.4620782613225315\n",
      "Train Loss: 0.5442023108209525\n",
      "Validation Loss: 0.46207812477373217\n",
      "Train Loss: 0.544202310681743\n",
      "Validation Loss: 0.4620779886207073\n",
      "Train Loss: 0.5442023105439333\n",
      "Validation Loss: 0.4620778534927177\n",
      "Train Loss: 0.5442023104074362\n",
      "Validation Loss: 0.46207771905317047\n",
      "Train Loss: 0.5442023102722419\n",
      "Validation Loss: 0.4620775853020553\n",
      "Train Loss: 0.5442023101384685\n",
      "Validation Loss: 0.462077451741767\n",
      "Train Loss: 0.5442023100058456\n",
      "Validation Loss: 0.46207731907479693\n",
      "Train Loss: 0.5442023098745671\n",
      "Validation Loss: 0.462077187140119\n",
      "Train Loss: 0.5442023097444849\n",
      "Validation Loss: 0.46207705584994235\n",
      "Train Loss: 0.5442023096157219\n",
      "Validation Loss: 0.4620769249993496\n",
      "Train Loss: 0.5442023094882742\n",
      "Validation Loss: 0.4620767948810177\n",
      "Train Loss: 0.5442023093619959\n",
      "Validation Loss: 0.4620766654071579\n",
      "Train Loss: 0.5442023092370081\n",
      "Validation Loss: 0.4620765363728512\n",
      "Train Loss: 0.5442023091131785\n",
      "Validation Loss: 0.462076408275685\n",
      "Train Loss: 0.5442023089905538\n",
      "Validation Loss: 0.46207628057416417\n",
      "Train Loss: 0.544202308869192\n",
      "Validation Loss: 0.4620761533121672\n",
      "Train Loss: 0.5442023087489625\n",
      "Validation Loss: 0.4620760269872824\n",
      "Train Loss: 0.5442023086299117\n",
      "Validation Loss: 0.46207590105801477\n",
      "Train Loss: 0.5442023085119713\n",
      "Validation Loss: 0.462075775773155\n",
      "Train Loss: 0.54420230839521\n",
      "Validation Loss: 0.462075651761952\n",
      "Train Loss: 0.5442023082795312\n",
      "Validation Loss: 0.4620755278097671\n",
      "Train Loss: 0.5442023081650034\n",
      "Validation Loss: 0.4620754045458494\n",
      "Train Loss: 0.5442023080516123\n",
      "Validation Loss: 0.46207528167750406\n",
      "Train Loss: 0.5442023079392327\n",
      "Validation Loss: 0.4620751597023225\n",
      "Train Loss: 0.5442023078280378\n",
      "Validation Loss: 0.46207503816658113\n",
      "Train Loss: 0.5442023077178969\n",
      "Validation Loss: 0.4620749172751863\n",
      "Train Loss: 0.5442023076088659\n",
      "Validation Loss: 0.4620747970720136\n",
      "Train Loss: 0.5442023075008107\n",
      "Validation Loss: 0.46207467746928654\n",
      "Train Loss: 0.5442023073938439\n",
      "Validation Loss: 0.46207455826208055\n",
      "Train Loss: 0.5442023072878955\n",
      "Validation Loss: 0.4620744394065039\n",
      "Train Loss: 0.5442023071829746\n",
      "Validation Loss: 0.46207432178060054\n",
      "Train Loss: 0.5442023070791133\n",
      "Validation Loss: 0.4620742042575091\n",
      "Train Loss: 0.544202306976192\n",
      "Validation Loss: 0.4620740873348246\n",
      "Train Loss: 0.5442023068743261\n",
      "Validation Loss: 0.4620739711003035\n",
      "Train Loss: 0.5442023067735023\n",
      "Validation Loss: 0.4620738552612536\n",
      "Train Loss: 0.5442023066735973\n",
      "Validation Loss: 0.4620737400225874\n",
      "Train Loss: 0.5442023065746047\n",
      "Validation Loss: 0.46207362538429786\n",
      "Train Loss: 0.5442023064766377\n",
      "Validation Loss: 0.4620735114341392\n",
      "Train Loss: 0.5442023063795642\n",
      "Validation Loss: 0.46207339779165985\n",
      "Train Loss: 0.5442023062834966\n",
      "Validation Loss: 0.46207328454461355\n",
      "Train Loss: 0.5442023061883197\n",
      "Validation Loss: 0.46207317219059657\n",
      "Train Loss: 0.5442023060940807\n",
      "Validation Loss: 0.4620730604807992\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442023060007143\n",
      "Validation Loss: 0.4620729493713349\n",
      "Train Loss: 0.5442023059083253\n",
      "Validation Loss: 0.462072838657273\n",
      "Train Loss: 0.5442023058167957\n",
      "Validation Loss: 0.46207272854352965\n",
      "Train Loss: 0.5442023057262295\n",
      "Validation Loss: 0.46207261882517386\n",
      "Train Loss: 0.5442023056364524\n",
      "Validation Loss: 0.46207250966324476\n",
      "Train Loss: 0.5442023055475682\n",
      "Validation Loss: 0.462072400852811\n",
      "Train Loss: 0.5442023054595186\n",
      "Validation Loss: 0.46207229264266886\n",
      "Train Loss: 0.5442023053722977\n",
      "Validation Loss: 0.46207218503281233\n",
      "Train Loss: 0.5442023052859558\n",
      "Validation Loss: 0.4620720780671109\n",
      "Train Loss: 0.5442023052004812\n",
      "Validation Loss: 0.4620719714528778\n",
      "Train Loss: 0.5442023051158723\n",
      "Validation Loss: 0.4620718654827861\n",
      "Train Loss: 0.5442023050320673\n",
      "Validation Loss: 0.46207176011295237\n",
      "Train Loss: 0.5442023049490555\n",
      "Validation Loss: 0.46207165505069064\n",
      "Train Loss: 0.5442023048668363\n",
      "Validation Loss: 0.4620715505886747\n",
      "Train Loss: 0.5442023047854038\n",
      "Validation Loss: 0.46207144672689815\n",
      "Train Loss: 0.5442023047048018\n",
      "Validation Loss: 0.4620713432165503\n",
      "Train Loss: 0.5442023046249749\n",
      "Validation Loss: 0.46207124030642915\n",
      "Train Loss: 0.5442023045458636\n",
      "Validation Loss: 0.46207113795265403\n",
      "Train Loss: 0.5442023044675653\n",
      "Validation Loss: 0.46207103595028914\n",
      "Train Loss: 0.544202304390074\n",
      "Validation Loss: 0.4620709342993279\n",
      "Train Loss: 0.5442023043132866\n",
      "Validation Loss: 0.4620708334973734\n",
      "Train Loss: 0.544202304237242\n",
      "Validation Loss: 0.4620707330029371\n",
      "Train Loss: 0.5442023041619393\n",
      "Validation Loss: 0.46207063310869095\n",
      "Train Loss: 0.5442023040873682\n",
      "Validation Loss: 0.4620705335219513\n",
      "Train Loss: 0.5442023040135757\n",
      "Validation Loss: 0.46207043428658506\n",
      "Train Loss: 0.5442023039404614\n",
      "Validation Loss: 0.46207033590019686\n",
      "Train Loss: 0.5442023038680115\n",
      "Validation Loss: 0.4620702377774258\n",
      "Train Loss: 0.5442023037962305\n",
      "Validation Loss: 0.4620701405036221\n",
      "Train Loss: 0.5442023037251975\n",
      "Validation Loss: 0.4620700429958143\n",
      "Train Loss: 0.5442023036548234\n",
      "Validation Loss: 0.4620699463369629\n",
      "Train Loss: 0.5442023035851953\n",
      "Validation Loss: 0.4620698500294502\n",
      "Train Loss: 0.5442023035162575\n",
      "Validation Loss: 0.4620697540294\n",
      "Train Loss: 0.5442023034479138\n",
      "Validation Loss: 0.4620696588344186\n",
      "Train Loss: 0.5442023033802552\n",
      "Validation Loss: 0.46206956423956586\n",
      "Train Loss: 0.5442023033132272\n",
      "Validation Loss: 0.4620694702009655\n",
      "Train Loss: 0.5442023032469192\n",
      "Validation Loss: 0.46206937651367636\n",
      "Train Loss: 0.5442023031811832\n",
      "Validation Loss: 0.46206928333875985\n",
      "Train Loss: 0.5442023031161128\n",
      "Validation Loss: 0.46206919076395014\n",
      "Train Loss: 0.5442023030517387\n",
      "Validation Loss: 0.4620690979550836\n",
      "Train Loss: 0.5442023029879275\n",
      "Validation Loss: 0.46206900595125144\n",
      "Train Loss: 0.5442023029247152\n",
      "Validation Loss: 0.4620689142109666\n",
      "Train Loss: 0.5442023028621495\n",
      "Validation Loss: 0.46206882307076824\n",
      "Train Loss: 0.5442023028001738\n",
      "Validation Loss: 0.4620687321941079\n",
      "Train Loss: 0.5442023027388353\n",
      "Validation Loss: 0.4620686419175235\n",
      "Train Loss: 0.544202302678078\n",
      "Validation Loss: 0.46206855190446766\n",
      "Train Loss: 0.5442023026179018\n",
      "Validation Loss: 0.46206846244761085\n",
      "Train Loss: 0.5442023025583067\n",
      "Validation Loss: 0.4620683738396227\n",
      "Train Loss: 0.5442023024993224\n",
      "Validation Loss: 0.46206828524634175\n",
      "Train Loss: 0.5442023024409065\n",
      "Validation Loss: 0.46206819720924536\n",
      "Train Loss: 0.5442023023830088\n",
      "Validation Loss: 0.46206810968446305\n",
      "Train Loss: 0.5442023023256674\n",
      "Validation Loss: 0.46206802242318235\n",
      "Train Loss: 0.5442023022688784\n",
      "Validation Loss: 0.4620679354253997\n",
      "Train Loss: 0.5442023022126872\n",
      "Validation Loss: 0.4620678490276499\n",
      "Train Loss: 0.5442023021570439\n",
      "Validation Loss: 0.4620677631860625\n",
      "Train Loss: 0.5442023021018549\n",
      "Validation Loss: 0.46206767781290264\n",
      "Train Loss: 0.5442023020472513\n",
      "Validation Loss: 0.4620675930397621\n",
      "Train Loss: 0.5442023019931762\n",
      "Validation Loss: 0.4620675082374243\n",
      "Train Loss: 0.5442023019395894\n",
      "Validation Loss: 0.46206742394736783\n",
      "Train Loss: 0.5442023018865276\n",
      "Validation Loss: 0.4620673399207796\n",
      "Train Loss: 0.5442023018340785\n",
      "Validation Loss: 0.4620672565380569\n",
      "Train Loss: 0.5442023017820588\n",
      "Validation Loss: 0.46206717333106606\n",
      "Train Loss: 0.5442023017305131\n",
      "Validation Loss: 0.46206709063634044\n",
      "Train Loss: 0.5442023016795206\n",
      "Validation Loss: 0.4620670082489306\n",
      "Train Loss: 0.5442023016289949\n",
      "Validation Loss: 0.4620669263737783\n",
      "Train Loss: 0.544202301579018\n",
      "Validation Loss: 0.46206684509860535\n",
      "Train Loss: 0.5442023015294932\n",
      "Validation Loss: 0.4620667637503376\n",
      "Train Loss: 0.5442023014804672\n",
      "Validation Loss: 0.4620666829581784\n",
      "Train Loss: 0.5442023014318942\n",
      "Validation Loss: 0.46206660267826144\n",
      "Train Loss: 0.5442023013837708\n",
      "Validation Loss: 0.4620665229105828\n",
      "Train Loss: 0.5442023013361321\n",
      "Validation Loss: 0.46206644340632946\n",
      "Train Loss: 0.5442023012889365\n",
      "Validation Loss: 0.46206636441430743\n",
      "Train Loss: 0.5442023012422187\n",
      "Validation Loss: 0.4620662856857032\n",
      "Train Loss: 0.5442023011959374\n",
      "Validation Loss: 0.4620662074693231\n",
      "Train Loss: 0.5442023011501268\n",
      "Validation Loss: 0.4620661295163534\n",
      "Train Loss: 0.5442023011047429\n",
      "Validation Loss: 0.4620660517829296\n",
      "Train Loss: 0.5442023010598228\n",
      "Validation Loss: 0.46206597431290947\n",
      "Train Loss: 0.5442023010153669\n",
      "Validation Loss: 0.4620658973989598\n",
      "Train Loss: 0.5442023009713314\n",
      "Validation Loss: 0.4620658209972164\n",
      "Train Loss: 0.5442023009276733\n",
      "Validation Loss: 0.46206574506381587\n",
      "Train Loss: 0.5442023008845024\n",
      "Validation Loss: 0.4620656691449941\n",
      "Train Loss: 0.5442023008417426\n",
      "Validation Loss: 0.4620655937383687\n",
      "Train Loss: 0.5442023007993876\n",
      "Validation Loss: 0.46206551855126593\n",
      "Train Loss: 0.5442023007574022\n",
      "Validation Loss: 0.46206544412516354\n",
      "Train Loss: 0.544202300715855\n",
      "Validation Loss: 0.46206536996243697\n",
      "Train Loss: 0.5442023006747039\n",
      "Validation Loss: 0.4620652960192239\n",
      "Train Loss: 0.544202300633988\n",
      "Validation Loss: 0.46206522263204924\n",
      "Train Loss: 0.5442023005936305\n",
      "Validation Loss: 0.4620651500058623\n",
      "Train Loss: 0.5442023005536571\n",
      "Validation Loss: 0.4620650773065098\n",
      "Train Loss: 0.5442023005140683\n",
      "Validation Loss: 0.4620650048266586\n",
      "Train Loss: 0.5442023004748959\n",
      "Validation Loss: 0.4620649323174941\n",
      "Train Loss: 0.5442023004360715\n",
      "Validation Loss: 0.46206486056930546\n",
      "Train Loss: 0.5442023003976235\n",
      "Validation Loss: 0.46206478904060927\n",
      "Train Loss: 0.5442023003595556\n",
      "Validation Loss: 0.4620647183167404\n",
      "Train Loss: 0.5442023003218553\n",
      "Validation Loss: 0.462064647519689\n",
      "Train Loss: 0.5442023002845601\n",
      "Validation Loss: 0.46206457698597814\n",
      "Train Loss: 0.5442023002475965\n",
      "Validation Loss: 0.46206450692055967\n",
      "Train Loss: 0.5442023002109989\n",
      "Validation Loss: 0.4620644373672873\n",
      "Train Loss: 0.5442023001747613\n",
      "Validation Loss: 0.46206436803349005\n",
      "Train Loss: 0.5442023001388482\n",
      "Validation Loss: 0.4620642991679768\n",
      "Train Loss: 0.54420230010329\n",
      "Validation Loss: 0.462064230521933\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442023000680842\n",
      "Validation Loss: 0.462064162095356\n",
      "Train Loss: 0.5442023000332313\n",
      "Validation Loss: 0.462064094180911\n",
      "Train Loss: 0.5442022999987225\n",
      "Validation Loss: 0.46206402619325915\n",
      "Train Loss: 0.5442022999645261\n",
      "Validation Loss: 0.4620639586738784\n",
      "Train Loss: 0.544202299930675\n",
      "Validation Loss: 0.46206389166662154\n",
      "Train Loss: 0.5442022998971288\n",
      "Validation Loss: 0.4620638248349628\n",
      "Train Loss: 0.5442022998639231\n",
      "Validation Loss: 0.4620637585154224\n",
      "Train Loss: 0.5442022998310553\n",
      "Validation Loss: 0.4620636927079974\n",
      "Train Loss: 0.5442022997984823\n",
      "Validation Loss: 0.46206362678349605\n",
      "Train Loss: 0.5442022997662427\n",
      "Validation Loss: 0.46206356137110494\n",
      "Train Loss: 0.5442022997342654\n",
      "Validation Loss: 0.46206349638311317\n",
      "Train Loss: 0.5442022997026477\n",
      "Validation Loss: 0.4620634316584135\n",
      "Train Loss: 0.544202299671353\n",
      "Validation Loss: 0.462063367153149\n",
      "Train Loss: 0.5442022996403453\n",
      "Validation Loss: 0.462063302823464\n",
      "Train Loss: 0.5442022996096253\n",
      "Validation Loss: 0.4620632389620226\n",
      "Train Loss: 0.5442022995792215\n",
      "Validation Loss: 0.4620631753200094\n",
      "Train Loss: 0.5442022995491345\n",
      "Validation Loss: 0.4620631121900883\n",
      "Train Loss: 0.5442022995193257\n",
      "Validation Loss: 0.4620630492357371\n",
      "Train Loss: 0.5442022994897963\n",
      "Validation Loss: 0.46206298674962026\n",
      "Train Loss: 0.544202299460574\n",
      "Validation Loss: 0.46206292448292174\n",
      "Train Loss: 0.5442022994315943\n",
      "Validation Loss: 0.4620628626406005\n",
      "Train Loss: 0.5442022994028852\n",
      "Validation Loss: 0.46206280097384095\n",
      "Train Loss: 0.5442022993744475\n",
      "Validation Loss: 0.4620627397753069\n",
      "Train Loss: 0.5442022993463059\n",
      "Validation Loss: 0.4620626785035165\n",
      "Train Loss: 0.5442022993184318\n",
      "Validation Loss: 0.4620626176999476\n",
      "Train Loss: 0.5442022992908548\n",
      "Validation Loss: 0.4620625574084489\n",
      "Train Loss: 0.5442022992635356\n",
      "Validation Loss: 0.46206249699983587\n",
      "Train Loss: 0.5442022992365093\n",
      "Validation Loss: 0.4620624371032884\n",
      "Train Loss: 0.5442022992097111\n",
      "Validation Loss: 0.46206237763110214\n",
      "Train Loss: 0.5442022991831678\n",
      "Validation Loss: 0.46206231833446076\n",
      "Train Loss: 0.5442022991569085\n",
      "Validation Loss: 0.4620622592572135\n",
      "Train Loss: 0.5442022991309005\n",
      "Validation Loss: 0.46206220035550694\n",
      "Train Loss: 0.5442022991051416\n",
      "Validation Loss: 0.4620621416293395\n",
      "Train Loss: 0.544202299079605\n",
      "Validation Loss: 0.46206208362018875\n",
      "Train Loss: 0.5442022990543448\n",
      "Validation Loss: 0.4620620258304233\n",
      "Train Loss: 0.5442022990293284\n",
      "Validation Loss: 0.4620619682161911\n",
      "Train Loss: 0.5442022990045566\n",
      "Validation Loss: 0.4620619110701547\n",
      "Train Loss: 0.5442022989800226\n",
      "Validation Loss: 0.46206185380698317\n",
      "Train Loss: 0.5442022989557025\n",
      "Validation Loss: 0.4620617972608187\n",
      "Train Loss: 0.5442022989316491\n",
      "Validation Loss: 0.4620617409340293\n",
      "Train Loss: 0.5442022989078281\n",
      "Validation Loss: 0.4620616844900993\n",
      "Train Loss: 0.5442022988841845\n",
      "Validation Loss: 0.4620616284266575\n",
      "Train Loss: 0.544202298860778\n",
      "Validation Loss: 0.4620615731240644\n",
      "Train Loss: 0.5442022988376258\n",
      "Validation Loss: 0.46206151745551094\n",
      "Train Loss: 0.5442022988147046\n",
      "Validation Loss: 0.46206146225513817\n",
      "Train Loss: 0.5442022987920391\n",
      "Validation Loss: 0.46206140727412875\n",
      "Train Loss: 0.5442022987695434\n",
      "Validation Loss: 0.46206135267359943\n",
      "Train Loss: 0.5442022987472713\n",
      "Validation Loss: 0.4620612982485816\n",
      "Train Loss: 0.5442022987252497\n",
      "Validation Loss: 0.46206124404292176\n",
      "Train Loss: 0.5442022987034222\n",
      "Validation Loss: 0.4620611902615853\n",
      "Train Loss: 0.5442022986818109\n",
      "Validation Loss: 0.4620611363630917\n",
      "Train Loss: 0.5442022986603937\n",
      "Validation Loss: 0.4620610831815817\n",
      "Train Loss: 0.544202298639192\n",
      "Validation Loss: 0.46206103017557476\n",
      "Train Loss: 0.544202298618179\n",
      "Validation Loss: 0.46206097759388487\n",
      "Train Loss: 0.5442022985973786\n",
      "Validation Loss: 0.4620609251876947\n",
      "Train Loss: 0.5442022985768166\n",
      "Validation Loss: 0.4620608730008496\n",
      "Train Loss: 0.5442022985564091\n",
      "Validation Loss: 0.46206082090180683\n",
      "Train Loss: 0.544202298536185\n",
      "Validation Loss: 0.462060769227075\n",
      "Train Loss: 0.5442022985161968\n",
      "Validation Loss: 0.46206071806434595\n",
      "Train Loss: 0.5442022984963574\n",
      "Validation Loss: 0.4620606666967526\n",
      "Train Loss: 0.5442022984767508\n",
      "Validation Loss: 0.4620606158411587\n",
      "Train Loss: 0.5442022984573196\n",
      "Validation Loss: 0.46206056511720706\n",
      "Train Loss: 0.5442022984380624\n",
      "Validation Loss: 0.46206051452489627\n",
      "Train Loss: 0.5442022984190046\n",
      "Validation Loss: 0.46206046410807106\n",
      "Train Loss: 0.5442022984001708\n",
      "Validation Loss: 0.46206041391057595\n",
      "Train Loss: 0.5442022983815069\n",
      "Validation Loss: 0.4620603638447174\n",
      "Train Loss: 0.5442022983630141\n",
      "Validation Loss: 0.46206031420315624\n",
      "Train Loss: 0.5442022983446418\n",
      "Validation Loss: 0.4620602651908621\n",
      "Train Loss: 0.5442022983264878\n",
      "Validation Loss: 0.46206021639789185\n",
      "Train Loss: 0.5442022983085503\n",
      "Validation Loss: 0.46206016782424314\n",
      "Train Loss: 0.544202298290751\n",
      "Validation Loss: 0.46206011933837915\n",
      "Train Loss: 0.5442022982731375\n",
      "Validation Loss: 0.4620600707353272\n",
      "Train Loss: 0.5442022982556647\n",
      "Validation Loss: 0.46206002280538105\n",
      "Train Loss: 0.5442022982384026\n",
      "Validation Loss: 0.4620599750947508\n",
      "Train Loss: 0.5442022982212995\n",
      "Validation Loss: 0.46205992751574504\n",
      "Train Loss: 0.5442022982043543\n",
      "Validation Loss: 0.46205988006836285\n",
      "Train Loss: 0.5442022981875657\n",
      "Validation Loss: 0.46205983275260293\n",
      "Train Loss: 0.5442022981709597\n",
      "Validation Loss: 0.4620597859049698\n",
      "Train Loss: 0.5442022981545058\n",
      "Validation Loss: 0.46205973889629537\n",
      "Train Loss: 0.5442022981381851\n",
      "Validation Loss: 0.4620596925607178\n",
      "Train Loss: 0.544202298122041\n",
      "Validation Loss: 0.46205964640060176\n",
      "Train Loss: 0.5442022981060701\n",
      "Validation Loss: 0.46205960012328473\n",
      "Train Loss: 0.5442022980902291\n",
      "Validation Loss: 0.4620595545190608\n",
      "Train Loss: 0.5442022980745568\n",
      "Validation Loss: 0.46205950850497285\n",
      "Train Loss: 0.5442022980590582\n",
      "Validation Loss: 0.46205946295900163\n",
      "Train Loss: 0.5442022980436865\n",
      "Validation Loss: 0.4620594180861201\n",
      "Train Loss: 0.5442022980284602\n",
      "Validation Loss: 0.4620593733448488\n",
      "Train Loss: 0.5442022980133999\n",
      "Validation Loss: 0.46205932848636927\n",
      "Train Loss: 0.5442022979984616\n",
      "Validation Loss: 0.4620592840083153\n",
      "Train Loss: 0.5442022979836658\n",
      "Validation Loss: 0.4620592396618685\n",
      "Train Loss: 0.5442022979690114\n",
      "Validation Loss: 0.4620591954470275\n",
      "Train Loss: 0.5442022979545225\n",
      "Validation Loss: 0.46205915170029455\n",
      "Train Loss: 0.5442022979401707\n",
      "Validation Loss: 0.4620591077925048\n",
      "Train Loss: 0.5442022979259592\n",
      "Validation Loss: 0.46205906430897775\n",
      "Train Loss: 0.5442022979118868\n",
      "Validation Loss: 0.46205902124971243\n",
      "Train Loss: 0.5442022978979506\n",
      "Validation Loss: 0.4620589783220473\n",
      "Train Loss: 0.5442022978841271\n",
      "Validation Loss: 0.46205893548213955\n",
      "Train Loss: 0.5442022978704623\n",
      "Validation Loss: 0.46205889311033205\n",
      "Train Loss: 0.5442022978569286\n",
      "Validation Loss: 0.4620588505774619\n",
      "Train Loss: 0.5442022978435274\n",
      "Validation Loss: 0.4620588081761877\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022978302372\n",
      "Validation Loss: 0.46205876615532704\n",
      "Train Loss: 0.5442022978170814\n",
      "Validation Loss: 0.46205872485138005\n",
      "Train Loss: 0.5442022978040513\n",
      "Validation Loss: 0.46205868309370673\n",
      "Train Loss: 0.5442022977911298\n",
      "Validation Loss: 0.4620586417164445\n",
      "Train Loss: 0.5442022977783559\n",
      "Validation Loss: 0.462058600221955\n",
      "Train Loss: 0.5442022977656891\n",
      "Validation Loss: 0.4620585591078743\n",
      "Train Loss: 0.5442022977531695\n",
      "Validation Loss: 0.46205851816922383\n",
      "Train Loss: 0.5442022977407572\n",
      "Validation Loss: 0.4620584779036395\n",
      "Train Loss: 0.5442022977284883\n",
      "Validation Loss: 0.4620584375208239\n",
      "Train Loss: 0.5442022977163229\n",
      "Validation Loss: 0.462058397518413\n",
      "Train Loss: 0.5442022977042779\n",
      "Validation Loss: 0.46205835735492834\n",
      "Train Loss: 0.5442022976923558\n",
      "Validation Loss: 0.46205831761568733\n",
      "Train Loss: 0.5442022976805542\n",
      "Validation Loss: 0.46205827800802957\n",
      "Train Loss: 0.5442022976688531\n",
      "Validation Loss: 0.46205823878077323\n",
      "Train Loss: 0.5442022976572706\n",
      "Validation Loss: 0.4620581996850983\n",
      "Train Loss: 0.5442022976458041\n",
      "Validation Loss: 0.4620581604283456\n",
      "Train Loss: 0.5442022976344563\n",
      "Validation Loss: 0.4620581215958313\n",
      "Train Loss: 0.5442022976232245\n",
      "Validation Loss: 0.4620580828948959\n",
      "Train Loss: 0.5442022976120876\n",
      "Validation Loss: 0.46205804428169867\n",
      "Train Loss: 0.5442022976010487\n",
      "Validation Loss: 0.4620580063415565\n",
      "Train Loss: 0.5442022975901233\n",
      "Validation Loss: 0.4620579685329903\n",
      "Train Loss: 0.544202297579291\n",
      "Validation Loss: 0.46205793081216034\n",
      "Train Loss: 0.5442022975685724\n",
      "Validation Loss: 0.4620578935155634\n",
      "Train Loss: 0.5442022975579633\n",
      "Validation Loss: 0.4620578560578817\n",
      "Train Loss: 0.5442022975474647\n",
      "Validation Loss: 0.46205781873177265\n",
      "Train Loss: 0.5442022975370384\n",
      "Validation Loss: 0.4620577817422163\n",
      "Train Loss: 0.5442022975267211\n",
      "Validation Loss: 0.4620577448842311\n",
      "Train Loss: 0.544202297516512\n",
      "Validation Loss: 0.4620577081578165\n",
      "Train Loss: 0.5442022975063909\n",
      "Validation Loss: 0.46205767151913285\n",
      "Train Loss: 0.5442022974963766\n",
      "Validation Loss: 0.4620576350120179\n",
      "Train Loss: 0.5442022974864698\n",
      "Validation Loss: 0.4620575989291292\n",
      "Train Loss: 0.544202297476649\n",
      "Validation Loss: 0.4620575629339691\n",
      "Train Loss: 0.5442022974669138\n",
      "Validation Loss: 0.4620575270265371\n",
      "Train Loss: 0.5442022974572823\n",
      "Validation Loss: 0.4620574912506708\n",
      "Train Loss: 0.544202297447735\n",
      "Validation Loss: 0.4620574555625315\n",
      "Train Loss: 0.5442022974383084\n",
      "Validation Loss: 0.4620574200497941\n",
      "Train Loss: 0.5442022974289831\n",
      "Validation Loss: 0.46205738466862\n",
      "Train Loss: 0.5442022974197214\n",
      "Validation Loss: 0.46205734933133263\n",
      "Train Loss: 0.5442022974105598\n",
      "Validation Loss: 0.4620573141256073\n",
      "Train Loss: 0.5442022974014626\n",
      "Validation Loss: 0.46205727925642526\n",
      "Train Loss: 0.5442022973924657\n",
      "Validation Loss: 0.4620572448114609\n",
      "Train Loss: 0.5442022973835667\n",
      "Validation Loss: 0.46205721049805626\n",
      "Train Loss: 0.5442022973747469\n",
      "Validation Loss: 0.4620571762723729\n",
      "Train Loss: 0.5442022973660057\n",
      "Validation Loss: 0.46205714213441035\n",
      "Train Loss: 0.5442022973573605\n",
      "Validation Loss: 0.4620571081280054\n",
      "Train Loss: 0.5442022973487942\n",
      "Validation Loss: 0.46205707450197714\n",
      "Train Loss: 0.5442022973403225\n",
      "Validation Loss: 0.4620570410075046\n",
      "Train Loss: 0.544202297331911\n",
      "Validation Loss: 0.4620570078495707\n",
      "Train Loss: 0.5442022973236087\n",
      "Validation Loss: 0.4620569745743711\n",
      "Train Loss: 0.5442022973153655\n",
      "Validation Loss: 0.46205694163570865\n",
      "Train Loss: 0.5442022973072144\n",
      "Validation Loss: 0.4620569088285994\n",
      "Train Loss: 0.5442022972991373\n",
      "Validation Loss: 0.46205687610920615\n",
      "Train Loss: 0.5442022972911179\n",
      "Validation Loss: 0.4620568437263484\n",
      "Train Loss: 0.5442022972831874\n",
      "Validation Loss: 0.46205681118238523\n",
      "Train Loss: 0.5442022972753306\n",
      "Validation Loss: 0.46205677901879316\n",
      "Train Loss: 0.5442022972675614\n",
      "Validation Loss: 0.46205674669409413\n",
      "Train Loss: 0.5442022972598649\n",
      "Validation Loss: 0.46205671474976495\n",
      "Train Loss: 0.5442022972522575\n",
      "Validation Loss: 0.4620566832296405\n",
      "Train Loss: 0.5442022972447037\n",
      "Validation Loss: 0.4620566517533922\n",
      "Train Loss: 0.544202297237221\n",
      "Validation Loss: 0.46205662065751163\n",
      "Train Loss: 0.5442022972298227\n",
      "Validation Loss: 0.46205658940052113\n",
      "Train Loss: 0.5442022972224918\n",
      "Validation Loss: 0.4620565579385846\n",
      "Train Loss: 0.5442022972152305\n",
      "Validation Loss: 0.4620565268570142\n",
      "Train Loss: 0.5442022972080531\n",
      "Validation Loss: 0.4620564959069884\n",
      "Train Loss: 0.5442022972009415\n",
      "Validation Loss: 0.46205646475201506\n",
      "Train Loss: 0.5442022971938995\n",
      "Validation Loss: 0.46205643427006216\n",
      "Train Loss: 0.5442022971869235\n",
      "Validation Loss: 0.46205640387581676\n",
      "Train Loss: 0.5442022971800133\n",
      "Validation Loss: 0.4620563735692784\n",
      "Train Loss: 0.5442022971731684\n",
      "Validation Loss: 0.46205634335044676\n",
      "Train Loss: 0.5442022971663896\n",
      "Validation Loss: 0.4620563135119769\n",
      "Train Loss: 0.5442022971596737\n",
      "Validation Loss: 0.4620562834685567\n",
      "Train Loss: 0.5442022971530219\n",
      "Validation Loss: 0.46205625351284174\n",
      "Train Loss: 0.5442022971464204\n",
      "Validation Loss: 0.4620562241863083\n",
      "Train Loss: 0.5442022971399104\n",
      "Validation Loss: 0.46205619444983664\n",
      "Train Loss: 0.5442022971334346\n",
      "Validation Loss: 0.4620561652987109\n",
      "Train Loss: 0.5442022971270503\n",
      "Validation Loss: 0.46205613603030166\n",
      "Train Loss: 0.5442022971207287\n",
      "Validation Loss: 0.4620561071422506\n",
      "Train Loss: 0.544202297114453\n",
      "Validation Loss: 0.46205607829806694\n",
      "Train Loss: 0.5442022971082393\n",
      "Validation Loss: 0.4620560498342408\n",
      "Train Loss: 0.5442022971021008\n",
      "Validation Loss: 0.4620560215019498\n",
      "Train Loss: 0.5442022970960207\n",
      "Validation Loss: 0.46205599296470373\n",
      "Train Loss: 0.5442022970899876\n",
      "Validation Loss: 0.4620559650566349\n",
      "Train Loss: 0.5442022970840121\n",
      "Validation Loss: 0.4620559369436102\n",
      "Train Loss: 0.5442022970780964\n",
      "Validation Loss: 0.4620559092109402\n",
      "Train Loss: 0.5442022970722374\n",
      "Validation Loss: 0.4620558812733137\n",
      "Train Loss: 0.5442022970664506\n",
      "Validation Loss: 0.4620558534672194\n",
      "Train Loss: 0.544202297060721\n",
      "Validation Loss: 0.46205582574882276\n",
      "Train Loss: 0.5442022970550348\n",
      "Validation Loss: 0.4620557983669452\n",
      "Train Loss: 0.5442022970494049\n",
      "Validation Loss: 0.4620557710727648\n",
      "Train Loss: 0.544202297043831\n",
      "Validation Loss: 0.46205574386628073\n",
      "Train Loss: 0.5442022970383115\n",
      "Validation Loss: 0.46205571645483806\n",
      "Train Loss: 0.5442022970328353\n",
      "Validation Loss: 0.46205568967256766\n",
      "Train Loss: 0.544202297027414\n",
      "Validation Loss: 0.4620556629779926\n",
      "Train Loss: 0.5442022970220599\n",
      "Validation Loss: 0.4620556361222908\n",
      "Train Loss: 0.5442022970167354\n",
      "Validation Loss: 0.46205561014458163\n",
      "Train Loss: 0.544202297011476\n",
      "Validation Loss: 0.4620555837130902\n",
      "Train Loss: 0.5442022970062699\n",
      "Validation Loss: 0.46205555736929216\n",
      "Train Loss: 0.5442022970011028\n",
      "Validation Loss: 0.46205553106935465\n",
      "Train Loss: 0.544202296996003\n",
      "Validation Loss: 0.4620555051935976\n",
      "Train Loss: 0.5442022969909416\n",
      "Validation Loss: 0.4620554793617001\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022969859442\n",
      "Validation Loss: 0.46205545336867265\n",
      "Train Loss: 0.5442022969809993\n",
      "Validation Loss: 0.4620554277559915\n",
      "Train Loss: 0.5442022969760796\n",
      "Validation Loss: 0.46205540243599086\n",
      "Train Loss: 0.544202296971197\n",
      "Validation Loss: 0.4620553771598485\n",
      "Train Loss: 0.544202296966377\n",
      "Validation Loss: 0.4620553517225748\n",
      "Train Loss: 0.544202296961608\n",
      "Validation Loss: 0.46205532666564575\n",
      "Train Loss: 0.5442022969568743\n",
      "Validation Loss: 0.4620553013599196\n",
      "Train Loss: 0.5442022969521908\n",
      "Validation Loss: 0.46205527643453725\n",
      "Train Loss: 0.5442022969475562\n",
      "Validation Loss: 0.462055251596844\n",
      "Train Loss: 0.5442022969429829\n",
      "Validation Loss: 0.4620552268906714\n",
      "Train Loss: 0.5442022969384449\n",
      "Validation Loss: 0.4620552022283549\n",
      "Train Loss: 0.5442022969339311\n",
      "Validation Loss: 0.46205517815137054\n",
      "Train Loss: 0.5442022969294636\n",
      "Validation Loss: 0.46205515386942\n",
      "Train Loss: 0.544202296925055\n",
      "Validation Loss: 0.46205512942633403\n",
      "Train Loss: 0.5442022969207058\n",
      "Validation Loss: 0.4620551051147668\n",
      "Train Loss: 0.5442022969163671\n",
      "Validation Loss: 0.46205508134469886\n",
      "Train Loss: 0.5442022969120873\n",
      "Validation Loss: 0.4620550577061486\n",
      "Train Loss: 0.5442022969078407\n",
      "Validation Loss: 0.46205503411145227\n",
      "Train Loss: 0.5442022969036271\n",
      "Validation Loss: 0.4620550105606099\n",
      "Train Loss: 0.54420229689947\n",
      "Validation Loss: 0.46205498684863033\n",
      "Train Loss: 0.5442022968953465\n",
      "Validation Loss: 0.4620549634731579\n",
      "Train Loss: 0.5442022968912685\n",
      "Validation Loss: 0.4620549404780236\n",
      "Train Loss: 0.5442022968872224\n",
      "Validation Loss: 0.46205491752674216\n",
      "Train Loss: 0.5442022968832182\n",
      "Validation Loss: 0.4620548940778368\n",
      "Train Loss: 0.5442022968792586\n",
      "Validation Loss: 0.4620548710092688\n",
      "Train Loss: 0.5442022968753303\n",
      "Validation Loss: 0.46205484798455254\n",
      "Train Loss: 0.544202296871435\n",
      "Validation Loss: 0.4620548255889953\n",
      "Train Loss: 0.5442022968675814\n",
      "Validation Loss: 0.4620548029884671\n",
      "Train Loss: 0.5442022968637702\n",
      "Validation Loss: 0.4620547804756207\n",
      "Train Loss: 0.5442022968599892\n",
      "Validation Loss: 0.4620547580066256\n",
      "Train Loss: 0.5442022968562512\n",
      "Validation Loss: 0.46205473591796536\n",
      "Train Loss: 0.5442022968525428\n",
      "Validation Loss: 0.46205471387315555\n",
      "Train Loss: 0.5442022968488874\n",
      "Validation Loss: 0.4620546919598571\n",
      "Train Loss: 0.5442022968452611\n",
      "Validation Loss: 0.4620546700904085\n",
      "Train Loss: 0.544202296841663\n",
      "Validation Loss: 0.4620546479721565\n",
      "Train Loss: 0.5442022968380947\n",
      "Validation Loss: 0.46205462619040705\n",
      "Train Loss: 0.5442022968345666\n",
      "Validation Loss: 0.46205460449633734\n",
      "Train Loss: 0.5442022968310782\n",
      "Validation Loss: 0.46205458288994705\n",
      "Train Loss: 0.5442022968276181\n",
      "Validation Loss: 0.46205456132740536\n",
      "Train Loss: 0.5442022968241869\n",
      "Validation Loss: 0.4620545401013655\n",
      "Train Loss: 0.5442022968207947\n",
      "Validation Loss: 0.4620545189630041\n",
      "Train Loss: 0.5442022968174413\n",
      "Validation Loss: 0.4620544979123207\n",
      "Train Loss: 0.544202296814104\n",
      "Validation Loss: 0.4620544768616553\n",
      "Train Loss: 0.544202296810805\n",
      "Validation Loss: 0.4620544558986673\n",
      "Train Loss: 0.5442022968075341\n",
      "Validation Loss: 0.4620544352721799\n",
      "Train Loss: 0.5442022968042888\n",
      "Validation Loss: 0.4620544143968867\n",
      "Train Loss: 0.544202296801092\n",
      "Validation Loss: 0.4620543936531001\n",
      "Train Loss: 0.5442022967979224\n",
      "Validation Loss: 0.46205437324581344\n",
      "Train Loss: 0.5442022967947798\n",
      "Validation Loss: 0.46205435317502586\n",
      "Train Loss: 0.544202296791673\n",
      "Validation Loss: 0.46205433289926146\n",
      "Train Loss: 0.5442022967885919\n",
      "Validation Loss: 0.46205431266734315\n",
      "Train Loss: 0.5442022967855469\n",
      "Validation Loss: 0.4620542925231001\n",
      "Train Loss: 0.5442022967825272\n",
      "Validation Loss: 0.46205427242270275\n",
      "Train Loss: 0.5442022967795326\n",
      "Validation Loss: 0.46205425236615094\n",
      "Train Loss: 0.5442022967765743\n",
      "Validation Loss: 0.4620542326899265\n",
      "Train Loss: 0.5442022967736503\n",
      "Validation Loss: 0.46205421280872383\n",
      "Train Loss: 0.5442022967707413\n",
      "Validation Loss: 0.462054193220189\n",
      "Train Loss: 0.5442022967678772\n",
      "Validation Loss: 0.4620541737631576\n",
      "Train Loss: 0.5442022967650364\n",
      "Validation Loss: 0.4620541540573178\n",
      "Train Loss: 0.5442022967622204\n",
      "Validation Loss: 0.4620541346879746\n",
      "Train Loss: 0.5442022967594291\n",
      "Validation Loss: 0.4620541156551281\n",
      "Train Loss: 0.5442022967566614\n",
      "Validation Loss: 0.46205409666612535\n",
      "Train Loss: 0.5442022967539172\n",
      "Validation Loss: 0.46205407772096624\n",
      "Train Loss: 0.5442022967512053\n",
      "Validation Loss: 0.46205405857082693\n",
      "Train Loss: 0.5442022967485266\n",
      "Validation Loss: 0.46205403950836005\n",
      "Train Loss: 0.5442022967458707\n",
      "Validation Loss: 0.46205402048973604\n",
      "Train Loss: 0.5442022967432294\n",
      "Validation Loss: 0.46205400205643066\n",
      "Train Loss: 0.5442022967406196\n",
      "Validation Loss: 0.46205398341814463\n",
      "Train Loss: 0.5442022967380412\n",
      "Validation Loss: 0.4620539645748775\n",
      "Train Loss: 0.5442022967354858\n",
      "Validation Loss: 0.462053946068105\n",
      "Train Loss: 0.5442022967329629\n",
      "Validation Loss: 0.46205392794165545\n",
      "Train Loss: 0.544202296730461\n",
      "Validation Loss: 0.46205390956639547\n",
      "Train Loss: 0.5442022967279729\n",
      "Validation Loss: 0.462053891776453\n",
      "Train Loss: 0.5442022967255056\n",
      "Validation Loss: 0.46205387373769996\n",
      "Train Loss: 0.5442022967230692\n",
      "Validation Loss: 0.4620538557866169\n",
      "Train Loss: 0.5442022967206539\n",
      "Validation Loss: 0.46205383787937504\n",
      "Train Loss: 0.5442022967182693\n",
      "Validation Loss: 0.46205382005980267\n",
      "Train Loss: 0.5442022967159055\n",
      "Validation Loss: 0.46205380228407117\n",
      "Train Loss: 0.5442022967135624\n",
      "Validation Loss: 0.4620537845521803\n",
      "Train Loss: 0.5442022967112399\n",
      "Validation Loss: 0.4620537668641302\n",
      "Train Loss: 0.5442022967089379\n",
      "Validation Loss: 0.46205374921992043\n",
      "Train Loss: 0.5442022967066662\n",
      "Validation Loss: 0.46205373195603083\n",
      "Train Loss: 0.5442022967044153\n",
      "Validation Loss: 0.4620537150286332\n",
      "Train Loss: 0.5442022967021928\n",
      "Validation Loss: 0.46205369789625167\n",
      "Train Loss: 0.5442022966999727\n",
      "Validation Loss: 0.4620536810127056\n",
      "Train Loss: 0.5442022966977896\n",
      "Validation Loss: 0.4620536639680033\n",
      "Train Loss: 0.5442022966956089\n",
      "Validation Loss: 0.4620536471721363\n",
      "Train Loss: 0.5442022966934559\n",
      "Validation Loss: 0.46205363017128487\n",
      "Train Loss: 0.544202296691323\n",
      "Validation Loss: 0.46205361350692437\n",
      "Train Loss: 0.54420229668921\n",
      "Validation Loss: 0.4620535971790544\n",
      "Train Loss: 0.544202296687124\n",
      "Validation Loss: 0.4620535806461995\n",
      "Train Loss: 0.544202296685056\n",
      "Validation Loss: 0.4620535638645315\n",
      "Train Loss: 0.5442022966830242\n",
      "Validation Loss: 0.46205354721435726\n",
      "Train Loss: 0.544202296681003\n",
      "Validation Loss: 0.46205353085684536\n",
      "Train Loss: 0.5442022966789922\n",
      "Validation Loss: 0.46205351479199586\n",
      "Train Loss: 0.5442022966770075\n",
      "Validation Loss: 0.46205349852216004\n",
      "Train Loss: 0.5442022966750488\n",
      "Validation Loss: 0.46205348204733837\n",
      "Train Loss: 0.5442022966731004\n",
      "Validation Loss: 0.4620534658651785\n",
      "Train Loss: 0.5442022966711627\n",
      "Validation Loss: 0.4620534502683318\n",
      "Train Loss: 0.5442022966692582\n",
      "Validation Loss: 0.46205343421767436\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022966673713\n",
      "Validation Loss: 0.4620534182108543\n",
      "Train Loss: 0.5442022966654942\n",
      "Validation Loss: 0.46205340249669563\n",
      "Train Loss: 0.5442022966636428\n",
      "Validation Loss: 0.4620533868702012\n",
      "Train Loss: 0.5442022966618085\n",
      "Validation Loss: 0.46205337128754365\n",
      "Train Loss: 0.5442022966599989\n",
      "Validation Loss: 0.4620533554998986\n",
      "Train Loss: 0.5442022966581986\n",
      "Validation Loss: 0.46205334000491444\n",
      "Train Loss: 0.5442022966564152\n",
      "Validation Loss: 0.46205332455376685\n",
      "Train Loss: 0.5442022966546566\n",
      "Validation Loss: 0.4620533091902827\n",
      "Train Loss: 0.5442022966529072\n",
      "Validation Loss: 0.46205329411945906\n",
      "Train Loss: 0.5442022966511741\n",
      "Validation Loss: 0.46205327909247135\n",
      "Train Loss: 0.5442022966494575\n",
      "Validation Loss: 0.4620532641093198\n",
      "Train Loss: 0.544202296647765\n",
      "Validation Loss: 0.46205324921383095\n",
      "Train Loss: 0.54420229664608\n",
      "Validation Loss: 0.4620532340256997\n",
      "Train Loss: 0.5442022966444189\n",
      "Validation Loss: 0.46205321892523094\n",
      "Train Loss: 0.5442022966427742\n",
      "Validation Loss: 0.46205320416124884\n",
      "Train Loss: 0.5442022966411453\n",
      "Validation Loss: 0.462053189441102\n",
      "Train Loss: 0.5442022966395244\n",
      "Validation Loss: 0.46205317472096386\n",
      "Train Loss: 0.5442022966379194\n",
      "Validation Loss: 0.46205316033731186\n",
      "Train Loss: 0.544202296636337\n",
      "Validation Loss: 0.4620531457486702\n",
      "Train Loss: 0.5442022966347698\n",
      "Validation Loss: 0.46205313120386365\n",
      "Train Loss: 0.5442022966332178\n",
      "Validation Loss: 0.46205311670289173\n",
      "Train Loss: 0.5442022966316815\n",
      "Validation Loss: 0.46205310253840537\n",
      "Train Loss: 0.5442022966301602\n",
      "Validation Loss: 0.4620530884177534\n",
      "Train Loss: 0.5442022966286462\n",
      "Validation Loss: 0.46205307429710973\n",
      "Train Loss: 0.5442022966271469\n",
      "Validation Loss: 0.4620530602203\n",
      "Train Loss: 0.5442022966256623\n",
      "Validation Loss: 0.4620530461873246\n",
      "Train Loss: 0.5442022966241997\n",
      "Validation Loss: 0.46205303224200983\n",
      "Train Loss: 0.5442022966227447\n",
      "Validation Loss: 0.46205301858935327\n",
      "Train Loss: 0.5442022966213108\n",
      "Validation Loss: 0.46205300473170596\n",
      "Train Loss: 0.5442022966198772\n",
      "Validation Loss: 0.46205299112289083\n",
      "Train Loss: 0.544202296618465\n",
      "Validation Loss: 0.4620529776017354\n",
      "Train Loss: 0.5442022966170595\n",
      "Validation Loss: 0.4620529640805876\n",
      "Train Loss: 0.5442022966156823\n",
      "Validation Loss: 0.4620529506909251\n",
      "Train Loss: 0.5442022966143106\n",
      "Validation Loss: 0.46205293671596875\n",
      "Train Loss: 0.5442022966129538\n",
      "Validation Loss: 0.4620529233701469\n",
      "Train Loss: 0.5442022966116177\n",
      "Validation Loss: 0.46205291011198385\n",
      "Train Loss: 0.544202296610295\n",
      "Validation Loss: 0.4620528968976539\n",
      "Train Loss: 0.5442022966089787\n",
      "Validation Loss: 0.4620528836833308\n",
      "Train Loss: 0.5442022966076757\n",
      "Validation Loss: 0.46205287051284033\n",
      "Train Loss: 0.5442022966063859\n",
      "Validation Loss: 0.4620528573861828\n",
      "Train Loss: 0.5442022966051023\n",
      "Validation Loss: 0.46205284425953186\n",
      "Train Loss: 0.5442022966038319\n",
      "Validation Loss: 0.4620528311767135\n",
      "Train Loss: 0.5442022966025744\n",
      "Validation Loss: 0.46205281813772753\n",
      "Train Loss: 0.5442022966013371\n",
      "Validation Loss: 0.46205280547904987\n",
      "Train Loss: 0.5442022966001057\n",
      "Validation Loss: 0.46205279282037887\n",
      "Train Loss: 0.5442022965988932\n",
      "Validation Loss: 0.46205277995671495\n",
      "Train Loss: 0.5442022965976865\n",
      "Validation Loss: 0.4620527670930574\n",
      "Train Loss: 0.5442022965964929\n",
      "Validation Loss: 0.4620527545658824\n",
      "Train Loss: 0.5442022965953051\n",
      "Validation Loss: 0.46205274203871344\n",
      "Train Loss: 0.5442022965941296\n",
      "Validation Loss: 0.46205272955537624\n",
      "Train Loss: 0.5442022965929729\n",
      "Validation Loss: 0.4620527171596961\n",
      "Train Loss: 0.5442022965918158\n",
      "Validation Loss: 0.462052705012847\n",
      "Train Loss: 0.5442022965906774\n",
      "Validation Loss: 0.46205269295365464\n",
      "Train Loss: 0.5442022965895508\n",
      "Validation Loss: 0.46205268093829366\n",
      "Train Loss: 0.5442022965884351\n",
      "Validation Loss: 0.46205266838146336\n",
      "Train Loss: 0.5442022965873259\n",
      "Validation Loss: 0.4620526564099394\n",
      "Train Loss: 0.5442022965862348\n",
      "Validation Loss: 0.46205264452607175\n",
      "Train Loss: 0.5442022965851431\n",
      "Validation Loss: 0.4620526328910348\n",
      "Train Loss: 0.5442022965840688\n",
      "Validation Loss: 0.4620526210510037\n",
      "Train Loss: 0.5442022965830055\n",
      "Validation Loss: 0.4620526089621534\n",
      "Train Loss: 0.544202296581954\n",
      "Validation Loss: 0.4620525972097838\n",
      "Train Loss: 0.5442022965809132\n",
      "Validation Loss: 0.4620525852085947\n",
      "Train Loss: 0.5442022965798837\n",
      "Validation Loss: 0.46205257325123616\n",
      "Train Loss: 0.5442022965788593\n",
      "Validation Loss: 0.462052561293883\n",
      "Train Loss: 0.5442022965778408\n",
      "Validation Loss: 0.4620525499218355\n",
      "Train Loss: 0.5442022965768388\n",
      "Validation Loss: 0.46205253834479304\n",
      "Train Loss: 0.5442022965758474\n",
      "Validation Loss: 0.4620525265189308\n",
      "Train Loss: 0.5442022965748677\n",
      "Validation Loss: 0.46205251532219893\n",
      "Train Loss: 0.5442022965738927\n",
      "Validation Loss: 0.46205250412547194\n",
      "Train Loss: 0.5442022965729341\n",
      "Validation Loss: 0.46205249272374976\n",
      "Train Loss: 0.5442022965719745\n",
      "Validation Loss: 0.462052481570858\n",
      "Train Loss: 0.5442022965710195\n",
      "Validation Loss: 0.4620524704179711\n",
      "Train Loss: 0.544202296570081\n",
      "Validation Loss: 0.4620524593527389\n",
      "Train Loss: 0.5442022965691524\n",
      "Validation Loss: 0.46205244803868634\n",
      "Train Loss: 0.5442022965682346\n",
      "Validation Loss: 0.4620524370611132\n",
      "Train Loss: 0.5442022965673265\n",
      "Validation Loss: 0.4620524258347196\n",
      "Train Loss: 0.544202296566429\n",
      "Validation Loss: 0.4620524149448055\n",
      "Train Loss: 0.5442022965655475\n",
      "Validation Loss: 0.46205240414254506\n",
      "Train Loss: 0.5442022965646645\n",
      "Validation Loss: 0.4620523932964648\n",
      "Train Loss: 0.5442022965637862\n",
      "Validation Loss: 0.462052382743039\n",
      "Train Loss: 0.5442022965629177\n",
      "Validation Loss: 0.46205237223344225\n",
      "Train Loss: 0.5442022965620588\n",
      "Validation Loss: 0.4620523614750247\n",
      "Train Loss: 0.5442022965612043\n",
      "Validation Loss: 0.46205235100926173\n",
      "Train Loss: 0.5442022965603648\n",
      "Validation Loss: 0.4620523403385021\n",
      "Train Loss: 0.5442022965595297\n",
      "Validation Loss: 0.4620523299603967\n",
      "Train Loss: 0.5442022965587093\n",
      "Validation Loss: 0.4620523193772947\n",
      "Train Loss: 0.5442022965578879\n",
      "Validation Loss: 0.4620523090430223\n",
      "Train Loss: 0.5442022965570759\n",
      "Validation Loss: 0.46205229875257864\n",
      "Train Loss: 0.5442022965562732\n",
      "Validation Loss: 0.46205228850596347\n",
      "Train Loss: 0.5442022965554799\n",
      "Validation Loss: 0.4620522783031768\n",
      "Train Loss: 0.5442022965546908\n",
      "Validation Loss: 0.4620522683930441\n",
      "Train Loss: 0.5442022965539154\n",
      "Validation Loss: 0.46205225798526445\n",
      "Train Loss: 0.5442022965531442\n",
      "Validation Loss: 0.4620522478701386\n",
      "Train Loss: 0.5442022965523821\n",
      "Validation Loss: 0.4620522377988409\n",
      "Train Loss: 0.544202296551624\n",
      "Validation Loss: 0.4620522280201969\n",
      "Train Loss: 0.5442022965508745\n",
      "Validation Loss: 0.4620522179927314\n",
      "Train Loss: 0.5442022965501339\n",
      "Validation Loss: 0.4620522080090939\n",
      "Train Loss: 0.5442022965493972\n",
      "Validation Loss: 0.4620521983181098\n",
      "Train Loss: 0.5442022965486693\n",
      "Validation Loss: 0.4620521886709536\n",
      "Train Loss: 0.5442022965479548\n",
      "Validation Loss: 0.4620521788187997\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022965472442\n",
      "Validation Loss: 0.4620521692592989\n",
      "Train Loss: 0.5442022965465315\n",
      "Validation Loss: 0.4620521593633285\n",
      "Train Loss: 0.5442022965458277\n",
      "Validation Loss: 0.46205214980383535\n",
      "Train Loss: 0.5442022965451376\n",
      "Validation Loss: 0.4620521403319937\n",
      "Train Loss: 0.5442022965444456\n",
      "Validation Loss: 0.4620521308163316\n",
      "Train Loss: 0.5442022965437667\n",
      "Validation Loss: 0.4620521210956717\n",
      "Train Loss: 0.544202296543096\n",
      "Validation Loss: 0.4620521114188389\n",
      "Train Loss: 0.544202296542434\n",
      "Validation Loss: 0.46205210207848313\n",
      "Train Loss: 0.5442022965417751\n",
      "Validation Loss: 0.4620520927381304\n",
      "Train Loss: 0.544202296541124\n",
      "Validation Loss: 0.46205208314895596\n",
      "Train Loss: 0.5442022965404764\n",
      "Validation Loss: 0.4620520738524341\n",
      "Train Loss: 0.5442022965398366\n",
      "Validation Loss: 0.4620520645997393\n",
      "Train Loss: 0.544202296539205\n",
      "Validation Loss: 0.46205205539087163\n",
      "Train Loss: 0.5442022965385768\n",
      "Validation Loss: 0.46205204647465653\n",
      "Train Loss: 0.5442022965379564\n",
      "Validation Loss: 0.46205203760226826\n",
      "Train Loss: 0.5442022965373434\n",
      "Validation Loss: 0.4620520284810577\n",
      "Train Loss: 0.5442022965367336\n",
      "Validation Loss: 0.4620520196524996\n",
      "Train Loss: 0.5442022965361359\n",
      "Validation Loss: 0.46205201061894247\n",
      "Train Loss: 0.5442022965355411\n",
      "Validation Loss: 0.4620520015853884\n",
      "Train Loss: 0.544202296534949\n",
      "Validation Loss: 0.46205199255183754\n",
      "Train Loss: 0.5442022965343647\n",
      "Validation Loss: 0.46205198356211336\n",
      "Train Loss: 0.5442022965337788\n",
      "Validation Loss: 0.46205197482121785\n",
      "Train Loss: 0.5442022965332001\n",
      "Validation Loss: 0.46205196583149977\n",
      "Train Loss: 0.5442022965326291\n",
      "Validation Loss: 0.4620519571782572\n",
      "Train Loss: 0.5442022965320609\n",
      "Validation Loss: 0.4620519485250178\n",
      "Train Loss: 0.5442022965315049\n",
      "Validation Loss: 0.46205194025207713\n",
      "Train Loss: 0.5442022965309512\n",
      "Validation Loss: 0.4620519316864904\n",
      "Train Loss: 0.5442022965304002\n",
      "Validation Loss: 0.4620519231209065\n",
      "Train Loss: 0.5442022965298612\n",
      "Validation Loss: 0.46205191493562114\n",
      "Train Loss: 0.5442022965293285\n",
      "Validation Loss: 0.4620519062088637\n",
      "Train Loss: 0.5442022965287947\n",
      "Validation Loss: 0.4620518980235839\n",
      "Train Loss: 0.5442022965282631\n",
      "Validation Loss: 0.46205188954565796\n",
      "Train Loss: 0.5442022965277389\n",
      "Validation Loss: 0.46205188140420705\n",
      "Train Loss: 0.5442022965272172\n",
      "Validation Loss: 0.46205187326275887\n",
      "Train Loss: 0.5442022965267025\n",
      "Validation Loss: 0.4620518651651367\n",
      "Train Loss: 0.5442022965261945\n",
      "Validation Loss: 0.4620518571113401\n",
      "Train Loss: 0.5442022965256929\n",
      "Validation Loss: 0.46205184880872063\n",
      "Train Loss: 0.5442022965251941\n",
      "Validation Loss: 0.4620518407987525\n",
      "Train Loss: 0.5442022965247015\n",
      "Validation Loss: 0.4620518325399613\n",
      "Train Loss: 0.54420229652422\n",
      "Validation Loss: 0.4620518243688187\n",
      "Train Loss: 0.5442022965237369\n",
      "Validation Loss: 0.46205181644650445\n",
      "Train Loss: 0.5442022965232602\n",
      "Validation Loss: 0.4620518085680158\n",
      "Train Loss: 0.544202296522786\n",
      "Validation Loss: 0.46205180068952967\n",
      "Train Loss: 0.5442022965223181\n",
      "Validation Loss: 0.46205179285486914\n",
      "Train Loss: 0.5442022965218525\n",
      "Validation Loss: 0.46205178502021094\n",
      "Train Loss: 0.544202296521393\n",
      "Validation Loss: 0.4620517769367293\n",
      "Train Loss: 0.5442022965209363\n",
      "Validation Loss: 0.46205176943854764\n",
      "Train Loss: 0.5442022965204857\n",
      "Validation Loss: 0.46205176169154255\n",
      "Train Loss: 0.5442022965200332\n",
      "Validation Loss: 0.46205175390071684\n",
      "Train Loss: 0.5442022965195907\n",
      "Validation Loss: 0.46205174619753936\n",
      "Train Loss: 0.5442022965191543\n",
      "Validation Loss: 0.4620517382455382\n",
      "Train Loss: 0.5442022965187243\n",
      "Validation Loss: 0.46205173063001087\n",
      "Train Loss: 0.5442022965182968\n",
      "Validation Loss: 0.4620517233071346\n",
      "Train Loss: 0.5442022965178709\n",
      "Validation Loss: 0.46205171569161196\n",
      "Train Loss: 0.5442022965174474\n",
      "Validation Loss: 0.4620517083687402\n",
      "Train Loss: 0.5442022965170299\n",
      "Validation Loss: 0.4620517010896933\n",
      "Train Loss: 0.5442022965166181\n",
      "Validation Loss: 0.4620516935618226\n",
      "Train Loss: 0.5442022965162046\n",
      "Validation Loss: 0.46205168628278015\n",
      "Train Loss: 0.5442022965158005\n",
      "Validation Loss: 0.46205167879873654\n",
      "Train Loss: 0.5442022965153985\n",
      "Validation Loss: 0.46205167131469504\n",
      "Train Loss: 0.5442022965149991\n",
      "Validation Loss: 0.4620516644159529\n",
      "Train Loss: 0.544202296514605\n",
      "Validation Loss: 0.4620516572683869\n",
      "Train Loss: 0.5442022965142128\n",
      "Validation Loss: 0.46205165012082294\n",
      "Train Loss: 0.5442022965138299\n",
      "Validation Loss: 0.46205164276825755\n",
      "Train Loss: 0.5442022965134453\n",
      "Validation Loss: 0.4620516356645203\n",
      "Train Loss: 0.5442022965130663\n",
      "Validation Loss: 0.4620516286046075\n",
      "Train Loss: 0.5442022965126929\n",
      "Validation Loss: 0.4620516215885193\n",
      "Train Loss: 0.5442022965123176\n",
      "Validation Loss: 0.46205161452861043\n",
      "Train Loss: 0.5442022965119514\n",
      "Validation Loss: 0.46205160755634866\n",
      "Train Loss: 0.544202296511587\n",
      "Validation Loss: 0.4620516005840888\n",
      "Train Loss: 0.5442022965112278\n",
      "Validation Loss: 0.46205159336300466\n",
      "Train Loss: 0.5442022965108706\n",
      "Validation Loss: 0.4620515864345709\n",
      "Train Loss: 0.5442022965105187\n",
      "Validation Loss: 0.4620515795499616\n",
      "Train Loss: 0.5442022965101686\n",
      "Validation Loss: 0.462051572665354\n",
      "Train Loss: 0.5442022965098204\n",
      "Validation Loss: 0.4620515660733968\n",
      "Train Loss: 0.5442022965094737\n",
      "Validation Loss: 0.46205155918879304\n",
      "Train Loss: 0.5442022965091289\n",
      "Validation Loss: 0.4620515525968396\n",
      "Train Loss: 0.5442022965087894\n",
      "Validation Loss: 0.4620515460487103\n",
      "Train Loss: 0.544202296508455\n",
      "Validation Loss: 0.462051539544405\n",
      "Train Loss: 0.5442022965081257\n",
      "Validation Loss: 0.4620515330839237\n",
      "Train Loss: 0.5442022965077977\n",
      "Validation Loss: 0.4620515263307959\n",
      "Train Loss: 0.544202296507475\n",
      "Validation Loss: 0.46205151991414023\n",
      "Train Loss: 0.544202296507157\n",
      "Validation Loss: 0.4620515132486601\n",
      "Train Loss: 0.5442022965068406\n",
      "Validation Loss: 0.46205150658318167\n",
      "Train Loss: 0.5442022965065294\n",
      "Validation Loss: 0.4620515002541756\n",
      "Train Loss: 0.5442022965062194\n",
      "Validation Loss: 0.46205149363252257\n",
      "Train Loss: 0.5442022965059112\n",
      "Validation Loss: 0.4620514873035197\n",
      "Train Loss: 0.5442022965056046\n",
      "Validation Loss: 0.4620514809745184\n",
      "Train Loss: 0.5442022965052994\n",
      "Validation Loss: 0.46205147464551866\n",
      "Train Loss: 0.5442022965049955\n",
      "Validation Loss: 0.4620514683165208\n",
      "Train Loss: 0.5442022965046998\n",
      "Validation Loss: 0.46205146178252\n",
      "Train Loss: 0.5442022965044058\n",
      "Validation Loss: 0.4620514558338176\n",
      "Train Loss: 0.544202296504113\n",
      "Validation Loss: 0.4620514495924686\n",
      "Train Loss: 0.5442022965038247\n",
      "Validation Loss: 0.46205144310229457\n",
      "Train Loss: 0.5442022965035412\n",
      "Validation Loss: 0.4620514369485925\n",
      "Train Loss: 0.544202296503256\n",
      "Validation Loss: 0.46205143075106997\n",
      "Train Loss: 0.5442022965029756\n",
      "Validation Loss: 0.4620514248900192\n",
      "Train Loss: 0.5442022965026962\n",
      "Validation Loss: 0.4620514187363217\n",
      "Train Loss: 0.5442022965024185\n",
      "Validation Loss: 0.46205141287527396\n",
      "Train Loss: 0.5442022965021482\n",
      "Validation Loss: 0.4620514068092231\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022965018792\n",
      "Validation Loss: 0.4620514007431739\n",
      "Train Loss: 0.5442022965016117\n",
      "Validation Loss: 0.4620513946771259\n",
      "Train Loss: 0.5442022965013485\n",
      "Validation Loss: 0.46205138894754955\n",
      "Train Loss: 0.5442022965010895\n",
      "Validation Loss: 0.4620513826765\n",
      "Train Loss: 0.5442022965008291\n",
      "Validation Loss: 0.4620513769469265\n",
      "Train Loss: 0.5442022965005698\n",
      "Validation Loss: 0.4620513712173543\n",
      "Train Loss: 0.5442022965003179\n",
      "Validation Loss: 0.46205136557542703\n",
      "Train Loss: 0.5442022965000699\n",
      "Validation Loss: 0.4620513593920264\n",
      "Train Loss: 0.5442022964998233\n",
      "Validation Loss: 0.46205135350127546\n",
      "Train Loss: 0.5442022964995781\n",
      "Validation Loss: 0.462051347903174\n",
      "Train Loss: 0.5442022964993342\n",
      "Validation Loss: 0.4620513423050737\n",
      "Train Loss: 0.5442022964990914\n",
      "Validation Loss: 0.46205133670697474\n",
      "Train Loss: 0.5442022964988498\n",
      "Validation Loss: 0.46205133110887714\n",
      "Train Loss: 0.5442022964986095\n",
      "Validation Loss: 0.46205132580342895\n",
      "Train Loss: 0.5442022964983759\n",
      "Validation Loss: 0.4620513200003291\n",
      "Train Loss: 0.5442022964981437\n",
      "Validation Loss: 0.46205131448987863\n",
      "Train Loss: 0.5442022964979154\n",
      "Validation Loss: 0.4620513090232511\n",
      "Train Loss: 0.5442022964976884\n",
      "Validation Loss: 0.4620513035566247\n",
      "Train Loss: 0.5442022964974623\n",
      "Validation Loss: 0.4620512980899995\n",
      "Train Loss: 0.5442022964972376\n",
      "Validation Loss: 0.46205129291602376\n",
      "Train Loss: 0.5442022964970138\n",
      "Validation Loss: 0.4620512874494008\n",
      "Train Loss: 0.544202296496794\n",
      "Validation Loss: 0.46205128202660073\n",
      "Train Loss: 0.5442022964965753\n",
      "Validation Loss: 0.46205127689645004\n",
      "Train Loss: 0.5442022964963601\n",
      "Validation Loss: 0.46205127122482575\n",
      "Train Loss: 0.5442022964961489\n",
      "Validation Loss: 0.46205126588967244\n",
      "Train Loss: 0.5442022964959387\n",
      "Validation Loss: 0.462051260261872\n",
      "Train Loss: 0.5442022964957298\n",
      "Validation Loss: 0.46205125521936874\n",
      "Train Loss: 0.5442022964955245\n",
      "Validation Loss: 0.46205124992804014\n",
      "Train Loss: 0.5442022964953203\n",
      "Validation Loss: 0.46205124463671254\n",
      "Train Loss: 0.5442022964951144\n",
      "Validation Loss: 0.46205123959421285\n",
      "Train Loss: 0.5442022964949121\n",
      "Validation Loss: 0.4620512343028874\n",
      "Train Loss: 0.5442022964947111\n",
      "Validation Loss: 0.46205122930421116\n",
      "Train Loss: 0.5442022964945109\n",
      "Validation Loss: 0.46205122430553597\n",
      "Train Loss: 0.5442022964943168\n",
      "Validation Loss: 0.46205121910185665\n",
      "Train Loss: 0.5442022964941264\n",
      "Validation Loss: 0.462051213942\n",
      "Train Loss: 0.544202296493937\n",
      "Validation Loss: 0.46205120878214395\n",
      "Train Loss: 0.5442022964937461\n",
      "Validation Loss: 0.4620512038711157\n",
      "Train Loss: 0.544202296493556\n",
      "Validation Loss: 0.46205119896008856\n",
      "Train Loss: 0.5442022964933693\n",
      "Validation Loss: 0.4620511938002356\n",
      "Train Loss: 0.5442022964931862\n",
      "Validation Loss: 0.4620511889768532\n",
      "Train Loss: 0.5442022964930064\n",
      "Validation Loss: 0.46205118390464484\n",
      "Train Loss: 0.5442022964928278\n",
      "Validation Loss: 0.46205117912508564\n",
      "Train Loss: 0.54420229649265\n",
      "Validation Loss: 0.46205117434552734\n",
      "Train Loss: 0.5442022964924755\n",
      "Validation Loss: 0.4620511696097911\n",
      "Train Loss: 0.5442022964923018\n",
      "Validation Loss: 0.462051164581408\n",
      "Train Loss: 0.544202296492129\n",
      "Validation Loss: 0.4620511598456737\n",
      "Train Loss: 0.5442022964919596\n",
      "Validation Loss: 0.46205115515376144\n",
      "Train Loss: 0.5442022964917886\n",
      "Validation Loss: 0.46205115041802897\n",
      "Train Loss: 0.5442022964916211\n",
      "Validation Loss: 0.4620511460187665\n",
      "Train Loss: 0.5442022964914544\n",
      "Validation Loss: 0.46205114161950495\n",
      "Train Loss: 0.5442022964912907\n",
      "Validation Loss: 0.46205113697141736\n",
      "Train Loss: 0.5442022964911277\n",
      "Validation Loss: 0.4620511323233309\n",
      "Train Loss: 0.5442022964909656\n",
      "Validation Loss: 0.46205112767524503\n",
      "Train Loss: 0.5442022964908068\n",
      "Validation Loss: 0.4620511230709814\n",
      "Train Loss: 0.5442022964906487\n",
      "Validation Loss: 0.4620511184667185\n",
      "Train Loss: 0.5442022964904913\n",
      "Validation Loss: 0.4620511138624565\n",
      "Train Loss: 0.5442022964903371\n",
      "Validation Loss: 0.4620511093020165\n",
      "Train Loss: 0.5442022964901814\n",
      "Validation Loss: 0.46205110469775607\n",
      "Train Loss: 0.5442022964900265\n",
      "Validation Loss: 0.4620511003861443\n",
      "Train Loss: 0.5442022964898747\n",
      "Validation Loss: 0.46205109611835454\n",
      "Train Loss: 0.5442022964897235\n",
      "Validation Loss: 0.46205109155791774\n",
      "Train Loss: 0.5442022964895733\n",
      "Validation Loss: 0.4620510872901295\n",
      "Train Loss: 0.5442022964894234\n",
      "Validation Loss: 0.4620510827296943\n",
      "Train Loss: 0.5442022964892791\n",
      "Validation Loss: 0.46205107825690206\n",
      "Train Loss: 0.5442022964891357\n",
      "Validation Loss: 0.4620510740767582\n",
      "Train Loss: 0.5442022964889905\n",
      "Validation Loss: 0.46205106985279415\n",
      "Train Loss: 0.5442022964888485\n",
      "Validation Loss: 0.462051065672652\n",
      "Train Loss: 0.5442022964887091\n",
      "Validation Loss: 0.4620510612436837\n",
      "Train Loss: 0.5442022964885705\n",
      "Validation Loss: 0.4620510568147161\n",
      "Train Loss: 0.5442022964884325\n",
      "Validation Loss: 0.46205105238574945\n",
      "Train Loss: 0.5442022964882977\n",
      "Validation Loss: 0.462051048293252\n",
      "Train Loss: 0.5442022964881633\n",
      "Validation Loss: 0.4620510439081077\n",
      "Train Loss: 0.5442022964880298\n",
      "Validation Loss: 0.4620510398156115\n",
      "Train Loss: 0.5442022964878968\n",
      "Validation Loss: 0.4620510357231165\n",
      "Train Loss: 0.5442022964877665\n",
      "Validation Loss: 0.46205103138179515\n",
      "Train Loss: 0.5442022964876368\n",
      "Validation Loss: 0.46205102704047446\n",
      "Train Loss: 0.5442022964875078\n",
      "Validation Loss: 0.46205102269915455\n",
      "Train Loss: 0.5442022964873818\n",
      "Validation Loss: 0.46205101869430387\n",
      "Train Loss: 0.5442022964872563\n",
      "Validation Loss: 0.4620510143968061\n",
      "Train Loss: 0.5442022964871314\n",
      "Validation Loss: 0.4620510103919568\n",
      "Train Loss: 0.5442022964870092\n",
      "Validation Loss: 0.46205100613828126\n",
      "Train Loss: 0.5442022964868857\n",
      "Validation Loss: 0.46205100242608094\n",
      "Train Loss: 0.5442022964867648\n",
      "Validation Loss: 0.4620509984650544\n",
      "Train Loss: 0.5442022964866443\n",
      "Validation Loss: 0.4620509942113809\n",
      "Train Loss: 0.5442022964865247\n",
      "Validation Loss: 0.46205099054300336\n",
      "Train Loss: 0.5442022964864075\n",
      "Validation Loss: 0.4620509863331518\n",
      "Train Loss: 0.544202296486291\n",
      "Validation Loss: 0.4620509824159487\n",
      "Train Loss: 0.5442022964861771\n",
      "Validation Loss: 0.4620509785425668\n",
      "Train Loss: 0.5442022964860618\n",
      "Validation Loss: 0.4620509746253649\n",
      "Train Loss: 0.5442022964859491\n",
      "Validation Loss: 0.4620509707519843\n",
      "Train Loss: 0.5442022964858348\n",
      "Validation Loss: 0.4620509671274312\n",
      "Train Loss: 0.5442022964857252\n",
      "Validation Loss: 0.46205096300522497\n",
      "Train Loss: 0.5442022964856161\n",
      "Validation Loss: 0.4620509594683144\n",
      "Train Loss: 0.5442022964855074\n",
      "Validation Loss: 0.46205095534610935\n",
      "Train Loss: 0.5442022964853995\n",
      "Validation Loss: 0.4620509518092\n",
      "Train Loss: 0.544202296485292\n",
      "Validation Loss: 0.46205094797964363\n",
      "Train Loss: 0.5442022964851868\n",
      "Validation Loss: 0.4620509441939085\n",
      "Train Loss: 0.5442022964850841\n",
      "Validation Loss: 0.46205094015934706\n",
      "Train Loss: 0.5442022964849822\n",
      "Validation Loss: 0.4620509367100813\n",
      "Train Loss: 0.5442022964848806\n",
      "Validation Loss: 0.4620509329681685\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964847797\n",
      "Validation Loss: 0.46205092951890403\n",
      "Train Loss: 0.5442022964846773\n",
      "Validation Loss: 0.4620509260258191\n",
      "Train Loss: 0.5442022964845773\n",
      "Validation Loss: 0.4620509225765555\n",
      "Train Loss: 0.5442022964844776\n",
      "Validation Loss: 0.4620509188346449\n",
      "Train Loss: 0.5442022964843803\n",
      "Validation Loss: 0.46205091484390776\n",
      "Train Loss: 0.5442022964842818\n",
      "Validation Loss: 0.4620509113946458\n",
      "Train Loss: 0.5442022964841855\n",
      "Validation Loss: 0.46205090769655727\n",
      "Train Loss: 0.5442022964840898\n",
      "Validation Loss: 0.4620509042911167\n",
      "Train Loss: 0.5442022964839947\n",
      "Validation Loss: 0.46205090088567685\n",
      "Train Loss: 0.5442022964839016\n",
      "Validation Loss: 0.4620508975240582\n",
      "Train Loss: 0.544202296483809\n",
      "Validation Loss: 0.4620508938697923\n",
      "Train Loss: 0.5442022964837188\n",
      "Validation Loss: 0.4620508902593475\n",
      "Train Loss: 0.5442022964836272\n",
      "Validation Loss: 0.46205088689773005\n",
      "Train Loss: 0.5442022964835396\n",
      "Validation Loss: 0.46205088333110667\n",
      "Train Loss: 0.5442022964834508\n",
      "Validation Loss: 0.4620508800133108\n",
      "Train Loss: 0.544202296483362\n",
      "Validation Loss: 0.46205087640286785\n",
      "Train Loss: 0.5442022964832758\n",
      "Validation Loss: 0.46205087283624596\n",
      "Train Loss: 0.5442022964831884\n",
      "Validation Loss: 0.4620508698110989\n",
      "Train Loss: 0.5442022964831029\n",
      "Validation Loss: 0.46205086653712535\n",
      "Train Loss: 0.5442022964830199\n",
      "Validation Loss: 0.4620508633069728\n",
      "Train Loss: 0.5442022964829353\n",
      "Validation Loss: 0.4620508600330001\n",
      "Train Loss: 0.5442022964828511\n",
      "Validation Loss: 0.4620508567590279\n",
      "Train Loss: 0.544202296482769\n",
      "Validation Loss: 0.46205085323622924\n",
      "Train Loss: 0.5442022964826871\n",
      "Validation Loss: 0.46205084971343074\n",
      "Train Loss: 0.5442022964826094\n",
      "Validation Loss: 0.4620508462782738\n",
      "Train Loss: 0.5442022964825303\n",
      "Validation Loss: 0.4620508430919442\n",
      "Train Loss: 0.5442022964824516\n",
      "Validation Loss: 0.46205083990561513\n",
      "Train Loss: 0.5442022964823732\n",
      "Validation Loss: 0.4620508367192863\n",
      "Train Loss: 0.5442022964822968\n",
      "Validation Loss: 0.46205083328413105\n",
      "Train Loss: 0.544202296482221\n",
      "Validation Loss: 0.4620508301416234\n",
      "Train Loss: 0.5442022964821439\n",
      "Validation Loss: 0.4620508272479434\n",
      "Train Loss: 0.5442022964820689\n",
      "Validation Loss: 0.462050824398084\n",
      "Train Loss: 0.544202296481994\n",
      "Validation Loss: 0.46205082125557756\n",
      "Train Loss: 0.5442022964819212\n",
      "Validation Loss: 0.46205081815689214\n",
      "Train Loss: 0.5442022964818487\n",
      "Validation Loss: 0.4620508147655593\n",
      "Train Loss: 0.5442022964817765\n",
      "Validation Loss: 0.46205081166687456\n",
      "Train Loss: 0.5442022964817049\n",
      "Validation Loss: 0.46205080856819014\n",
      "Train Loss: 0.5442022964816337\n",
      "Validation Loss: 0.4620508057621535\n",
      "Train Loss: 0.5442022964815626\n",
      "Validation Loss: 0.46205080266346965\n",
      "Train Loss: 0.5442022964814935\n",
      "Validation Loss: 0.46205079960860657\n",
      "Train Loss: 0.5442022964814247\n",
      "Validation Loss: 0.46205079655374415\n",
      "Train Loss: 0.5442022964813578\n",
      "Validation Loss: 0.4620507932500548\n",
      "Train Loss: 0.5442022964812913\n",
      "Validation Loss: 0.462050790239013\n",
      "Train Loss: 0.5442022964812234\n",
      "Validation Loss: 0.46205078718415143\n",
      "Train Loss: 0.5442022964811575\n",
      "Validation Loss: 0.46205078388046333\n",
      "Train Loss: 0.544202296481092\n",
      "Validation Loss: 0.4620507811620701\n",
      "Train Loss: 0.5442022964810284\n",
      "Validation Loss: 0.4620507781948501\n",
      "Train Loss: 0.5442022964809634\n",
      "Validation Loss: 0.4620507751838102\n",
      "Train Loss: 0.5442022964809005\n",
      "Validation Loss: 0.4620507722165908\n",
      "Train Loss: 0.5442022964808347\n",
      "Validation Loss: 0.46205076974702614\n",
      "Train Loss: 0.5442022964807723\n",
      "Validation Loss: 0.46205076677980755\n",
      "Train Loss: 0.5442022964807103\n",
      "Validation Loss: 0.46205076410523643\n",
      "Train Loss: 0.54420229648065\n",
      "Validation Loss: 0.46205076147448615\n",
      "Train Loss: 0.5442022964805899\n",
      "Validation Loss: 0.4620507582584412\n",
      "Train Loss: 0.5442022964805288\n",
      "Validation Loss: 0.46205075558387126\n",
      "Train Loss: 0.5442022964804692\n",
      "Validation Loss: 0.46205075266047446\n",
      "Train Loss: 0.5442022964804116\n",
      "Validation Loss: 0.46205075007354557\n",
      "Train Loss: 0.5442022964803542\n",
      "Validation Loss: 0.4620507471939695\n",
      "Train Loss: 0.5442022964802956\n",
      "Validation Loss: 0.4620507442705737\n",
      "Train Loss: 0.5442022964802388\n",
      "Validation Loss: 0.46205074168364557\n",
      "Train Loss: 0.5442022964801823\n",
      "Validation Loss: 0.4620507388040704\n",
      "Train Loss: 0.5442022964801261\n",
      "Validation Loss: 0.462050736217143\n",
      "Train Loss: 0.5442022964800687\n",
      "Validation Loss: 0.4620507335863956\n",
      "Train Loss: 0.5442022964800128\n",
      "Validation Loss: 0.46205073070682123\n",
      "Train Loss: 0.5442022964799588\n",
      "Validation Loss: 0.46205072787106743\n",
      "Train Loss: 0.5442022964799049\n",
      "Validation Loss: 0.4620507250353142\n",
      "Train Loss: 0.5442022964798515\n",
      "Validation Loss: 0.46205072249220797\n",
      "Train Loss: 0.5442022964797982\n",
      "Validation Loss: 0.4620507199491024\n",
      "Train Loss: 0.5442022964797466\n",
      "Validation Loss: 0.4620507171571699\n",
      "Train Loss: 0.5442022964796953\n",
      "Validation Loss: 0.4620507146578849\n",
      "Train Loss: 0.5442022964796444\n",
      "Validation Loss: 0.46205071215860016\n",
      "Train Loss: 0.5442022964795922\n",
      "Validation Loss: 0.46205070990814284\n",
      "Train Loss: 0.5442022964795414\n",
      "Validation Loss: 0.46205070682356414\n",
      "Train Loss: 0.5442022964794926\n",
      "Validation Loss: 0.46205070436810025\n",
      "Train Loss: 0.5442022964794412\n",
      "Validation Loss: 0.4620507021176437\n",
      "Train Loss: 0.5442022964793927\n",
      "Validation Loss: 0.46205069936953325\n",
      "Train Loss: 0.5442022964793444\n",
      "Validation Loss: 0.46205069691406997\n",
      "Train Loss: 0.5442022964792963\n",
      "Validation Loss: 0.4620506944586071\n",
      "Train Loss: 0.5442022964792498\n",
      "Validation Loss: 0.4620506917543175\n",
      "Train Loss: 0.5442022964792034\n",
      "Validation Loss: 0.46205068905002794\n",
      "Train Loss: 0.5442022964791574\n",
      "Validation Loss: 0.46205068634573865\n",
      "Train Loss: 0.5442022964791103\n",
      "Validation Loss: 0.4620506838902767\n",
      "Train Loss: 0.5442022964790636\n",
      "Validation Loss: 0.46205068172746216\n",
      "Train Loss: 0.5442022964790183\n",
      "Validation Loss: 0.462050679608468\n",
      "Train Loss: 0.5442022964789731\n",
      "Validation Loss: 0.462050677196827\n",
      "Train Loss: 0.5442022964789295\n",
      "Validation Loss: 0.46205067453635895\n",
      "Train Loss: 0.5442022964788862\n",
      "Validation Loss: 0.4620506724611854\n",
      "Train Loss: 0.544202296478843\n",
      "Validation Loss: 0.46205067009336503\n",
      "Train Loss: 0.5442022964788\n",
      "Validation Loss: 0.46205066772554465\n",
      "Train Loss: 0.5442022964787573\n",
      "Validation Loss: 0.46205066565037184\n",
      "Train Loss: 0.5442022964787158\n",
      "Validation Loss: 0.4620506630337249\n",
      "Train Loss: 0.5442022964786746\n",
      "Validation Loss: 0.46205066041707815\n",
      "Train Loss: 0.5442022964786336\n",
      "Validation Loss: 0.4620506578004315\n",
      "Train Loss: 0.5442022964785929\n",
      "Validation Loss: 0.4620506554764323\n",
      "Train Loss: 0.5442022964785524\n",
      "Validation Loss: 0.46205065344508056\n",
      "Train Loss: 0.544202296478512\n",
      "Validation Loss: 0.4620506511210818\n",
      "Train Loss: 0.544202296478472\n",
      "Validation Loss: 0.46205064879708324\n",
      "Train Loss: 0.544202296478432\n",
      "Validation Loss: 0.46205064647308486\n",
      "Train Loss: 0.5442022964783922\n",
      "Validation Loss: 0.46205064414908675\n",
      "Train Loss: 0.5442022964783527\n",
      "Validation Loss: 0.46205064211773605\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964783146\n",
      "Validation Loss: 0.46205063983755806\n",
      "Train Loss: 0.5442022964782766\n",
      "Validation Loss: 0.46205063755738063\n",
      "Train Loss: 0.5442022964782387\n",
      "Validation Loss: 0.4620506352772032\n",
      "Train Loss: 0.5442022964782023\n",
      "Validation Loss: 0.46205063274819874\n",
      "Train Loss: 0.5442022964781649\n",
      "Validation Loss: 0.4620506307606687\n",
      "Train Loss: 0.5442022964781277\n",
      "Validation Loss: 0.46205062848049205\n",
      "Train Loss: 0.5442022964780906\n",
      "Validation Loss: 0.46205062649296263\n",
      "Train Loss: 0.5442022964780561\n",
      "Validation Loss: 0.46205062430042576\n",
      "Train Loss: 0.5442022964780205\n",
      "Validation Loss: 0.4620506220640695\n",
      "Train Loss: 0.5442022964779851\n",
      "Validation Loss: 0.4620506198277133\n",
      "Train Loss: 0.5442022964779499\n",
      "Validation Loss: 0.4620506178840043\n",
      "Train Loss: 0.5442022964779161\n",
      "Validation Loss: 0.4620506156914684\n",
      "Train Loss: 0.5442022964778812\n",
      "Validation Loss: 0.4620506137477599\n",
      "Train Loss: 0.5442022964778476\n",
      "Validation Loss: 0.4620506112625771\n",
      "Train Loss: 0.5442022964778142\n",
      "Validation Loss: 0.4620506090700417\n",
      "Train Loss: 0.544202296477781\n",
      "Validation Loss: 0.46205060717015356\n",
      "Train Loss: 0.5442022964777478\n",
      "Validation Loss: 0.46205060497761846\n",
      "Train Loss: 0.5442022964777159\n",
      "Validation Loss: 0.46205060282890326\n",
      "Train Loss: 0.5442022964776843\n",
      "Validation Loss: 0.46205060068018833\n",
      "Train Loss: 0.5442022964776528\n",
      "Validation Loss: 0.46205059882412053\n",
      "Train Loss: 0.5442022964776214\n",
      "Validation Loss: 0.46205059696805295\n",
      "Train Loss: 0.5442022964775912\n",
      "Validation Loss: 0.46205059457051123\n",
      "Train Loss: 0.5442022964775601\n",
      "Validation Loss: 0.46205059271444393\n",
      "Train Loss: 0.5442022964775303\n",
      "Validation Loss: 0.4620505903169025\n",
      "Train Loss: 0.5442022964774996\n",
      "Validation Loss: 0.4620505887534827\n",
      "Train Loss: 0.5442022964774689\n",
      "Validation Loss: 0.4620505866047688\n",
      "Train Loss: 0.5442022964774396\n",
      "Validation Loss: 0.462050584792522\n",
      "Train Loss: 0.5442022964774104\n",
      "Validation Loss: 0.46205058298027524\n",
      "Train Loss: 0.5442022964773812\n",
      "Validation Loss: 0.4620505808753818\n",
      "Train Loss: 0.5442022964773521\n",
      "Validation Loss: 0.4620505787704882\n",
      "Train Loss: 0.5442022964773242\n",
      "Validation Loss: 0.46205057670941474\n",
      "Train Loss: 0.5442022964772966\n",
      "Validation Loss: 0.46205057464834126\n",
      "Train Loss: 0.544202296477269\n",
      "Validation Loss: 0.46205057287991513\n",
      "Train Loss: 0.5442022964772416\n",
      "Validation Loss: 0.46205057111148884\n",
      "Train Loss: 0.5442022964772143\n",
      "Validation Loss: 0.4620505690504159\n",
      "Train Loss: 0.5442022964771871\n",
      "Validation Loss: 0.46205056698934305\n",
      "Train Loss: 0.5442022964771601\n",
      "Validation Loss: 0.4620505652209175\n",
      "Train Loss: 0.5442022964771331\n",
      "Validation Loss: 0.4620505631598449\n",
      "Train Loss: 0.5442022964771064\n",
      "Validation Loss: 0.4620505610987725\n",
      "Train Loss: 0.5442022964770798\n",
      "Validation Loss: 0.4620505593303472\n",
      "Train Loss: 0.5442022964770523\n",
      "Validation Loss: 0.46205055751810237\n",
      "Train Loss: 0.544202296477027\n",
      "Validation Loss: 0.4620505557934972\n",
      "Train Loss: 0.5442022964770008\n",
      "Validation Loss: 0.46205055402507234\n",
      "Train Loss: 0.5442022964769747\n",
      "Validation Loss: 0.4620505525492947\n",
      "Train Loss: 0.5442022964769506\n",
      "Validation Loss: 0.46205055057586236\n",
      "Train Loss: 0.5442022964769258\n",
      "Validation Loss: 0.46205054855861066\n",
      "Train Loss: 0.544202296476901\n",
      "Validation Loss: 0.462050546834006\n",
      "Train Loss: 0.5442022964768763\n",
      "Validation Loss: 0.46205054510940147\n",
      "Train Loss: 0.5442022964768527\n",
      "Validation Loss: 0.4620505431359697\n",
      "Train Loss: 0.5442022964768292\n",
      "Validation Loss: 0.46205054116253813\n",
      "Train Loss: 0.5442022964768058\n",
      "Validation Loss: 0.46205053948175356\n",
      "Train Loss: 0.5442022964767825\n",
      "Validation Loss: 0.46205053780096933\n",
      "Train Loss: 0.5442022964767603\n",
      "Validation Loss: 0.46205053587135764\n",
      "Train Loss: 0.5442022964767382\n",
      "Validation Loss: 0.46205053423439324\n",
      "Train Loss: 0.5442022964767163\n",
      "Validation Loss: 0.4620505323047817\n",
      "Train Loss: 0.5442022964766935\n",
      "Validation Loss: 0.4620505309166448\n",
      "Train Loss: 0.5442022964766717\n",
      "Validation Loss: 0.4620505292796806\n",
      "Train Loss: 0.5442022964766501\n",
      "Validation Loss: 0.46205052793536355\n",
      "Train Loss: 0.5442022964766284\n",
      "Validation Loss: 0.4620505260057526\n",
      "Train Loss: 0.544202296476607\n",
      "Validation Loss: 0.4620505240761418\n",
      "Train Loss: 0.5442022964765856\n",
      "Validation Loss: 0.462050522439178\n",
      "Train Loss: 0.5442022964765644\n",
      "Validation Loss: 0.4620505208022145\n",
      "Train Loss: 0.5442022964765432\n",
      "Validation Loss: 0.462050519165251\n",
      "Train Loss: 0.544202296476523\n",
      "Validation Loss: 0.4620505175721071\n",
      "Train Loss: 0.544202296476503\n",
      "Validation Loss: 0.46205051568631644\n",
      "Train Loss: 0.5442022964764821\n",
      "Validation Loss: 0.4620505143420002\n",
      "Train Loss: 0.5442022964764622\n",
      "Validation Loss: 0.46205051245620965\n",
      "Train Loss: 0.5442022964764416\n",
      "Validation Loss: 0.46205051111189355\n",
      "Train Loss: 0.5442022964764219\n",
      "Validation Loss: 0.46205050951875026\n",
      "Train Loss: 0.5442022964764024\n",
      "Validation Loss: 0.46205050792560703\n",
      "Train Loss: 0.5442022964763829\n",
      "Validation Loss: 0.46205050662511093\n",
      "Train Loss: 0.5442022964763643\n",
      "Validation Loss: 0.4620505050757875\n",
      "Train Loss: 0.544202296476345\n",
      "Validation Loss: 0.4620505031899977\n",
      "Train Loss: 0.5442022964763258\n",
      "Validation Loss: 0.4620505015968548\n",
      "Train Loss: 0.5442022964763066\n",
      "Validation Loss: 0.46205050000371206\n",
      "Train Loss: 0.5442022964762885\n",
      "Validation Loss: 0.462050498454389\n",
      "Train Loss: 0.5442022964762704\n",
      "Validation Loss: 0.462050496905066\n",
      "Train Loss: 0.5442022964762516\n",
      "Validation Loss: 0.46205049560457057\n",
      "Train Loss: 0.544202296476233\n",
      "Validation Loss: 0.4620504943040751\n",
      "Train Loss: 0.5442022964762143\n",
      "Validation Loss: 0.4620504927109329\n",
      "Train Loss: 0.5442022964761958\n",
      "Validation Loss: 0.46205049141043775\n",
      "Train Loss: 0.5442022964761781\n",
      "Validation Loss: 0.46205048956846845\n",
      "Train Loss: 0.5442022964761605\n",
      "Validation Loss: 0.4620504880191459\n",
      "Train Loss: 0.5442022964761437\n",
      "Validation Loss: 0.46205048651364317\n",
      "Train Loss: 0.5442022964761271\n",
      "Validation Loss: 0.4620504847154936\n",
      "Train Loss: 0.5442022964761105\n",
      "Validation Loss: 0.4620504832099908\n",
      "Train Loss: 0.5442022964760941\n",
      "Validation Loss: 0.46205048170448815\n",
      "Train Loss: 0.5442022964760778\n",
      "Validation Loss: 0.4620504801989857\n",
      "Train Loss: 0.5442022964760607\n",
      "Validation Loss: 0.4620504789423108\n",
      "Train Loss: 0.5442022964760452\n",
      "Validation Loss: 0.4620504771879811\n",
      "Train Loss: 0.544202296476029\n",
      "Validation Loss: 0.46205047568247887\n",
      "Train Loss: 0.544202296476013\n",
      "Validation Loss: 0.4620504741769767\n",
      "Train Loss: 0.5442022964759978\n",
      "Validation Loss: 0.46205047271529404\n",
      "Train Loss: 0.544202296475982\n",
      "Validation Loss: 0.4620504715024391\n",
      "Train Loss: 0.5442022964759661\n",
      "Validation Loss: 0.46205046999693705\n",
      "Train Loss: 0.5442022964759511\n",
      "Validation Loss: 0.4620504685352547\n",
      "Train Loss: 0.5442022964759362\n",
      "Validation Loss: 0.46205046707357234\n",
      "Train Loss: 0.5442022964759213\n",
      "Validation Loss: 0.46205046561189034\n",
      "Train Loss: 0.5442022964759066\n",
      "Validation Loss: 0.462050464150208\n",
      "Train Loss: 0.5442022964758919\n",
      "Validation Loss: 0.462050462688526\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964758773\n",
      "Validation Loss: 0.462050461519491\n",
      "Train Loss: 0.5442022964758635\n",
      "Validation Loss: 0.46205046010162854\n",
      "Train Loss: 0.544202296475849\n",
      "Validation Loss: 0.46205045893259333\n",
      "Train Loss: 0.5442022964758352\n",
      "Validation Loss: 0.46205045722208427\n",
      "Train Loss: 0.5442022964758224\n",
      "Validation Loss: 0.46205045584804133\n",
      "Train Loss: 0.5442022964758081\n",
      "Validation Loss: 0.4620504546790067\n",
      "Train Loss: 0.5442022964757945\n",
      "Validation Loss: 0.4620504532611445\n",
      "Train Loss: 0.5442022964757818\n",
      "Validation Loss: 0.4620504518871018\n",
      "Train Loss: 0.5442022964757691\n",
      "Validation Loss: 0.4620504505130593\n",
      "Train Loss: 0.5442022964757558\n",
      "Validation Loss: 0.4620504490951974\n",
      "Train Loss: 0.5442022964757433\n",
      "Validation Loss: 0.46205044772115494\n",
      "Train Loss: 0.54420229647573\n",
      "Validation Loss: 0.4620504463032932\n",
      "Train Loss: 0.544202296475717\n",
      "Validation Loss: 0.46205044517807825\n",
      "Train Loss: 0.544202296475704\n",
      "Validation Loss: 0.46205044405286344\n",
      "Train Loss: 0.5442022964756916\n",
      "Validation Loss: 0.46205044267882117\n",
      "Train Loss: 0.5442022964756793\n",
      "Validation Loss: 0.46205044130477907\n",
      "Train Loss: 0.544202296475668\n",
      "Validation Loss: 0.46205043997455636\n",
      "Train Loss: 0.5442022964756552\n",
      "Validation Loss: 0.4620504391419886\n",
      "Train Loss: 0.5442022964756424\n",
      "Validation Loss: 0.4620504380167742\n",
      "Train Loss: 0.544202296475631\n",
      "Validation Loss: 0.46205043668655177\n",
      "Train Loss: 0.5442022964756197\n",
      "Validation Loss: 0.4620504350636824\n",
      "Train Loss: 0.5442022964756085\n",
      "Validation Loss: 0.46205043373346005\n",
      "Train Loss: 0.5442022964755973\n",
      "Validation Loss: 0.46205043240323757\n",
      "Train Loss: 0.5442022964755862\n",
      "Validation Loss: 0.46205043107301547\n",
      "Train Loss: 0.5442022964755744\n",
      "Validation Loss: 0.46205042999162066\n",
      "Train Loss: 0.5442022964755634\n",
      "Validation Loss: 0.4620504286613985\n",
      "Train Loss: 0.5442022964755517\n",
      "Validation Loss: 0.4620504272873569\n",
      "Train Loss: 0.5442022964755409\n",
      "Validation Loss: 0.462050425957135\n",
      "Train Loss: 0.5442022964755301\n",
      "Validation Loss: 0.46205042521220646\n",
      "Train Loss: 0.5442022964755187\n",
      "Validation Loss: 0.4620504244234589\n",
      "Train Loss: 0.5442022964755079\n",
      "Validation Loss: 0.46205042309323696\n",
      "Train Loss: 0.5442022964754972\n",
      "Validation Loss: 0.4620504220556619\n",
      "Train Loss: 0.5442022964754866\n",
      "Validation Loss: 0.46205042072544017\n",
      "Train Loss: 0.544202296475476\n",
      "Validation Loss: 0.4620504193952184\n",
      "Train Loss: 0.5442022964754648\n",
      "Validation Loss: 0.4620504183138243\n",
      "Train Loss: 0.5442022964754544\n",
      "Validation Loss: 0.4620504169836026\n",
      "Train Loss: 0.5442022964754439\n",
      "Validation Loss: 0.4620504162386748\n",
      "Train Loss: 0.5442022964754342\n",
      "Validation Loss: 0.46205041495227256\n",
      "Train Loss: 0.5442022964754237\n",
      "Validation Loss: 0.46205041362205107\n",
      "Train Loss: 0.5442022964754141\n",
      "Validation Loss: 0.46205041233564903\n",
      "Train Loss: 0.5442022964754044\n",
      "Validation Loss: 0.46205041134189373\n",
      "Train Loss: 0.5442022964753954\n",
      "Validation Loss: 0.462050410099311\n",
      "Train Loss: 0.5442022964753865\n",
      "Validation Loss: 0.46205040885672843\n",
      "Train Loss: 0.544202296475377\n",
      "Validation Loss: 0.4620504078629733\n",
      "Train Loss: 0.5442022964753677\n",
      "Validation Loss: 0.4620504068692182\n",
      "Train Loss: 0.5442022964753577\n",
      "Validation Loss: 0.46205040612429066\n",
      "Train Loss: 0.5442022964753482\n",
      "Validation Loss: 0.462050404837889\n",
      "Train Loss: 0.5442022964753389\n",
      "Validation Loss: 0.4620504035514873\n",
      "Train Loss: 0.5442022964753302\n",
      "Validation Loss: 0.4620504026015516\n",
      "Train Loss: 0.5442022964753216\n",
      "Validation Loss: 0.4620504013589694\n",
      "Train Loss: 0.544202296475313\n",
      "Validation Loss: 0.46205040040903383\n",
      "Train Loss: 0.5442022964753038\n",
      "Validation Loss: 0.46205039941527914\n",
      "Train Loss: 0.5442022964752954\n",
      "Validation Loss: 0.46205039817269694\n",
      "Train Loss: 0.544202296475287\n",
      "Validation Loss: 0.4620503972227615\n",
      "Train Loss: 0.5442022964752784\n",
      "Validation Loss: 0.4620503962728261\n",
      "Train Loss: 0.5442022964752701\n",
      "Validation Loss: 0.462050395030244\n",
      "Train Loss: 0.5442022964752616\n",
      "Validation Loss: 0.46205039408030885\n",
      "Train Loss: 0.544202296475254\n",
      "Validation Loss: 0.4620503928815461\n",
      "Train Loss: 0.5442022964752451\n",
      "Validation Loss: 0.4620503918877916\n",
      "Train Loss: 0.5442022964752369\n",
      "Validation Loss: 0.46205039093785666\n",
      "Train Loss: 0.5442022964752287\n",
      "Validation Loss: 0.4620503896952748\n",
      "Train Loss: 0.5442022964752204\n",
      "Validation Loss: 0.46205038874533977\n",
      "Train Loss: 0.5442022964752129\n",
      "Validation Loss: 0.4620503875465772\n",
      "Train Loss: 0.5442022964752053\n",
      "Validation Loss: 0.46205038664046144\n",
      "Train Loss: 0.5442022964751984\n",
      "Validation Loss: 0.4620503857781649\n",
      "Train Loss: 0.5442022964751908\n",
      "Validation Loss: 0.4620503845794024\n",
      "Train Loss: 0.544202296475184\n",
      "Validation Loss: 0.4620503831318126\n",
      "Train Loss: 0.5442022964751762\n",
      "Validation Loss: 0.4620503824745247\n",
      "Train Loss: 0.5442022964751687\n",
      "Validation Loss: 0.46205038156840916\n",
      "Train Loss: 0.5442022964751614\n",
      "Validation Loss: 0.46205038066229354\n",
      "Train Loss: 0.5442022964751542\n",
      "Validation Loss: 0.4620503797561781\n",
      "Train Loss: 0.544202296475147\n",
      "Validation Loss: 0.46205037885006267\n",
      "Train Loss: 0.5442022964751392\n",
      "Validation Loss: 0.462050377900128\n",
      "Train Loss: 0.544202296475132\n",
      "Validation Loss: 0.46205037699401275\n",
      "Train Loss: 0.5442022964751253\n",
      "Validation Loss: 0.4620503761317166\n",
      "Train Loss: 0.5442022964751188\n",
      "Validation Loss: 0.46205037497677365\n",
      "Train Loss: 0.5442022964751116\n",
      "Validation Loss: 0.46205037407065846\n",
      "Train Loss: 0.5442022964751045\n",
      "Validation Loss: 0.46205037287189654\n",
      "Train Loss: 0.544202296475098\n",
      "Validation Loss: 0.46205037171695384\n",
      "Train Loss: 0.5442022964750917\n",
      "Validation Loss: 0.46205037056201104\n",
      "Train Loss: 0.5442022964750851\n",
      "Validation Loss: 0.462050369992362\n",
      "Train Loss: 0.5442022964750787\n",
      "Validation Loss: 0.4620503688374193\n",
      "Train Loss: 0.5442022964750723\n",
      "Validation Loss: 0.46205036768247676\n",
      "Train Loss: 0.5442022964750655\n",
      "Validation Loss: 0.4620503667763617\n",
      "Train Loss: 0.5442022964750591\n",
      "Validation Loss: 0.46205036591406573\n",
      "Train Loss: 0.5442022964750529\n",
      "Validation Loss: 0.46205036534441685\n",
      "Train Loss: 0.5442022964750467\n",
      "Validation Loss: 0.46205036448212106\n",
      "Train Loss: 0.5442022964750405\n",
      "Validation Loss: 0.4620503639124722\n",
      "Train Loss: 0.5442022964750338\n",
      "Validation Loss: 0.46205036329900395\n",
      "Train Loss: 0.5442022964750277\n",
      "Validation Loss: 0.46205036243670833\n",
      "Train Loss: 0.5442022964750216\n",
      "Validation Loss: 0.46205036186705956\n",
      "Train Loss: 0.5442022964750155\n",
      "Validation Loss: 0.4620503610047639\n",
      "Train Loss: 0.5442022964750094\n",
      "Validation Loss: 0.46205036014246825\n",
      "Train Loss: 0.5442022964750038\n",
      "Validation Loss: 0.462050359323992\n",
      "Train Loss: 0.5442022964749977\n",
      "Validation Loss: 0.4620503581690498\n",
      "Train Loss: 0.5442022964749922\n",
      "Validation Loss: 0.46205035735057354\n",
      "Train Loss: 0.5442022964749866\n",
      "Validation Loss: 0.46205035623945045\n",
      "Train Loss: 0.5442022964749812\n",
      "Validation Loss: 0.4620503551283277\n",
      "Train Loss: 0.5442022964749758\n",
      "Validation Loss: 0.4620503543098514\n",
      "Train Loss: 0.5442022964749702\n",
      "Validation Loss: 0.46205035349137513\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964749653\n",
      "Validation Loss: 0.46205035242407144\n",
      "Train Loss: 0.54420229647496\n",
      "Validation Loss: 0.46205035160559516\n",
      "Train Loss: 0.5442022964749547\n",
      "Validation Loss: 0.4620503507871192\n",
      "Train Loss: 0.5442022964749489\n",
      "Validation Loss: 0.46205034992482397\n",
      "Train Loss: 0.5442022964749436\n",
      "Validation Loss: 0.462050349106348\n",
      "Train Loss: 0.5442022964749382\n",
      "Validation Loss: 0.46205034828787184\n",
      "Train Loss: 0.5442022964749331\n",
      "Validation Loss: 0.4620503471767492\n",
      "Train Loss: 0.5442022964749275\n",
      "Validation Loss: 0.4620503466071009\n",
      "Train Loss: 0.5442022964749222\n",
      "Validation Loss: 0.46205034578862486\n",
      "Train Loss: 0.5442022964749171\n",
      "Validation Loss: 0.4620503449701489\n",
      "Train Loss: 0.544202296474912\n",
      "Validation Loss: 0.4620503444443198\n",
      "Train Loss: 0.5442022964749074\n",
      "Validation Loss: 0.4620503436696631\n",
      "Train Loss: 0.5442022964749023\n",
      "Validation Loss: 0.4620503428511871\n",
      "Train Loss: 0.5442022964748972\n",
      "Validation Loss: 0.4620503417400648\n",
      "Train Loss: 0.5442022964748925\n",
      "Validation Loss: 0.46205034096540815\n",
      "Train Loss: 0.5442022964748879\n",
      "Validation Loss: 0.4620503398981046\n",
      "Train Loss: 0.5442022964748834\n",
      "Validation Loss: 0.4620503394160948\n",
      "Train Loss: 0.5442022964748788\n",
      "Validation Loss: 0.46205033864143813\n",
      "Train Loss: 0.5442022964748743\n",
      "Validation Loss: 0.46205033786678157\n",
      "Train Loss: 0.5442022964748698\n",
      "Validation Loss: 0.46205033709212495\n",
      "Train Loss: 0.5442022964748653\n",
      "Validation Loss: 0.46205033631746845\n",
      "Train Loss: 0.5442022964748608\n",
      "Validation Loss: 0.46205033525016537\n",
      "Train Loss: 0.5442022964748564\n",
      "Validation Loss: 0.46205033447550875\n",
      "Train Loss: 0.544202296474852\n",
      "Validation Loss: 0.4620503337008523\n",
      "Train Loss: 0.5442022964748475\n",
      "Validation Loss: 0.46205033292619585\n",
      "Train Loss: 0.5442022964748435\n",
      "Validation Loss: 0.46205033190271194\n",
      "Train Loss: 0.5442022964748392\n",
      "Validation Loss: 0.4620503311280555\n",
      "Train Loss: 0.5442022964748353\n",
      "Validation Loss: 0.4620503303972182\n",
      "Train Loss: 0.544202296474831\n",
      "Validation Loss: 0.4620503299152084\n",
      "Train Loss: 0.5442022964748271\n",
      "Validation Loss: 0.4620503291843712\n",
      "Train Loss: 0.5442022964748229\n",
      "Validation Loss: 0.46205032840971483\n",
      "Train Loss: 0.5442022964748187\n",
      "Validation Loss: 0.46205032792770534\n",
      "Train Loss: 0.5442022964748144\n",
      "Validation Loss: 0.4620503274456957\n",
      "Train Loss: 0.5442022964748102\n",
      "Validation Loss: 0.4620503266710394\n",
      "Train Loss: 0.5442022964748064\n",
      "Validation Loss: 0.4620503256475556\n",
      "Train Loss: 0.5442022964748027\n",
      "Validation Loss: 0.4620503252093652\n",
      "Train Loss: 0.5442022964747989\n",
      "Validation Loss: 0.4620503247711747\n",
      "Train Loss: 0.5442022964747951\n",
      "Validation Loss: 0.4620503240403376\n",
      "Train Loss: 0.5442022964747915\n",
      "Validation Loss: 0.46205032330950047\n",
      "Train Loss: 0.5442022964747877\n",
      "Validation Loss: 0.46205032228601683\n",
      "Train Loss: 0.544202296474784\n",
      "Validation Loss: 0.4620503218478263\n",
      "Train Loss: 0.5442022964747804\n",
      "Validation Loss: 0.46205032082434266\n",
      "Train Loss: 0.5442022964747767\n",
      "Validation Loss: 0.4620503200935057\n",
      "Train Loss: 0.544202296474773\n",
      "Validation Loss: 0.4620503193626686\n",
      "Train Loss: 0.5442022964747694\n",
      "Validation Loss: 0.46205031863183166\n",
      "Train Loss: 0.5442022964747658\n",
      "Validation Loss: 0.46205031790099477\n",
      "Train Loss: 0.5442022964747626\n",
      "Validation Loss: 0.46205031750662356\n",
      "Train Loss: 0.544202296474759\n",
      "Validation Loss: 0.4620503167757866\n",
      "Train Loss: 0.5442022964747558\n",
      "Validation Loss: 0.46205031608876873\n",
      "Train Loss: 0.5442022964747523\n",
      "Validation Loss: 0.4620503153579319\n",
      "Train Loss: 0.544202296474749\n",
      "Validation Loss: 0.462050314670914\n",
      "Train Loss: 0.5442022964747458\n",
      "Validation Loss: 0.4620503136912496\n",
      "Train Loss: 0.5442022964747427\n",
      "Validation Loss: 0.4620503127115852\n",
      "Train Loss: 0.5442022964747397\n",
      "Validation Loss: 0.4620503120245675\n",
      "Train Loss: 0.5442022964747362\n",
      "Validation Loss: 0.4620503115863773\n",
      "Train Loss: 0.5442022964747332\n",
      "Validation Loss: 0.4620503108993596\n",
      "Train Loss: 0.5442022964747297\n",
      "Validation Loss: 0.46205031075381603\n",
      "Train Loss: 0.5442022964747267\n",
      "Validation Loss: 0.4620503100667982\n",
      "Train Loss: 0.5442022964747233\n",
      "Validation Loss: 0.4620503093359616\n",
      "Train Loss: 0.5442022964747203\n",
      "Validation Loss: 0.4620503086489439\n",
      "Train Loss: 0.5442022964747173\n",
      "Validation Loss: 0.4620503079619263\n",
      "Train Loss: 0.5442022964747142\n",
      "Validation Loss: 0.4620503072749085\n",
      "Train Loss: 0.5442022964747116\n",
      "Validation Loss: 0.46205030663171\n",
      "Train Loss: 0.5442022964747086\n",
      "Validation Loss: 0.4620503062373389\n",
      "Train Loss: 0.5442022964747057\n",
      "Validation Loss: 0.4620503055503214\n",
      "Train Loss: 0.5442022964747028\n",
      "Validation Loss: 0.46205030515595036\n",
      "Train Loss: 0.5442022964746999\n",
      "Validation Loss: 0.46205030446893275\n",
      "Train Loss: 0.5442022964746969\n",
      "Validation Loss: 0.4620503037819153\n",
      "Train Loss: 0.5442022964746944\n",
      "Validation Loss: 0.4620503031387167\n",
      "Train Loss: 0.5442022964746915\n",
      "Validation Loss: 0.4620503027443458\n",
      "Train Loss: 0.5442022964746884\n",
      "Validation Loss: 0.46205030230615585\n",
      "Train Loss: 0.5442022964746852\n",
      "Validation Loss: 0.4620503018679661\n",
      "Train Loss: 0.5442022964746827\n",
      "Validation Loss: 0.46205030122476765\n",
      "Train Loss: 0.5442022964746801\n",
      "Validation Loss: 0.4620503005815691\n",
      "Train Loss: 0.5442022964746775\n",
      "Validation Loss: 0.4620502996457241\n",
      "Train Loss: 0.5442022964746751\n",
      "Validation Loss: 0.4620502990025257\n",
      "Train Loss: 0.5442022964746726\n",
      "Validation Loss: 0.4620502983593272\n",
      "Train Loss: 0.5442022964746701\n",
      "Validation Loss: 0.4620502977161287\n",
      "Train Loss: 0.5442022964746677\n",
      "Validation Loss: 0.46205029707293027\n",
      "Train Loss: 0.5442022964746652\n",
      "Validation Loss: 0.46205029642973194\n",
      "Train Loss: 0.5442022964746628\n",
      "Validation Loss: 0.4620502957865335\n",
      "Train Loss: 0.5442022964746603\n",
      "Validation Loss: 0.46205029514333523\n",
      "Train Loss: 0.544202296474658\n",
      "Validation Loss: 0.46205029450013685\n",
      "Train Loss: 0.5442022964746557\n",
      "Validation Loss: 0.46205029414958504\n",
      "Train Loss: 0.5442022964746531\n",
      "Validation Loss: 0.46205029379903345\n",
      "Train Loss: 0.5442022964746511\n",
      "Validation Loss: 0.46205029290700733\n",
      "Train Loss: 0.5442022964746485\n",
      "Validation Loss: 0.46205029221999017\n",
      "Train Loss: 0.5442022964746461\n",
      "Validation Loss: 0.4620502918694384\n",
      "Train Loss: 0.5442022964746438\n",
      "Validation Loss: 0.4620502912262402\n",
      "Train Loss: 0.5442022964746415\n",
      "Validation Loss: 0.46205029087568855\n",
      "Train Loss: 0.5442022964746395\n",
      "Validation Loss: 0.4620502902763092\n",
      "Train Loss: 0.5442022964746371\n",
      "Validation Loss: 0.46205028963311096\n",
      "Train Loss: 0.5442022964746351\n",
      "Validation Loss: 0.4620502890337317\n",
      "Train Loss: 0.5442022964746328\n",
      "Validation Loss: 0.46205028868318004\n",
      "Train Loss: 0.5442022964746309\n",
      "Validation Loss: 0.4620502880838008\n",
      "Train Loss: 0.5442022964746284\n",
      "Validation Loss: 0.46205028768943024\n",
      "Train Loss: 0.544202296474626\n",
      "Validation Loss: 0.4620502873388786\n",
      "Train Loss: 0.5442022964746241\n",
      "Validation Loss: 0.46205028673949944\n",
      "Train Loss: 0.5442022964746221\n",
      "Validation Loss: 0.4620502861401202\n",
      "Train Loss: 0.5442022964746203\n",
      "Validation Loss: 0.46205028554074096\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964746182\n",
      "Validation Loss: 0.4620502848975428\n",
      "Train Loss: 0.5442022964746159\n",
      "Validation Loss: 0.46205028454699143\n",
      "Train Loss: 0.5442022964746134\n",
      "Validation Loss: 0.46205028415262084\n",
      "Train Loss: 0.5442022964746115\n",
      "Validation Loss: 0.4620502835532416\n",
      "Train Loss: 0.5442022964746096\n",
      "Validation Loss: 0.4620502829538626\n",
      "Train Loss: 0.5442022964746077\n",
      "Validation Loss: 0.4620502823544833\n",
      "Train Loss: 0.5442022964746059\n",
      "Validation Loss: 0.4620502817551043\n",
      "Train Loss: 0.5442022964746037\n",
      "Validation Loss: 0.46205028140455273\n",
      "Train Loss: 0.5442022964746019\n",
      "Validation Loss: 0.4620502808051738\n",
      "Train Loss: 0.5442022964746001\n",
      "Validation Loss: 0.4620502804984411\n",
      "Train Loss: 0.5442022964745983\n",
      "Validation Loss: 0.46205028019170863\n",
      "Train Loss: 0.5442022964745964\n",
      "Validation Loss: 0.4620502798849762\n",
      "Train Loss: 0.544202296474595\n",
      "Validation Loss: 0.46205027932941606\n",
      "Train Loss: 0.5442022964745928\n",
      "Validation Loss: 0.4620502789788646\n",
      "Train Loss: 0.5442022964745911\n",
      "Validation Loss: 0.4620502783794856\n",
      "Train Loss: 0.5442022964745891\n",
      "Validation Loss: 0.4620502780289342\n",
      "Train Loss: 0.5442022964745872\n",
      "Validation Loss: 0.46205027772220175\n",
      "Train Loss: 0.5442022964745857\n",
      "Validation Loss: 0.4620502771666417\n",
      "Train Loss: 0.544202296474584\n",
      "Validation Loss: 0.46205027685990924\n",
      "Train Loss: 0.5442022964745821\n",
      "Validation Loss: 0.46205027626053025\n",
      "Train Loss: 0.5442022964745807\n",
      "Validation Loss: 0.4620502754123236\n",
      "Train Loss: 0.5442022964745786\n",
      "Validation Loss: 0.4620502750617723\n",
      "Train Loss: 0.5442022964745772\n",
      "Validation Loss: 0.4620502745062123\n",
      "Train Loss: 0.5442022964745755\n",
      "Validation Loss: 0.46205027390683334\n",
      "Train Loss: 0.5442022964745737\n",
      "Validation Loss: 0.4620502736001008\n",
      "Train Loss: 0.544202296474572\n",
      "Validation Loss: 0.462050273000722\n",
      "Train Loss: 0.5442022964745707\n",
      "Validation Loss: 0.4620502721963343\n",
      "Train Loss: 0.5442022964745693\n",
      "Validation Loss: 0.4620502716407742\n",
      "Train Loss: 0.5442022964745676\n",
      "Validation Loss: 0.4620502710413953\n",
      "Train Loss: 0.5442022964745662\n",
      "Validation Loss: 0.4620502707784819\n",
      "Train Loss: 0.5442022964745649\n",
      "Validation Loss: 0.46205027022292194\n",
      "Train Loss: 0.5442022964745631\n",
      "Validation Loss: 0.4620502699161896\n",
      "Train Loss: 0.544202296474562\n",
      "Validation Loss: 0.46205026940444854\n",
      "Train Loss: 0.5442022964745606\n",
      "Validation Loss: 0.46205026884888845\n",
      "Train Loss: 0.5442022964745589\n",
      "Validation Loss: 0.4620502685421562\n",
      "Train Loss: 0.5442022964745578\n",
      "Validation Loss: 0.46205026803041516\n",
      "Train Loss: 0.5442022964745564\n",
      "Validation Loss: 0.4620502677675017\n",
      "Train Loss: 0.5442022964745548\n",
      "Validation Loss: 0.4620502674607696\n",
      "Train Loss: 0.5442022964745534\n",
      "Validation Loss: 0.4620502669052096\n",
      "Train Loss: 0.5442022964745518\n",
      "Validation Loss: 0.46205026630583074\n",
      "Train Loss: 0.5442022964745507\n",
      "Validation Loss: 0.46205026579408975\n",
      "Train Loss: 0.5442022964745493\n",
      "Validation Loss: 0.4620502652385299\n",
      "Train Loss: 0.544202296474548\n",
      "Validation Loss: 0.46205026468296995\n",
      "Train Loss: 0.5442022964745467\n",
      "Validation Loss: 0.4620502644200566\n",
      "Train Loss: 0.5442022964745453\n",
      "Validation Loss: 0.46205026415714334\n",
      "Train Loss: 0.5442022964745441\n",
      "Validation Loss: 0.4620502638942299\n",
      "Train Loss: 0.5442022964745424\n",
      "Validation Loss: 0.4620502635874978\n",
      "Train Loss: 0.5442022964745413\n",
      "Validation Loss: 0.46205026336840327\n",
      "Train Loss: 0.5442022964745402\n",
      "Validation Loss: 0.4620502628566623\n",
      "Train Loss: 0.5442022964745392\n",
      "Validation Loss: 0.4620502626375679\n",
      "Train Loss: 0.5442022964745379\n",
      "Validation Loss: 0.4620502623746545\n",
      "Train Loss: 0.5442022964745367\n",
      "Validation Loss: 0.46205026181909487\n",
      "Train Loss: 0.5442022964745353\n",
      "Validation Loss: 0.46205026155618145\n",
      "Train Loss: 0.5442022964745342\n",
      "Validation Loss: 0.46205026133708704\n",
      "Train Loss: 0.5442022964745331\n",
      "Validation Loss: 0.46205026053269954\n",
      "Train Loss: 0.5442022964745321\n",
      "Validation Loss: 0.46205026002095867\n",
      "Train Loss: 0.5442022964745309\n",
      "Validation Loss: 0.4620502597580454\n",
      "Train Loss: 0.5442022964745297\n",
      "Validation Loss: 0.4620502594951321\n",
      "Train Loss: 0.5442022964745284\n",
      "Validation Loss: 0.4620502592322189\n",
      "Train Loss: 0.5442022964745271\n",
      "Validation Loss: 0.4620502589693057\n",
      "Train Loss: 0.544202296474526\n",
      "Validation Loss: 0.4620502584575647\n",
      "Train Loss: 0.5442022964745252\n",
      "Validation Loss: 0.4620502576969962\n",
      "Train Loss: 0.5442022964745243\n",
      "Validation Loss: 0.4620502571852554\n",
      "Train Loss: 0.544202296474523\n",
      "Validation Loss: 0.4620502569223421\n",
      "Train Loss: 0.544202296474522\n",
      "Validation Loss: 0.46205025670324773\n",
      "Train Loss: 0.5442022964745209\n",
      "Validation Loss: 0.4620502561476881\n",
      "Train Loss: 0.5442022964745197\n",
      "Validation Loss: 0.4620502558847748\n",
      "Train Loss: 0.5442022964745183\n",
      "Validation Loss: 0.4620502556218616\n",
      "Train Loss: 0.5442022964745177\n",
      "Validation Loss: 0.46205025515393966\n",
      "Train Loss: 0.5442022964745166\n",
      "Validation Loss: 0.4620502548910265\n",
      "Train Loss: 0.5442022964745153\n",
      "Validation Loss: 0.46205025492075974\n",
      "Train Loss: 0.5442022964745141\n",
      "Validation Loss: 0.46205025465784655\n",
      "Train Loss: 0.5442022964745131\n",
      "Validation Loss: 0.46205025414610584\n",
      "Train Loss: 0.5442022964745123\n",
      "Validation Loss: 0.46205025367818375\n",
      "Train Loss: 0.5442022964745115\n",
      "Validation Loss: 0.46205025316644305\n",
      "Train Loss: 0.5442022964745105\n",
      "Validation Loss: 0.46205025294734875\n",
      "Train Loss: 0.5442022964745096\n",
      "Validation Loss: 0.46205025272825434\n",
      "Train Loss: 0.5442022964745086\n",
      "Validation Loss: 0.4620502522165136\n",
      "Train Loss: 0.5442022964745076\n",
      "Validation Loss: 0.4620502519974194\n",
      "Train Loss: 0.5442022964745067\n",
      "Validation Loss: 0.4620502514856785\n",
      "Train Loss: 0.5442022964745057\n",
      "Validation Loss: 0.46205025097393776\n",
      "Train Loss: 0.544202296474505\n",
      "Validation Loss: 0.46205025050601595\n",
      "Train Loss: 0.5442022964745041\n",
      "Validation Loss: 0.46205025028692154\n",
      "Train Loss: 0.544202296474503\n",
      "Validation Loss: 0.46205025002400835\n",
      "Train Loss: 0.5442022964745019\n",
      "Validation Loss: 0.4620502497610954\n",
      "Train Loss: 0.5442022964745009\n",
      "Validation Loss: 0.4620502495420012\n",
      "Train Loss: 0.5442022964745002\n",
      "Validation Loss: 0.46205024907407916\n",
      "Train Loss: 0.5442022964744994\n",
      "Validation Loss: 0.46205024856233845\n",
      "Train Loss: 0.5442022964744985\n",
      "Validation Loss: 0.46205024834324426\n",
      "Train Loss: 0.5442022964744975\n",
      "Validation Loss: 0.46205024812414996\n",
      "Train Loss: 0.5442022964744968\n",
      "Validation Loss: 0.46205024765622804\n",
      "Train Loss: 0.5442022964744959\n",
      "Validation Loss: 0.4620502471444874\n",
      "Train Loss: 0.5442022964744953\n",
      "Validation Loss: 0.462050246969212\n",
      "Train Loss: 0.5442022964744945\n",
      "Validation Loss: 0.4620502467939367\n",
      "Train Loss: 0.5442022964744938\n",
      "Validation Loss: 0.46205024632601477\n",
      "Train Loss: 0.5442022964744931\n",
      "Validation Loss: 0.4620502461507393\n",
      "Train Loss: 0.5442022964744923\n",
      "Validation Loss: 0.46205024563899866\n",
      "Train Loss: 0.5442022964744916\n",
      "Validation Loss: 0.46205024546372336\n",
      "Train Loss: 0.5442022964744907\n",
      "Validation Loss: 0.4620502452446292\n",
      "Train Loss: 0.54420229647449\n",
      "Validation Loss: 0.4620502447767073\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744893\n",
      "Validation Loss: 0.4620502446014318\n",
      "Train Loss: 0.5442022964744888\n",
      "Validation Loss: 0.46205024388468235\n",
      "Train Loss: 0.5442022964744881\n",
      "Validation Loss: 0.4620502434167606\n",
      "Train Loss: 0.5442022964744875\n",
      "Validation Loss: 0.46205024324148525\n",
      "Train Loss: 0.5442022964744868\n",
      "Validation Loss: 0.46205024306620984\n",
      "Train Loss: 0.5442022964744859\n",
      "Validation Loss: 0.46205024284711566\n",
      "Train Loss: 0.5442022964744853\n",
      "Validation Loss: 0.4620502423791938\n",
      "Train Loss: 0.5442022964744847\n",
      "Validation Loss: 0.46205024191127203\n",
      "Train Loss: 0.544202296474484\n",
      "Validation Loss: 0.4620502417359967\n",
      "Train Loss: 0.5442022964744831\n",
      "Validation Loss: 0.4620502415169025\n",
      "Train Loss: 0.5442022964744825\n",
      "Validation Loss: 0.4620502413416272\n",
      "Train Loss: 0.544202296474482\n",
      "Validation Loss: 0.4620502409175243\n",
      "Train Loss: 0.5442022964744814\n",
      "Validation Loss: 0.46205024074224893\n",
      "Train Loss: 0.5442022964744808\n",
      "Validation Loss: 0.46205024056697364\n",
      "Train Loss: 0.5442022964744799\n",
      "Validation Loss: 0.4620502403478795\n",
      "Train Loss: 0.5442022964744793\n",
      "Validation Loss: 0.46205024017260427\n",
      "Train Loss: 0.5442022964744787\n",
      "Validation Loss: 0.46205023970468245\n",
      "Train Loss: 0.544202296474478\n",
      "Validation Loss: 0.46205023952940716\n",
      "Train Loss: 0.5442022964744774\n",
      "Validation Loss: 0.46205023935413186\n",
      "Train Loss: 0.5442022964744768\n",
      "Validation Loss: 0.46205023888621005\n",
      "Train Loss: 0.5442022964744763\n",
      "Validation Loss: 0.4620502384182884\n",
      "Train Loss: 0.5442022964744754\n",
      "Validation Loss: 0.46205023819919416\n",
      "Train Loss: 0.5442022964744748\n",
      "Validation Loss: 0.4620502377312723\n",
      "Train Loss: 0.544202296474474\n",
      "Validation Loss: 0.46205023751217833\n",
      "Train Loss: 0.5442022964744733\n",
      "Validation Loss: 0.46205023729308425\n",
      "Train Loss: 0.5442022964744727\n",
      "Validation Loss: 0.46205023711780885\n",
      "Train Loss: 0.5442022964744719\n",
      "Validation Loss: 0.4620502368987147\n",
      "Train Loss: 0.5442022964744712\n",
      "Validation Loss: 0.46205023667962064\n",
      "Train Loss: 0.5442022964744706\n",
      "Validation Loss: 0.46205023621169905\n",
      "Train Loss: 0.54420229647447\n",
      "Validation Loss: 0.4620502360364237\n",
      "Train Loss: 0.5442022964744692\n",
      "Validation Loss: 0.46205023581732974\n",
      "Train Loss: 0.5442022964744687\n",
      "Validation Loss: 0.4620502351005803\n",
      "Train Loss: 0.5442022964744684\n",
      "Validation Loss: 0.4620502346764774\n",
      "Train Loss: 0.5442022964744678\n",
      "Validation Loss: 0.4620502347938486\n",
      "Train Loss: 0.544202296474467\n",
      "Validation Loss: 0.4620502345747546\n",
      "Train Loss: 0.5442022964744665\n",
      "Validation Loss: 0.46205023410683277\n",
      "Train Loss: 0.5442022964744659\n",
      "Validation Loss: 0.4620502339315577\n",
      "Train Loss: 0.5442022964744655\n",
      "Validation Loss: 0.4620502338001012\n",
      "Train Loss: 0.5442022964744649\n",
      "Validation Loss: 0.46205023333217937\n",
      "Train Loss: 0.5442022964744644\n",
      "Validation Loss: 0.4620502331569042\n",
      "Train Loss: 0.544202296474464\n",
      "Validation Loss: 0.4620502330254478\n",
      "Train Loss: 0.5442022964744632\n",
      "Validation Loss: 0.4620502330990003\n",
      "Train Loss: 0.5442022964744628\n",
      "Validation Loss: 0.4620502323822508\n",
      "Train Loss: 0.5442022964744623\n",
      "Validation Loss: 0.4620502322069757\n",
      "Train Loss: 0.5442022964744616\n",
      "Validation Loss: 0.4620502320317005\n",
      "Train Loss: 0.5442022964744613\n",
      "Validation Loss: 0.46205023131495104\n",
      "Train Loss: 0.5442022964744607\n",
      "Validation Loss: 0.46205023113967586\n",
      "Train Loss: 0.5442022964744604\n",
      "Validation Loss: 0.4620502310082195\n",
      "Train Loss: 0.5442022964744597\n",
      "Validation Loss: 0.4620502308329443\n",
      "Train Loss: 0.5442022964744594\n",
      "Validation Loss: 0.46205023040884136\n",
      "Train Loss: 0.5442022964744588\n",
      "Validation Loss: 0.46205023023356623\n",
      "Train Loss: 0.5442022964744585\n",
      "Validation Loss: 0.4620502298094632\n",
      "Train Loss: 0.544202296474458\n",
      "Validation Loss: 0.4620502296341882\n",
      "Train Loss: 0.5442022964744574\n",
      "Validation Loss: 0.4620502294589129\n",
      "Train Loss: 0.544202296474457\n",
      "Validation Loss: 0.46205022903480997\n",
      "Train Loss: 0.5442022964744567\n",
      "Validation Loss: 0.46205022861070716\n",
      "Train Loss: 0.5442022964744561\n",
      "Validation Loss: 0.4620502287280783\n",
      "Train Loss: 0.5442022964744558\n",
      "Validation Loss: 0.46205022859662204\n",
      "Train Loss: 0.544202296474455\n",
      "Validation Loss: 0.4620502283775282\n",
      "Train Loss: 0.5442022964744548\n",
      "Validation Loss: 0.4620502277045976\n",
      "Train Loss: 0.5442022964744544\n",
      "Validation Loss: 0.4620502275731411\n",
      "Train Loss: 0.5442022964744541\n",
      "Validation Loss: 0.46205022714903826\n",
      "Train Loss: 0.5442022964744536\n",
      "Validation Loss: 0.46205022701758186\n",
      "Train Loss: 0.5442022964744533\n",
      "Validation Loss: 0.46205022659347916\n",
      "Train Loss: 0.544202296474453\n",
      "Validation Loss: 0.4620502264620227\n",
      "Train Loss: 0.5442022964744526\n",
      "Validation Loss: 0.4620502263305664\n",
      "Train Loss: 0.544202296474452\n",
      "Validation Loss: 0.46205022644793764\n",
      "Train Loss: 0.5442022964744518\n",
      "Validation Loss: 0.46205022606765356\n",
      "Train Loss: 0.5442022964744514\n",
      "Validation Loss: 0.46205022589237854\n",
      "Train Loss: 0.5442022964744508\n",
      "Validation Loss: 0.4620502260097498\n",
      "Train Loss: 0.5442022964744503\n",
      "Validation Loss: 0.46205022583447464\n",
      "Train Loss: 0.54420229647445\n",
      "Validation Loss: 0.46205022541037183\n",
      "Train Loss: 0.5442022964744495\n",
      "Validation Loss: 0.4620502252350967\n",
      "Train Loss: 0.5442022964744492\n",
      "Validation Loss: 0.4620502248109939\n",
      "Train Loss: 0.5442022964744487\n",
      "Validation Loss: 0.4620502246357187\n",
      "Train Loss: 0.5442022964744482\n",
      "Validation Loss: 0.4620502244604435\n",
      "Train Loss: 0.5442022964744478\n",
      "Validation Loss: 0.46205022432898724\n",
      "Train Loss: 0.5442022964744473\n",
      "Validation Loss: 0.4620502241537121\n",
      "Train Loss: 0.5442022964744471\n",
      "Validation Loss: 0.46205022377342797\n",
      "Train Loss: 0.544202296474447\n",
      "Validation Loss: 0.462050223393144\n",
      "Train Loss: 0.5442022964744464\n",
      "Validation Loss: 0.4620502232178688\n",
      "Train Loss: 0.5442022964744462\n",
      "Validation Loss: 0.46205022283758485\n",
      "Train Loss: 0.5442022964744458\n",
      "Validation Loss: 0.4620502227061285\n",
      "Train Loss: 0.5442022964744455\n",
      "Validation Loss: 0.46205022257467215\n",
      "Train Loss: 0.5442022964744452\n",
      "Validation Loss: 0.46205022244321586\n",
      "Train Loss: 0.5442022964744448\n",
      "Validation Loss: 0.4620502223117595\n",
      "Train Loss: 0.5442022964744445\n",
      "Validation Loss: 0.46205022218030317\n",
      "Train Loss: 0.5442022964744442\n",
      "Validation Loss: 0.46205022175620036\n",
      "Train Loss: 0.5442022964744441\n",
      "Validation Loss: 0.4620502216685629\n",
      "Train Loss: 0.5442022964744435\n",
      "Validation Loss: 0.4620502217859342\n",
      "Train Loss: 0.5442022964744432\n",
      "Validation Loss: 0.46205022165447784\n",
      "Train Loss: 0.5442022964744428\n",
      "Validation Loss: 0.4620502212303751\n",
      "Train Loss: 0.5442022964744425\n",
      "Validation Loss: 0.4620502210989188\n",
      "Train Loss: 0.5442022964744422\n",
      "Validation Loss: 0.46205022096746257\n",
      "Train Loss: 0.5442022964744418\n",
      "Validation Loss: 0.46205022083600605\n",
      "Train Loss: 0.5442022964744417\n",
      "Validation Loss: 0.46205022074836866\n",
      "Train Loss: 0.5442022964744414\n",
      "Validation Loss: 0.4620502206169123\n",
      "Train Loss: 0.5442022964744411\n",
      "Validation Loss: 0.46205022048545596\n",
      "Train Loss: 0.5442022964744406\n",
      "Validation Loss: 0.4620502203101809\n",
      "Train Loss: 0.5442022964744403\n",
      "Validation Loss: 0.46205022017872466\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.54420229647444\n",
      "Validation Loss: 0.46205021975462174\n",
      "Train Loss: 0.5442022964744396\n",
      "Validation Loss: 0.4620502196231655\n",
      "Train Loss: 0.5442022964744394\n",
      "Validation Loss: 0.4620502191990627\n",
      "Train Loss: 0.544202296474439\n",
      "Validation Loss: 0.46205021906760646\n",
      "Train Loss: 0.5442022964744389\n",
      "Validation Loss: 0.4620502186873224\n",
      "Train Loss: 0.5442022964744386\n",
      "Validation Loss: 0.46205021859968487\n",
      "Train Loss: 0.5442022964744383\n",
      "Validation Loss: 0.46205021846822864\n",
      "Train Loss: 0.5442022964744381\n",
      "Validation Loss: 0.4620502183367724\n",
      "Train Loss: 0.5442022964744376\n",
      "Validation Loss: 0.46205021816149716\n",
      "Train Loss: 0.5442022964744373\n",
      "Validation Loss: 0.462050218030041\n",
      "Train Loss: 0.544202296474437\n",
      "Validation Loss: 0.4620502178985848\n",
      "Train Loss: 0.5442022964744367\n",
      "Validation Loss: 0.4620502172256542\n",
      "Train Loss: 0.5442022964744366\n",
      "Validation Loss: 0.4620502168453701\n",
      "Train Loss: 0.5442022964744364\n",
      "Validation Loss: 0.4620502167139139\n",
      "Train Loss: 0.544202296474436\n",
      "Validation Loss: 0.46205021658245754\n",
      "Train Loss: 0.5442022964744359\n",
      "Validation Loss: 0.4620502162021736\n",
      "Train Loss: 0.5442022964744354\n",
      "Validation Loss: 0.4620502160268986\n",
      "Train Loss: 0.5442022964744351\n",
      "Validation Loss: 0.4620502158954423\n",
      "Train Loss: 0.544202296474435\n",
      "Validation Loss: 0.4620502155151584\n",
      "Train Loss: 0.5442022964744346\n",
      "Validation Loss: 0.46205021538370195\n",
      "Train Loss: 0.5442022964744345\n",
      "Validation Loss: 0.46205021529606444\n",
      "Train Loss: 0.5442022964744342\n",
      "Validation Loss: 0.46205021516460815\n",
      "Train Loss: 0.544202296474434\n",
      "Validation Loss: 0.4620502147405055\n",
      "Train Loss: 0.5442022964744336\n",
      "Validation Loss: 0.4620502149016957\n",
      "Train Loss: 0.5442022964744334\n",
      "Validation Loss: 0.46205021481405817\n",
      "Train Loss: 0.5442022964744333\n",
      "Validation Loss: 0.46205021443377414\n",
      "Train Loss: 0.544202296474433\n",
      "Validation Loss: 0.46205021400967144\n",
      "Train Loss: 0.5442022964744329\n",
      "Validation Loss: 0.46205021392203394\n",
      "Train Loss: 0.5442022964744324\n",
      "Validation Loss: 0.46205021379057765\n",
      "Train Loss: 0.5442022964744324\n",
      "Validation Loss: 0.46205021316146605\n",
      "Train Loss: 0.5442022964744323\n",
      "Validation Loss: 0.4620502130738285\n",
      "Train Loss: 0.544202296474432\n",
      "Validation Loss: 0.46205021294237225\n",
      "Train Loss: 0.5442022964744317\n",
      "Validation Loss: 0.4620502125182695\n",
      "Train Loss: 0.5442022964744315\n",
      "Validation Loss: 0.462050212430632\n",
      "Train Loss: 0.5442022964744313\n",
      "Validation Loss: 0.4620502123429944\n",
      "Train Loss: 0.5442022964744313\n",
      "Validation Loss: 0.46205021229917564\n",
      "Train Loss: 0.544202296474431\n",
      "Validation Loss: 0.46205021216771947\n",
      "Train Loss: 0.5442022964744309\n",
      "Validation Loss: 0.46205021208008207\n",
      "Train Loss: 0.5442022964744306\n",
      "Validation Loss: 0.4620502119924445\n",
      "Train Loss: 0.5442022964744305\n",
      "Validation Loss: 0.462050211904807\n",
      "Train Loss: 0.5442022964744302\n",
      "Validation Loss: 0.4620502117733507\n",
      "Train Loss: 0.5442022964744301\n",
      "Validation Loss: 0.46205021168571314\n",
      "Train Loss: 0.5442022964744299\n",
      "Validation Loss: 0.4620502115542569\n",
      "Train Loss: 0.5442022964744295\n",
      "Validation Loss: 0.4620502114228007\n",
      "Train Loss: 0.5442022964744294\n",
      "Validation Loss: 0.46205021133516316\n",
      "Train Loss: 0.5442022964744291\n",
      "Validation Loss: 0.462050211203707\n",
      "Train Loss: 0.5442022964744291\n",
      "Validation Loss: 0.4620502111598882\n",
      "Train Loss: 0.5442022964744287\n",
      "Validation Loss: 0.462050211028432\n",
      "Train Loss: 0.5442022964744286\n",
      "Validation Loss: 0.46205021098461324\n",
      "Train Loss: 0.5442022964744285\n",
      "Validation Loss: 0.4620502106043293\n",
      "Train Loss: 0.5442022964744283\n",
      "Validation Loss: 0.46205021051669193\n",
      "Train Loss: 0.5442022964744283\n",
      "Validation Loss: 0.4620502101802266\n",
      "Train Loss: 0.5442022964744282\n",
      "Validation Loss: 0.4620502100925891\n",
      "Train Loss: 0.5442022964744279\n",
      "Validation Loss: 0.4620502099611329\n",
      "Train Loss: 0.5442022964744277\n",
      "Validation Loss: 0.4620502098734954\n",
      "Train Loss: 0.5442022964744275\n",
      "Validation Loss: 0.462050209785858\n",
      "Train Loss: 0.5442022964744275\n",
      "Validation Loss: 0.4620502094493926\n",
      "Train Loss: 0.5442022964744272\n",
      "Validation Loss: 0.46205020931793644\n",
      "Train Loss: 0.5442022964744272\n",
      "Validation Loss: 0.4620502092741178\n",
      "Train Loss: 0.5442022964744269\n",
      "Validation Loss: 0.46205020914266154\n",
      "Train Loss: 0.5442022964744269\n",
      "Validation Loss: 0.46205020880619635\n",
      "Train Loss: 0.5442022964744267\n",
      "Validation Loss: 0.4620502087185588\n",
      "Train Loss: 0.5442022964744265\n",
      "Validation Loss: 0.4620502086309213\n",
      "Train Loss: 0.5442022964744264\n",
      "Validation Loss: 0.4620502085432839\n",
      "Train Loss: 0.5442022964744262\n",
      "Validation Loss: 0.4620502084556463\n",
      "Train Loss: 0.5442022964744261\n",
      "Validation Loss: 0.4620502083680089\n",
      "Train Loss: 0.544202296474426\n",
      "Validation Loss: 0.46205020828037136\n",
      "Train Loss: 0.5442022964744258\n",
      "Validation Loss: 0.4620502081927339\n",
      "Train Loss: 0.5442022964744256\n",
      "Validation Loss: 0.46205020814891523\n",
      "Train Loss: 0.5442022964744256\n",
      "Validation Loss: 0.46205020781245015\n",
      "Train Loss: 0.5442022964744255\n",
      "Validation Loss: 0.46205020772481253\n",
      "Train Loss: 0.5442022964744253\n",
      "Validation Loss: 0.4620502076371751\n",
      "Train Loss: 0.5442022964744252\n",
      "Validation Loss: 0.46205020754953763\n",
      "Train Loss: 0.5442022964744249\n",
      "Validation Loss: 0.4620502074180814\n",
      "Train Loss: 0.544202296474425\n",
      "Validation Loss: 0.4620502070816162\n",
      "Train Loss: 0.5442022964744246\n",
      "Validation Loss: 0.46205020724280643\n",
      "Train Loss: 0.5442022964744246\n",
      "Validation Loss: 0.46205020719898765\n",
      "Train Loss: 0.5442022964744244\n",
      "Validation Loss: 0.46205020711135025\n",
      "Train Loss: 0.5442022964744242\n",
      "Validation Loss: 0.46205020673106617\n",
      "Train Loss: 0.5442022964744242\n",
      "Validation Loss: 0.4620502063946011\n",
      "Train Loss: 0.5442022964744241\n",
      "Validation Loss: 0.46205020630696364\n",
      "Train Loss: 0.544202296474424\n",
      "Validation Loss: 0.46205020621932613\n",
      "Train Loss: 0.5442022964744239\n",
      "Validation Loss: 0.4620502061316886\n",
      "Train Loss: 0.5442022964744235\n",
      "Validation Loss: 0.46205020600023233\n",
      "Train Loss: 0.5442022964744234\n",
      "Validation Loss: 0.4620502059564137\n",
      "Train Loss: 0.5442022964744234\n",
      "Validation Loss: 0.46205020591259505\n",
      "Train Loss: 0.5442022964744233\n",
      "Validation Loss: 0.4620502058249574\n",
      "Train Loss: 0.5442022964744232\n",
      "Validation Loss: 0.4620502057373201\n",
      "Train Loss: 0.5442022964744231\n",
      "Validation Loss: 0.46205020564968263\n",
      "Train Loss: 0.5442022964744228\n",
      "Validation Loss: 0.46205020551822634\n",
      "Train Loss: 0.5442022964744228\n",
      "Validation Loss: 0.4620502054744077\n",
      "Train Loss: 0.5442022964744226\n",
      "Validation Loss: 0.4620502053867701\n",
      "Train Loss: 0.5442022964744224\n",
      "Validation Loss: 0.4620502052991327\n",
      "Train Loss: 0.5442022964744224\n",
      "Validation Loss: 0.46205020496266763\n",
      "Train Loss: 0.5442022964744223\n",
      "Validation Loss: 0.4620502049188488\n",
      "Train Loss: 0.5442022964744223\n",
      "Validation Loss: 0.4620502048750301\n",
      "Train Loss: 0.5442022964744222\n",
      "Validation Loss: 0.46205020478739267\n",
      "Train Loss: 0.544202296474422\n",
      "Validation Loss: 0.46205020465593655\n",
      "Train Loss: 0.5442022964744218\n",
      "Validation Loss: 0.462050204568299\n",
      "Train Loss: 0.5442022964744218\n",
      "Validation Loss: 0.46205020423183385\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744216\n",
      "Validation Loss: 0.46205020414419634\n",
      "Train Loss: 0.5442022964744215\n",
      "Validation Loss: 0.4620502040565589\n",
      "Train Loss: 0.5442022964744212\n",
      "Validation Loss: 0.4620502039251028\n",
      "Train Loss: 0.5442022964744212\n",
      "Validation Loss: 0.462050203295991\n",
      "Train Loss: 0.5442022964744212\n",
      "Validation Loss: 0.4620502032521724\n",
      "Train Loss: 0.5442022964744211\n",
      "Validation Loss: 0.4620502031645349\n",
      "Train Loss: 0.5442022964744209\n",
      "Validation Loss: 0.4620502033695439\n",
      "Train Loss: 0.5442022964744209\n",
      "Validation Loss: 0.4620502033257252\n",
      "Train Loss: 0.5442022964744206\n",
      "Validation Loss: 0.462050203194269\n",
      "Train Loss: 0.5442022964744205\n",
      "Validation Loss: 0.46205020281398507\n",
      "Train Loss: 0.5442022964744203\n",
      "Validation Loss: 0.46205020272634767\n",
      "Train Loss: 0.5442022964744203\n",
      "Validation Loss: 0.46205020238988254\n",
      "Train Loss: 0.5442022964744203\n",
      "Validation Loss: 0.46205020234606375\n",
      "Train Loss: 0.5442022964744202\n",
      "Validation Loss: 0.4620502022584264\n",
      "Train Loss: 0.54420229647442\n",
      "Validation Loss: 0.4620502021707889\n",
      "Train Loss: 0.5442022964744199\n",
      "Validation Loss: 0.4620502020831514\n",
      "Train Loss: 0.5442022964744199\n",
      "Validation Loss: 0.4620502017466862\n",
      "Train Loss: 0.5442022964744198\n",
      "Validation Loss: 0.46205020195169527\n",
      "Train Loss: 0.5442022964744195\n",
      "Validation Loss: 0.4620502018640578\n",
      "Train Loss: 0.5442022964744194\n",
      "Validation Loss: 0.4620502015275927\n",
      "Train Loss: 0.5442022964744194\n",
      "Validation Loss: 0.4620502011911275\n",
      "Train Loss: 0.5442022964744194\n",
      "Validation Loss: 0.4620502008546623\n",
      "Train Loss: 0.5442022964744194\n",
      "Validation Loss: 0.4620502008108435\n",
      "Train Loss: 0.5442022964744193\n",
      "Validation Loss: 0.46205020072320613\n",
      "Train Loss: 0.544202296474419\n",
      "Validation Loss: 0.4620502005917499\n",
      "Train Loss: 0.544202296474419\n",
      "Validation Loss: 0.4620502002552848\n",
      "Train Loss: 0.544202296474419\n",
      "Validation Loss: 0.46205020021146614\n",
      "Train Loss: 0.544202296474419\n",
      "Validation Loss: 0.46205020016764736\n",
      "Train Loss: 0.5442022964744188\n",
      "Validation Loss: 0.4620502003726563\n",
      "Train Loss: 0.5442022964744188\n",
      "Validation Loss: 0.4620502000361913\n",
      "Train Loss: 0.5442022964744186\n",
      "Validation Loss: 0.46205019994855384\n",
      "Train Loss: 0.5442022964744185\n",
      "Validation Loss: 0.462050199904735\n",
      "Train Loss: 0.5442022964744185\n",
      "Validation Loss: 0.4620501998609164\n",
      "Train Loss: 0.5442022964744184\n",
      "Validation Loss: 0.4620501998170976\n",
      "Train Loss: 0.5442022964744184\n",
      "Validation Loss: 0.46205019948063253\n",
      "Train Loss: 0.5442022964744182\n",
      "Validation Loss: 0.46205019939299496\n",
      "Train Loss: 0.5442022964744182\n",
      "Validation Loss: 0.4620501993491763\n",
      "Train Loss: 0.5442022964744182\n",
      "Validation Loss: 0.4620501993053577\n",
      "Train Loss: 0.5442022964744182\n",
      "Validation Loss: 0.4620501992615388\n",
      "Train Loss: 0.544202296474418\n",
      "Validation Loss: 0.46205019946654785\n",
      "Train Loss: 0.544202296474418\n",
      "Validation Loss: 0.4620501991300827\n",
      "Train Loss: 0.5442022964744179\n",
      "Validation Loss: 0.4620501993350917\n",
      "Train Loss: 0.5442022964744178\n",
      "Validation Loss: 0.4620501992912729\n",
      "Train Loss: 0.5442022964744176\n",
      "Validation Loss: 0.46205019891098914\n",
      "Train Loss: 0.5442022964744176\n",
      "Validation Loss: 0.4620501988671704\n",
      "Train Loss: 0.5442022964744175\n",
      "Validation Loss: 0.46205019877953296\n",
      "Train Loss: 0.5442022964744174\n",
      "Validation Loss: 0.46205019873571435\n",
      "Train Loss: 0.5442022964744174\n",
      "Validation Loss: 0.46205019869189556\n",
      "Train Loss: 0.5442022964744173\n",
      "Validation Loss: 0.4620501986480769\n",
      "Train Loss: 0.5442022964744173\n",
      "Validation Loss: 0.46205019831161176\n",
      "Train Loss: 0.5442022964744173\n",
      "Validation Loss: 0.462050198267793\n",
      "Train Loss: 0.5442022964744172\n",
      "Validation Loss: 0.46205019818015564\n",
      "Train Loss: 0.5442022964744172\n",
      "Validation Loss: 0.46205019813633674\n",
      "Train Loss: 0.5442022964744171\n",
      "Validation Loss: 0.46205019834134586\n",
      "Train Loss: 0.544202296474417\n",
      "Validation Loss: 0.46205019854635493\n",
      "Train Loss: 0.5442022964744168\n",
      "Validation Loss: 0.4620501984587174\n",
      "Train Loss: 0.5442022964744168\n",
      "Validation Loss: 0.4620501984148988\n",
      "Train Loss: 0.5442022964744166\n",
      "Validation Loss: 0.46205019837108\n",
      "Train Loss: 0.5442022964744166\n",
      "Validation Loss: 0.46205019803461483\n",
      "Train Loss: 0.5442022964744165\n",
      "Validation Loss: 0.46205019794697744\n",
      "Train Loss: 0.5442022964744164\n",
      "Validation Loss: 0.4620501979031587\n",
      "Train Loss: 0.5442022964744164\n",
      "Validation Loss: 0.4620501975666936\n",
      "Train Loss: 0.5442022964744164\n",
      "Validation Loss: 0.46205019752287485\n",
      "Train Loss: 0.5442022964744163\n",
      "Validation Loss: 0.4620501974790561\n",
      "Train Loss: 0.5442022964744163\n",
      "Validation Loss: 0.46205019714259105\n",
      "Train Loss: 0.5442022964744163\n",
      "Validation Loss: 0.46205019709877226\n",
      "Train Loss: 0.5442022964744162\n",
      "Validation Loss: 0.46205019705495365\n",
      "Train Loss: 0.5442022964744162\n",
      "Validation Loss: 0.46205019701113487\n",
      "Train Loss: 0.5442022964744161\n",
      "Validation Loss: 0.4620501969234975\n",
      "Train Loss: 0.544202296474416\n",
      "Validation Loss: 0.46205019717232515\n",
      "Train Loss: 0.544202296474416\n",
      "Validation Loss: 0.4620501971285065\n",
      "Train Loss: 0.544202296474416\n",
      "Validation Loss: 0.46205019708468775\n",
      "Train Loss: 0.5442022964744159\n",
      "Validation Loss: 0.46205019699705036\n",
      "Train Loss: 0.5442022964744158\n",
      "Validation Loss: 0.46205019690941296\n",
      "Train Loss: 0.5442022964744158\n",
      "Validation Loss: 0.4620501968655942\n",
      "Train Loss: 0.5442022964744155\n",
      "Validation Loss: 0.4620501967779569\n",
      "Train Loss: 0.5442022964744156\n",
      "Validation Loss: 0.46205019648531026\n",
      "Train Loss: 0.5442022964744155\n",
      "Validation Loss: 0.46205019644149165\n",
      "Train Loss: 0.5442022964744154\n",
      "Validation Loss: 0.46205019635385414\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.462050196602682\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Epoch: 10000, Train Loss: 0.54, Validation Loss: 0.46\n",
      "=====================================\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n",
      "Train Loss: 0.5442022964744153\n",
      "Validation Loss: 0.4620501959735704\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(train_X.columns.size)\n",
    "b = 0\n",
    "learning_rate = 0.003\n",
    "\n",
    "epoch = 10000\n",
    "\n",
    "for epochs in range(epoch):\n",
    "\n",
    "\n",
    "    \"\"\"Compute Lofis\"\"\"\n",
    "    train_loss = cost_function(train_X, train_y, w, b)\n",
    "    val_loss = cost_function(val_X, val_y, w, b)\n",
    "    print(f\"Train Loss: {train_loss}\")\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "\n",
    "    \"\"\"\"Compute Gradient Descent\"\"\"\n",
    "    dw, db = compute_gradient(train_X, train_y, w, b)\n",
    "\n",
    "\n",
    "    \"\"\"Update Parameters\"\"\"\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    if epochs % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {train_loss:0.2f}, Validation Loss: {val_loss:0.2f}\")\n",
    "        print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Parameters: w = [-0.04665697 -0.04665697 -0.04665697 -0.04665697 -0.04665697 -0.04665697\n",
      " -0.04665697 -0.04665697 -0.04665697 -0.04665697 -0.04665697 -0.04665697], b = 1.146310115163196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Parameters: w = {w}, b = {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is  0.48620323140031224\n"
     ]
    }
   ],
   "source": [
    "test_loss = cost_function(test_X, test_y, w, b)\n",
    "print(f\"MSE is  {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"The Phenomenon of overfitting occurs when the model learns the training data too well, including its noise and outliers, leading to poor generalization on unseen data. In this case, the model performs well on the training set but fails to predict accurately on the validation and test sets. To mitigate overfitting, techniques such as regularization, dropout, and early stopping can be employed. Regularization adds a penalty term to the loss function to discourage complex models, while dropout randomly drops units during training to prevent co-adaptation. Early stopping monitors validation loss and halts training when it starts to increase, ensuring the model retains its ability to generalize. By implementing these strategies, we can improve the model's performance on unseen data and reduce overfitting.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
